{"text":"Title: Exploring the dark universe with quantum technologies Abstract: The search to understand the nature of the elusive dark matter in our universe, making up 85% of its mass, is amongst the highest scientific priorities around the world. Terrestrial experiments focus efforts on Weakly Interacting Massive Particles (WIMPs) with ultra-low background experiments, operating many tonnes of target mass in deep underground sites. Such experiments have swept the bulk of the available electroweak parameter space for WIMPs and in the next decade will approach an irreducible background from coherent scattering of neutrinos - indistinguishable from WIMPs. Internationally, efforts are ramping up to explore new avenues towards the first definitive detection of galactic dark matter: quantum technologies is an exciting new frontier that may provide the breakthrough.\n\nLevitating nanospheres, opto-mechanically held with high precision, represent targets with unprecedented sensitivity to dark matter scattering. Our experimental setup holds a 150 nm quartz sphere, represented in Figure 1, and has recently indicated recoil sensitivity to local alpha-particle emission. In this project, we will investigate through the experimental facility and Monte Carlo simulations the sensitivity to neutron and gamma-ray sources as well. We expect that our target can discriminate between them whilst also providing directional information and sensitivity to free electrons. Such capability would be revolutionary in the global hunt for dark matter: sensing the direction of incoming particles lowers the number of events required for discovery dramatically and can penetrate the irreducible background from coherent neutrino scattering. Moreover, the system would be sensitive to a vast range of well-motivated low-mass WIMP and non-WIMP thermal relic dark matter candidates, as well as beyond the Standard Model and exotic neutrino physics, all of which have remained inaccessible to-date.","isTelecoms":0}
{"text":"Title: DCDP - Digital Cancer Diagnosis Platform Abstract: Chromition have developed innovative and disruptive digital cancer diagnostic platform. The platform uses Chromition\u2019s innovative Luminspheres\u2122 nanotechnology combined with spatial pattern recognition software to diagnose cancer.\n\nLuminspheres\u2122 are multicoloured fluorescent nanoparticles that are prepared from carbon-based precursors in water at low temperature using our proprietary and environmentally considerate process.\n\nLuminspheres\u2122 bioimaging probes when tethered to biological molecules of interest provide sensitive and non-invasive insight into biological processes and interactions with minimal impact on the system under investigation.\n\nChromition are working with the Manchester University NHS Foundation Trust (MFT), using the Luminspheres\u2122-antibody biomarker conjugates to stain tissue samples.  The tissue samples are then analysed by Chromition\u2019s digital platform, which is able to analyse multiple biomarkers in a short space of time using bespoke spatial pattern recognition software.\n\nChromition will use Luminspheres\u2122 in Immunohistochemical Staining (IHC) to rapidly identify multiple biomarkers in a single image. The image will then be analysed by innovative software that facilitates fast and autonomous analysis of multiple samples across a clinical cohort.\n\nThe development of this technology will enable the identification and analysis of multiple biomarkers at a speed not currently possible using existing technology and relying on human sight. \n\nThe success of this project has the potential to transform the way clinical pathology is practiced.\n\nIn this project the platform will be used to identify multiple cancer biomarkers in tissue samples from women with endometrial cancers. \n\nUtilising the Chromition method firstly for the identification of endometrial cancers, and using the results to tailor medical intervention, will have a significant impact on the cancer burden for women in the EU and globally.","isTelecoms":0}
{"text":"Title: Bayesian issues in ant navigation Abstract: Our brains have to deal with ambiguity and uncertainty, and an increasingly popular explanation of how they do so is based on Bayesian reasoning. In essence, this says we estimate the probability of a certain state of affairs (such as 'I am at home') on the basis of both current sensory inputs ('This looks like my house') and prior expectations ('Given my starting location, and the speed I was travelling, I wouldn't expect to be home yet'). Bayes theorem tells us how we should combine these factors to obtain the best estimate of our current state. But is this form of reasoning universal? An ideal way to investigate this issue is to look at 'simple' animals that have to solve analogous problems. And an effective way to test our understanding of what these animals do is to implement and test our hypotheses in robot models that operate in the same sensory environment. A clear example of an animal solving such problems is found in desert ants, who forage individually and without the use of chemical trails, yet can efficiently relocate their nest or a food source over long distances in barren or complex environments. Recent studies have shown that ants can individually learn and recall specific routes through cluttered environments that force detours and prevent the use of distant landmarks. Ant navigation depends on two main mechanisms: they can keep track of how far they have moved and in which direction from the nest and continuously update a vector that points back home; and they can recognise familiar visual surroundings and use these to determine which way to go. Do they integrate these cues in an optimal fashion? What if one or other cue is more or less variable? Can they use one of these cues to disambiguate the other? We can make the investigation of these issues rigorous and quantitative by drawing on methods developed for robot navigation. We will first determine what ants actually see as they develop new routes, by following ants as they forage, and capturing images from the ant's eye point of view. We will feed this information into algorithms that should be able to learn a map of the area. We can systematically vary the type of information available, its reliability, and the computational methods used to update the map, and compare the performance to ants. Further experiments to see what the ants do when the same variables are manipulated will serve to evaluate the models. Finally, the models will also be tested in the real world by implementing them on a small robot able to navigate in the ant environment.","isTelecoms":0}
{"text":"Title: TB-EPF - Enhanced Place Finding (EPF) of TB transmission hotspots Abstract: TB is transmitted via person-to-person aerosols. Recent studies suggests that in TB endemic areas up to 70% of transmission events take place outside the household in public places. Moreover, TB transmission is unequally spatially distributed and occurs in transmission hotspot areas. Mathematical models consequently demonstrated that identifying hotspots and blocking within-hotspot-transmission through targeted public health interventions will be the most efficient way of lowering the TB burden. In the present PoC proposal we aim to complement the population-based Enhanced-Case-Finding intervention tested in the INTERRUPTB study, with a spatially more targeted \u201cEnhanced-Place-Finding\u201d (EPF) approach to identify transmission hotspots in an unbiased fashion. Using traditional methods to find transmission hotspots can only be done retrospectively after years of data collection. Therefore we propose a novel EPF strategy to detect transmission hotspots in real-time using phone-tracking technology to establish a spatial map of aggregated TB patients movements. Within the ERC-funded INTERRUPTB study in The Gambia, we sequenced 2000 mycobacterial isolates, which allows us to establish a bacterial genetic transmission network. Within the PoC proposal, we seek to reconsent these patients to analyze their everyday movements using classical contact investigation complemented by phone tracking, to determine which public places have an increased risk of TB transmission. We aim to demonstrate that phone tracking of TB patients can be a cheap, easy, and, most importantly, prospective TB transmission hotspots identification tool, no longer requiring molecular epidemiological investigations. Such a finding can ultimately be developed into an app that warns national TB programs of early TB outbreaks, so that early public health measures like increased ventilation and active case finding can be initiated. This approach can furthermore be applied to other infectious diseases.","isTelecoms":1}
{"text":"Title: Engineering enzymes to enhance diagnostic devices for improved antibiotic stewardship Abstract: Project Summary\nBackground: Atlas seeks to develop improved diagnostics systems by engineering enzymes to enhance Atlas' diagnostics technology. The Atlas Genetics io system is a pioneering rapid diagnostic platform designed to detect the presence of infectious diseases such as Chlamydia and MRSA, where a quick, actionable test result provided on-demand can significantly improve patient outcomes and better target the use of antibiotics and is thus of relevance to the Antimicrobial Resistance (AMR) theme. The Atlas platform uses enzymes known as flap endonucleases. These are structure-specific DNA processing enzymes. The Sayers lab has a track record in developing these enzymes and for commercial use (1) and significant expertise in their characterization, production and modification (2,3). This will also include a second academic supervisor, Prof. Jamie Hobbs (Physics Dept TUOS) who will supervise work on Atomic Force Microscopy (ATM) imaging of protein DNA complexes. \n\nBrief project outline: This collaboration seeks to further characterize the enzymes used by Atlas and to develop new more robust versions with improved signal-to-noise characteristics and to carry out basic structure determination of the EE-DNA complex as we have done for a related enzyme (3). Atlas Genetics Ltd Atlas has expertise in microfluidics\/hardware for electrochemical detection of specific DNA and is developing new point-of-care devices for rapid detection of pathogens and genetic defects. However, a recombinant exonuclease is central to the system but Atlas has no historical expertise in this area. Complementary expertise in recombinant exonuclease technology, kinetic assays and recombinant protein production exists in the academic partner labs, who have developed new engineered exonucleases (EEs) that appear ideally suited to the Atlas platform.\n\nThe student will express, purify and characterize a bank of EEs and evaluate their performance in the Atlas system compared with their current enzyme. He\/she will carry out systematic assay development aimed at improving signal-to-noise ratios, stability, detection limits and specificity. We have a real-time FRET-based solution phase assay that will be used to produce quantitative biophysical data in addition to the Atlas assay. We will also attempt crystallization and structure determination of the EEs with bound DNA substrates to further inform the protein engineering process and provide new data on these biologically and commercially important enzymes. \n\nReferences from Sayers' lab relevant to project\n\n1) Sayers, JR, Zhang J. Modified Exonucleases, 2013, Patent application WO2013079924 \n2) Wong, I. N., Sayers, J. R., &amp; Sanders, C. M. (2016). Bacteriophage T5 gene D10 encodes a branch-migration protein. Scientific Reports, 6.\n3) AlMalki, Faizah A., et al. Direct observation of DNA threading in flap endonuclease complexes. Nature Structural &amp; Molecular Biology (2016).","isTelecoms":1}
{"text":"Title: HIV-1 Reservoir in Gut-Associated Lymphoid Tissue (GALT) in Primary HIV Infection Abstract: HIV is a chronic disease that can be well controlled with daily medications, known as antiretroviral therapy (ART). Usually ART is not started straight away, but only after immune cells (CD4 T-cells) have fallen below a set level. Although ART has dramatically improved survival for people living with HIV, it cannot cure HIV and so once started, treatment is life-long. This is because current ART cannot remove HIV from cells containing virus in a resting state - known as the HIV reservoir. For this reason virus levels return and people can become unwell if ART is stopped. Lifelong ART is challenging due to drug side effects, treatment fatigue, viral drug-resistance and expense. Whilst curing HIV infection is not possible with ART alone, a period of time off treatment without detectable virus in the blood - &quot;remission&quot; maybe feasible and is highly attractive.\n\nRecent studies have shown that if ART is started immediately after an individual becomes infected with HIV a lower level of viral reservoir can be achieved than for those starting treatment in later stage disease. Unexpectedly, amongst some rare individuals treated from early infection, virus did not return to high levels even after therapy is stopped; this is called post-treatment control (PTC).\n\nUsing current laboratory tests to measure HIV reservoir in blood cannot accurately predict who might achieve PCT. One reason blood tests measuring viral reservoir may not accurately predict PTC may be that the rebounding virus is not coming from blood cells. There are different HIV reservoirs in the body from which the virus can return; the largest is the gut which can be five times larger than the reservoir in the blood. It is hypothesized that virus that returns after ART is stopped maybe coming from reservoirs within the Gut-associated lymphoid tissue (GALT).\n \nTo address this question, my key aim is to characterise and compare measures of viral reservoir in gut samples with those from blood from people who have started on early ART. This will be a sub-study of an ongoing study of treated early infection called HEATHER which is evaluating blood biomarkers of viral reservoir. Participants enrolled into the HEATHER study will be invited to additionally agree to an endoscopy where small samples of gut will be taken for research evaluation of viral reservoirs. These biopsy tests are routine procedures and will be performed by a doctor who specialises in such procedures at St Mary's Hospital in London. We will analyse the blood and gut samples using specialised laboratory tests at the University of Oxford in order to assess the types of cells which make up the reservoir and the amount of HIV in the gut reservoir compared with blood. We then aim to investigate if gut reservoir measures can predict which patients might safely interrupt ART and achieve PTC. Ultimately this will be tested by giving the option of interrupting treatment (as part of a study) but only amongst a very small number of patients deemed most likely to achieve PTC based on our study results. The results of this work will inform other studies which test new treatments aimed at curing HIV by helping the investigators to decide who can stop treatment without the virus returning.","isTelecoms":0}
{"text":"Title: DERIVE:Dev. of Riboflavin biomarkers to relate dietary sources with status, gene-nutrient interactions and validated health effects in adult cohorts Abstract: Riboflavin (vitamin B2) is essential energy metabolism, but biomarker\nstatus is rarely measured. The UK and Ireland are the only countries worldwide to have included a riboflavin\nbiomarker in national dietary surveys. Some concern exists in both countries regarding the large proportion of\nadults showing low riboflavin status, measured using erythrocyte glutathione reductase activation coefficient\n(EGRac) (the gold-standard marker), but the functional significance of such findings is unclear since in general,\nwith the exception of younger women, dietary intakes of British and Irish adults are within dietary reference\nranges. Elsewhere in the world (including Canada and US), riboflavin biomarkers are not measured in nutrition\nsurveys because the existing biomarker EGRac requires very specific pre-analysis processing, unfeasible in most\nsettings. DERIVE will develop accessible riboflavin biomarkers in plasma (FMN, FAD, riboflavin) and identify\nwhich most sensitively reflect dietary intakes and food sources of riboflavin in biobanked population based\ncohorts from Ireland (n=1136) and Canada (n=1200), and are in best agreement with EGRac. The functional\nsignificance of riboflavin will be evaluated using samples from previous placebo-controlled riboflavin\ninterventions (n=537; UK cohorts) to test whether correcting low status is associated with a functional response\nrelated to a known metabolic role of riboflavin, the FMN-dependent generation of active vitamin B6 (i.e. PLP) in\ntissues. Finally we will demonstrate an important health effect of riboflavin by investigating its role in modulating\nblood pressure via a novel gene-nutrient interactive effect mediated through the FAD-dependent folate\nmetabolising enzyme methylenetetrahydrofolate reductase (MTHFR).","isTelecoms":0}
{"text":"Title: Agent-based controllers for electric vehicles and micro-generators Abstract: The concept of intelligent autonomous software for controlling domestic appliances, small domestic generators and electric vehicles has been studied extensively within the last years. The academic partners of this project have developed and tested two software systems for controlling (i) electric vehicles (EV) battery charging and (ii) domestic generator emissions. The operation of both systems has been tested experimentally.\nThis project will look at ways to bring these two software systems from a conceptual level to a real product\/solution. This product\/solution can be used by businesses in the future energy market to control electric vehicles and domestic generators, bringing benefits both to these businesses and to the end-user.","isTelecoms":1}
{"text":"Title: University of the West of England Bristol and Rowan Dartington &amp; Co Limited Abstract: To enable better investment decisions to be made through the introduction of novel portfolio analytics and historical performance analysis; and differentiate itself through the personalisation of its portfolio management system.","isTelecoms":1}
{"text":"Title: Investigating the Cultural Ecosystem Services of Urban Water Bodies and their use in Environmental and Land Use Planning Abstract: Bodies of freshwater, such as rivers, lakes and canals, serve\nas defining features of human settlement, are amongst the\nmost biodiverse habitats on earth (Dudgeon et al, 2006) and\nhave significant importance to people, providing spiritual and\ninspirational values, recreational opportunities, favourable\naesthetics and educational opportunities (Millennium\nEcosystem Assessment, 2005). However, their value has\noften been overlooked with urbanisation and changes in land\nuse posing a significant threat to the services they provide\n(Everard and Moggridge). This PhD project will work with the\nEnvironment Agency to investigate the non-material benefits\nhumans obtain from urban blue spaces, such as health and\nwellbeing and to identify how this information could be used\nin environmental and land use planning. This will support the\ndelivery of England's policy framework for freshwater\nmanagement.\nNatural environments within towns and cities has been\nshown to have positive effects on health inequalities, mental\nhealth, recreation and life satisfaction. Therefore, designing\ntowns and cities with this in mind could help to overcome the\nunhealthy lifestyles and increased chronic diseases that are\nassociated with increased urbanisation (Dora &amp; Phillips,\n2000; Passchier-Vermeer &amp; Passchier, 2000; WHO, 2009),\nwhilst at the same time protecting the environment and\npromoting sustainability.\nTo date most investigations of the health benefits of natural\nenvironments have typically not differentiated between blue\nand green space (V&ouml;lker &amp; Kistemann, 2011). Therefore,\nmore research is needed to understand how urban blue\nspace contributes to health and wellbeing in order for the\nsustainable management of these resources.\nCultural Ecosystem Services (CES) are the &quot;nonmaterial\nbenefits people obtain from ecosystems through spiritual\nenrichment, cognitive development, reflection, recreation,\nand aesthetic experiences&quot; (MA, 2005). Recent work has\nproposed and applied frameworks to assess CES focusing on\nthe contribution that aspects of environmental spaces and\ncultural practices make to three aspects of wellbeing;\nidentity, experiences and capabilities (Fish et al., 2016a; Fish\net al., 2016b; Bryce et al., 2016). However, these have only\n3 \/ 13\nbeen applied in designated areas such as national parks,\nnature improvement areas and marine protected areas (Fish\net al., 2016b; Bryce et al., 2016) which has overlooked urban\nareas and everyday activities that have the potential to\naffect the wellbeing of the increasing urban population. This\nPhD will investigate characteristics of urban blue space that\npeople visit and value, the cultural practices associated and\nthe benefits people obtain from urban water bodies in terms\nof identity and experiences. Working with the Environment\nAgency it will then go on to review the CES framework,\nmethods used to apply it and its use in environmental and\nland use planning.\n12 Project description: please\ncopy\/paste\/write a full description of the\nproposed project here, outlining its aims,\nproposed methodology, timescales and\nplans for dissemination and knowledge\nexchange, both between the project and\nexternal partner and with wider audiences","isTelecoms":0}
{"text":"Title: A revolutionary ground transport system to transport patients to and from hospitals, saving the NHS &pound;2M a year Abstract: Founded by the team of Amer Hasan, Barnaby Hapgood and Nicholas Brown, minicabit brings expertise and understanding from the world of cab driving together with product and software development to create an innovative solution to the problem of transport to and from hospitals. This endeavour has experienced both setbacks and great opportunities as a result of the changes wrought by COVID-19, but the company expects its uniquely designed ride-finding algorithms and wide range of payment and vehicle options to develop into a post-project revenue of &pound;15M.","isTelecoms":0}
{"text":"Title: UK National Quantum Technology Hub in Sensing and Timing Abstract: The Quantum Technology Hub in Sensors and Timing, a collaboration between 7 universities, NPL, BGS and industry, will bring disruptive new capability to real world applications with high economic and societal impact to the UK. The unique properties of QT sensors will enable radical innovations in Geophysics, Health Care, Timing Applications and Navigation. Our established industry partnerships bring a focus to our research work that enable sensors to be customised to the needs of each application. The total long term economic impact could amount to ~10% of GDP. \n\nGravity sensors can see beneath the surface of the ground to identify buried structures that result in enormous cost to construction projects ranging from rail infrastructure, or sink holes, to brownfield site developments. Similarly they can identify oil resources and magma flows. To be of practical value, gravity sensors must be able to make rapid measurements in challenging environments. Operation from airborne platforms, such as drones, will greatly reduce the cost of deployment and bring inaccessible locations within reach. \n\nMapping brain activity in patients with dementia or schizophrenia, particularly when they are able to move around and perform tasks which stimulate brain function, will help early diagnosis and speed the development of new treatments. Existing brain imaging systems are large and unwieldy; it is particularly difficult to use them with children where a better understanding of epilepsy or brain injury would be of enormous benefit. The systems we will develop will be used initially for patients moving freely in shielded rooms but will eventually be capable of operation in less specialised environments. A new generation of QT based magnetometers, manufactured in the UK, will enable these advances. \n\nPrecision timing is essential to many systems that we take for granted, including communications and radar. Ultra-precise oscillators, in a field deployable package, will enable radar systems to identify small slow-moving targets such as drones which are currently difficult to detect, bringing greater safety to airports and other sensitive locations. \n\nOur world is highly dependent on precise navigation. Although originally developed for defence, our civil infrastructure is critically reliant on GNSS. The ability to fix one's location underground, underwater, inside buildings or when satellite signals are deliberately disrupted can be greatly enhanced using QT sensing. Making Inertial Navigation Systems more robust and using novel techniques such as gravity map matching will alleviate many of these problems. \n\nIn order to achieve all this, we will drive advanced physics research aimed at small, low power operation and translate it into engineered packages to bring systems of unparalleled capability within the reach of practical applications. Applied research will bring out their ability to deliver huge societal and economic benefit. By continuing to work with a cohort of industry partners, we will help establish a complete ecosystem for QT exploitation, with global reach but firmly rooted in the UK. \n\nThese goals can only be met by combining the expertise of scientists and engineers across a broad spectrum of capability. The ability to engineer devices that can be deployed in challenging environments requires contributions from physics electronic engineering and materials science. The design of systems that possess the necessary characteristics for specific applications requires understanding from civil and electronic engineering, neuroscience and a wide range of stakeholders in the supply chain. The outputs from a sensor is of little value without the ability to translate raw data into actionable information: data analysis and AI skills are needed here. The research activities of the hub are designed to connect and develop these skills in a coordinated fashion such that the impact on our economy is accelerated.","isTelecoms":1}
{"text":"Title: Insect wing design: evolution and biomechanics Abstract: Insects are the most diverse order of animals on earth and flight may be the key to this success. However, despite hundreds of millions of years of evolution, insect wings have not converged on a single optimal shape. Instead, there is an extraordinary range of wing morphologies visible in the world today (and even more fossilized), yet fundamentally, they all perform the same task - to enable flight. This led me to ask 'why is there no single wing shape that is best-suited to flapping flight?'The answer may well lie in assorted locally optimal solutions, specifically adapted to the tasks each insect undertakes during its life. The mission-profile of flight is unique for each insect species and so the selection pressures on wing morphology and kinematics is also species specific. A dragonfly that catches its prey on the wing and engages in aerial combat against rivals must be fast and manoeuvrable. Contrast this with the death's-head hawkmoth, migrating across Europe raiding bees' nests. They must be highly efficient since energy is at a premium during migration, but also robust enough to withstand attacks from bees when in their honey-stores. Understanding the morphologies of over a million described flying insect species is unfeasible, yet trends run through them which are exciting for aerodynamic engineering because they show solutions to specific requirements that have been tried, tested, and proven to succeed.My research seeks to understand how and why insect wing shapes have such variation despite intense selective pressure for aerodynamic performance, and why morphologies change when transitioning between ecological niches. The best way to examine this is to look at examples of convergent evolution, species which have similar ecology and morphology, yet originate from disparate taxonomic branches. Selecting species which are quite unrelated from one another allows discrimination of the aspects of wing shape which are part of design optimisation as opposed to those which are simply due to their historical starting point. My experiment therefore utilizes a comparative approach to evaluate representative species from across the class.In Track 1 of my research programme, a Postdoc will measure the aerodynamic output of flying insects directly, because it is essential to know how fast and in which direction the air is moving around the wings and in the wake. Flow velocities will be calculated around insects tethered in a wind tunnel by seeding the air with a light fog, and illuminating the particles with pulsing laser light. This technique is called Digital Particle Image Velocimetry and is the technique of choice for engineers studying complex flows. Recently, I successfully applied the technique to flying insects despite their small size and high wingbeat frequencies.Insects have no musculature in their wings. All the deforming complexities of the flapping cycle are controlled either actively by muscles at the wing hinge, or passively by inertial and aerodynamic forces on the wing architecture. The aerodynamic output is a result of wing motion so it is vital to know how the wing shape changes during flapping. In Track 2 of my research, a PhD student will record the kinematics of individuals from the same representative insects. The student will test predictions about the role of wing shape in ecology, by artificially selecting strains of fruit fly for alternate morphologies (e.g. more slender wings) and characterising the new morphs' flight performance. Simultaneously, the student will validate their results, by selecting strains based upon flight performance, and measuring the resulting modification in wing morphology.The output from these two tracks will be: 1) an explanation for the diversity of insect wing shapes from the perspective of biomechanical adaptation; 2) detailed kinematic data for Computational Fluid Dynamics studies; 3) clear design guidelines for engineers constructing insect-sized vehicles.","isTelecoms":0}
{"text":"Title: Caenorhabditis elegans as an expression system for vaccine candidates of parasitic nematodes Abstract: Parasitic nematode (worm) infections of humans and livestock cause major health, welfare and economic problems worldwide. The efficiency of drugs currently available to control parasitic nematode infections is decreasing due to the emergence of drug-resistant parasites and alternative control approaches are urgently needed. Validation of new drug or vaccine targets of parasitic nematodes is hampered by the difficulty of obtaining sufficient parasite material for testing. Parasite proteins produced artificially in bacteria, yeast or insect cells are often folded incorrectly and\/or fail to be modified in the same way as the normal parasite protein. This affects the proteins' ability to stimulate protective immune responses to infection, required for an effective vaccine, and their ability to interact with inhibitors, required for drug design. Development of a system which can synthesise protein in a similar form to the protein present within the worm would, therefore, be advantageous to parasite vaccine and drug research. Parasitic nematodes are closely related to the free-living nematode Caenorhabditis elegans and many of the proteins made in free-living and parasitic nematodes are similar. We have successfully used C. elegans to synthesise a parasite enzyme and shown that the enzyme is active, can interact with inhibitors and is modified correctly. Sufficient protein was expressed for vaccine studies to be carried out. We now propose to use the C. elegans system to make a previously identified, highly effective vaccine candidate of a major sheep parasitic nematode. We will compare the folding and modifications of the C. elegans synthesised protein to the normal parasite protein and test its ability to protect sheep against nematode disease. This work can be developed to generate other important parasite proteins and will be important both to basic research of nematode proteins and to commercial vaccine development. We will link with other researchers with expertise in animal parasite control and with industry (Pfizer) to achieve our aims.","isTelecoms":0}
{"text":"Title: Lego Physics Abstract: For the Big Bang Fair in National Science and Engineering Week 2011, we developed a LEGO physics set documenting the history of the Universe, which covered aspects of the physics syllabus at both GCSE and A-Level. This grant bid is to extend the workshop to two separate workshops, incorporating the fission\/fusion aspects of GCSE and the more extended particle physics aspects of the A-Level.\n\nThe aim of this project is to improve the understanding of these topics within the syllabi by demonstrating them in an innovative way. We hope this may encourage more students at GCSE to take physics at A-Level, and students at A-level to consider a research career or a degree in physics.\n\nWe will disseminate the kits both via workshops, supported by current undergraduates and Ph.D students, and through a mailing to all UK schools, which we will be undertaking in September 2011. The mailing will include the instruction booklet for the LEGO kit we currently have, as well as other curriculum resources.","isTelecoms":0}
{"text":"Title: Knowledge repository for surgery preparations Abstract: Stenting is a popular treatment for common cardiovascular diseases, such as aneurysms or stenosis, performed in hospitals on a daily basis. Stents are small metallic tubes surgically placed inside diseased blood vessels to provide vascular support or relieve obstructions. Although, stenting is becoming more and more popular due to its minimally-invasive nature, there are a number of challenges associated with successful stent delivery. For a successful surgery, choosing the correct device is critical. Considering the significant anatomical variations between patients and differences in device mechanics, it is currently extremely difficult to predict the final configuration of a stent after deployment. This results in high mortality and morbidity, dangerous complications, increased cost, and the need for secondary surgeries.\n\nIn the proposed project we will be investigating the desirability and usefulness to clinicians of a novel knowledge repository which they can consult in preparation of surgeries. Working together with designers, we will be using the human-centred Idea's Design Kit methodology.\n\nDuring the immersion phase in hospital environment, we will be conducting in-depth research with end users -- neurosurgeons\/interventional neuroradiologists -- to determine their needs and design a proposed solution. Thereafter, the initial prototype sketches will be user-tested in the series of interviews and the received feedback used to iteratively improve the proposed solution to ensure it is fully aligned with clinical needs and to facilitate future adoption.\n\nThis functionality would provide unprecedented all-encompassing support for surgical preparation, improving patient outcomes and providing peace of mind to clinicians.","isTelecoms":0}
{"text":"Title: Active Filtering Technology Transfer for Magnetocardiogram Data Sets (ATTMEDS) Abstract: Creavo Medical Technologies make magnetocardiographs, devices for detailed modelling of the heart of patients presenting with symptoms consistent with heart disease.\n\nWe propose a collaborative research project with Creavo, that utilises existing expertise in signal processing, vibration isolation, vibration measurement, and dynamic tracking of sine wave components of data, to try and improve the filtering of background noise in the hospital environment found to affect Creavo devices. This expertise was gained whilst the Sheffield group was working on instrument science in connection with the LIGO gravitational wave detectors, and thus this project represents technology transfer from LIGO (with STFC support) to a UK owned and located SME. This project has the potential to impact heart patients worldwide, to help a strong British business, and to achieve impact from STFC-funded, nominally ' blue skies ' University research.\n\nThe proposed duration of the project is two years, during which specialised noise removal techniques will be tried in Creavo units under evaluation in test facilities at Creavo's research headquarters, and also at the University of Sheffield. We will also explore the use of specialised vibration measurement hardware and explore possibilities for the implementation of the developed methods in commercial unites manufactured by Creavo.","isTelecoms":1}
{"text":"Title: IAA Proposal Abstract: The University's mission is to 'discover and understand'. We remain committed to the goal of changing the world for the better through the power and application of ideas and knowledge.\nIn 2012, the University formalised its commitment to Impact, Innovation and Knowledge Exchange (IIKE) in its IIKE Strategy, which has four key objectives:\n1. To create and maintain deeper partnerships with external organisations\n2. To make the most of our Intellectual Property\n3. To engage with our City Region\n4. To embed Impact, Innovation and Knowledge Exchange within our organisation\n\nFollowing the success of our Pilot NERC Impact Accelerator, we will continue to invest in short term, collaborative Research and Development projects which aim to help academics to build partnerships with Industry and public sector partners, with the ultimate aim of translating their research into real-world impact. We will also trial a secondment scheme which will see academics spending time in industry, in order to better understand the opportunities of partnership.","isTelecoms":0}
{"text":"Title: PrImmersive Theatre Process &amp; Production: Developing a Capture Methodology for Archiving Digital Storytelling Abstract: This research will lead to a significant original contribution to the field of scenography and archival practice\nby providing a systematic documentation of the methods and processes utilised during the production of\nimmersive theatre.\nThe complex integrative nature of immersive theatre that increasingly combines virtual reality, rich audiovisual design and site-specific performance spaces has prompted a fast-moving period of creative\ninnovation, making it difficult for academic research to keep up. The first wave, inspired by the popularity of\ncompanies such as Punchdrunk in the UK at the start of the twenty-first century, spawned a raft of academic\nattention and new theories about audience interaction (Alston (2013), Machon (2013), White (2012)). Over\ntime the term immersive has come to be an indiscriminate metonym for any theatrical performance which\ninvolves even a modicum of audience agency. These critics argue that what we now refer as immersive\ntheatre is in fact an imprecise umbrella term for a confluence of traditional (i.e., promenade and site-specific\ntheatre) and other experimental digital formats. Marvin Carlson suggests there is no historical immersive\ntheatre; it is entirely a synthetic product of the twenty-first century for marketing purposes (2016). It is also\ncontested by industry professionals who reject the bifurcation of theatrical performance into immersive and\nnon-immersive; in their view, any production which sufficiently transports the audience into another time and\nplace meets this contemporary definition (Jarvis (2019), Dixon (2015)). Finally, it has been challenged\naesthetically by critics who contend mainstream immersive theatre is predominantly consumed by the\nbourgeoisie (Lehmann, 2006, p118); any output is therefore inevitably trapped within conventional modes of\ncommercial exploitation and resistant to genuine artistic expression (Ramos, Dunne-Howrie, Maravala &amp;\nSimon, 2020).\nThis critical focus on the audience experience of immersive theatre has largely ignored the innovative and\nrapidly changing practices employed in its production, specifically digital technologies and how these are\nimpacting all aspects of the production process across the industry. This research is timely because it will\nexpand discussions beyond reception to encompass a close analysis of the production processes involved\nin the making of immersive work and offer strategies as to how these rapidly changing processes may be\ncaptured and preserved before they are lost.","isTelecoms":1}
{"text":"Title: Oxford Space Systems: Deployable Cassegrain Ka-band Space Antenna (DeCSA) Prototype Abstract: Oxford Space Systems (OSS) is an awarding-winning early-stage technology business focused\non developing a new generation of deployable structures for the global space industry. The\ndiverse and experienced OSS team is rapidly establishing itself as an innovative &amp; agile\nsupplier to the space sector.\nAlthough an essential part of many geostationary telecomms satellites - and likely to form a\ncritical part of a large number of smaller low earth orbit (LEO) satellites - Europe currently\ndoes not have a flight-proven Large Deployable reflector Antenna (LDA). The EU presently\nrelies upon the US for all LDAs. The European Space Agency (ESA) recently published a\nWorking Group report which concluded, \u201cFrom the European industry point of view, there is\nan absolute dependence on the USA\u201d, and, \u201cLarge reflector technologies are considered a\nfundamental requirement to maintain commercial and strategic competitiveness\u201d. This was\nfurther echoed in a document published this year, \u201cCritical Space Technologies for European\nStrategic Non-Dependence\u201d, produced by the European Commission, ESA, and the European\nDefence Agency.\nLDAs fall into two families: Offset Feed and Cassegrain configurations. OSS has already\ndeveloped an innovative and highly scalable Offset Feed LDA to TRL3 that is significantly\nlower in mass, cost and complexity than current offerings from the USA.\nOSS has been approached by a USA based company to explore the development of a\nCassegrain LDA. This is for a proposed constellation of up to 35 LEO microsats scheduled\nfor launch in Q4 2018. Having profiled its outline concept to the potential customer, OSS are\nconfident that a significant export order can be secured if a prototype can be presented by mid-\n2017. In addition, OSS has similar interest from both Eu and Canadian companies.\nSecuring matched funding via this SMART award will enable the rapid development of a UK\nspace technology that has excellent export potential to Europe, USA and beyond.","isTelecoms":1}
{"text":"Title: Improving the design of medical devices used by asthmatic children. Abstract: Improving the design of medical devices used by asthmatic children.","isTelecoms":0}
{"text":"Title: Computational fluid dynamics (CFD) modelling of thermal propulsion system concept performance Abstract: Low-cost transport is one of the leading drivers for human development and routes out of poverty, but burning hydrocarbon fuels in internal combustion engine (ICE) vehicles results in various emissions which contribute to climate change and are toxic to humans. The challenge is therefore to develop affordable powertrain technology that can facilitate human development while minimising impacts on the environment and human health. Several recent studies have shown that a mixed-technology approach to the future fleet, which includes the use of hybrid-electric vehicles and alternative fuels for ICE vehicles, is the fastest way to save the most amount of carbon in a robust and sustainable fashion. Continued research into improving the ICE is therefore imperative for reaching national and international climate targets. A crucial part of the powertrain design process are CFD simulations, which provide opportunities to quickly optimise performance, diagnose problems, and provide explanations for observed experimental results. Characterised by complex multi-physics phenomena inherent in turbulent combustion, and spanning very broad space- and time-scales, CFD models of an ICE need to be carefully validated against measured data in order to produce reliable predictions. In particular, the present work answers two questions:\n1. What constitutes a fair comparison between CFD results and experimental measurements?\n2. When has a CFD model been sufficiently validated?\nThis work pioneers a novel use and interpretation of cutting-edge machine learning techniques to extract features from complex fluid flow datasets. Particular focus is placed on sparsity-promoting dynamic mode decomposition, which is a recent dimensionality reduction technique capable of correlating sections of a flow with specific frequencies. Therefore, steady structures can be separated from turbulent structures, which allows new insights to be gained from experimental data. The feature extraction capabilities are also robust against artificial diminishing of quantity magnitudes, which is a common issue with datasets relevant to propulsion research. This therefore enables the construction of fairer validation targets for the CFD models. The next step for the research is to use these tools to conduct a more in-depth investigation into important physical phenomena present in the flows, which will highlight key processes that need to be captured by the CFD as well as highlight any deficiencies in the model accuracy.\nThis project falls within the EPSRC 'Fluid dynamics and aerodynamics' research area, as is part of the EPSRC Prosperity Partnership - Centre of Excellence for Hybrid Propulsion Systems. Collaborators include Jaguar Land Rover, Siemens Digital Industries, and the University of Bath.","isTelecoms":0}
{"text":"Title: The Experimental Study of Elementary Particle Interactions at High Energy Abstract: The Large Hadron Collider is delivering data which allows us to study the properties of the smallest known constituents of matter - quarks and leptons. The current theory which describes these properties is known as the Standard Model, and it has been extremely successful in the predicting the outcome of experiments at lower energies. However, it is expected that new phenomena, not predicted by the Standard Model, should begin to appear in the TeV energy range. Theoretical predictions include a variety of new particles and interactions. Models using supersymmetry predict a new particle for every one so far discovered for example. The theory does not currently explain the lack of antimatter in our Universe. By performing experiments with the ATLAS and LHCb detectors, we aim to cast light on these issues by observing effects outside of the Standard Model.\n\nNeutrino experiments have also revealed many unexpected phenomena over the years, including the recent suggestion that they may travel faster than light. We will continue our successful exploration of the properties of these particles using the MINOS and MINOS+ detectors. We hope to able to confirm or refute the suggestion that they travel at superluminal speed, and also to test whether they possess interactions consistent with being in the class of Majorana particles (which are their own antiparticles), rather than Dirac particles as currently presumed. \n\nWe will also work on upgrading the detector systems of ATLAS and LHCb, which will allow us to continue to gather new data much faster, after a planned increase in beam intensity at the LHC. This will involve novel work on sensors and fast electronics.\n\nFinally, we will prepare the ground for the next generation of accelerators. If discoveries are made at the LHC, for example by observing the Higgs boson or another new particle, its properties will need to be measured at very high precision. This could be achieved with a linear electron-positron collider. We will remain in the forefront of design work for such a new machine and its detector systems.","isTelecoms":0}
{"text":"Title: The cosmic carbon observatory Abstract: This research programme seeks to understand key processes during the early history of the Solar System including the construction and destruction of planetary bodies, and delivery of some of the key ingredients for life to Earth, including carbon and water. \n\nOne focus of this project is on 'carbonaceous' asteroids that are made of rocks that are rich in water and organic matter. If enough fragments of these asteroids had fallen to the Earth early in its history, they could have introduced sufficient water and organic matter to help life to start. In recognition of their scientific importance, two carbonaceous asteroids, named Bennu and Ryugu, are currently being studied by spacecraft sent by NASA and the Japanese Aerospace Exploration Agency, respectively. These spacecraft have collected samples to deliver to Earth; Hayabusa2 successfully delivered ~5 g of Ryugu in December 2020. We will study these samples to understand how much water the asteroid now contains. One theory is that less water is present now than when the asteroid formed, and was lost as the asteroid was heated from the inside. We will try to answer this question by analysing samples from Ryugu, and interpreting them using information from experiments. These experiments will simulate the effects of heating of the asteroid's interior, and irradiation of Ryugu's surface by hydrogen and helium from the Sun (called the solar wind). \n\nIn another project we will investigate how the same process of solar wind irradiation could have added water to otherwise completely dry mineral grains within the disk of dust within which the Solar System was born. We will also evaluate how much of the water that has been created by this process may provide an accessible resource on the surfaces of airless worlds. This work will use extraterrestrial materials that have been exposed to the solar wind on the surfaces of asteroids and the Moon. Alongside this work, experiments will mimic the effects of solar wind on mineral grains. The amount of water in both sets of samples will be measured using a new and very powerful technique called atom probe tomography; this technique enables scientists to see the locations of atoms of various types and water molecules within a sample and in three dimensions.\n\nThe formation, compaction and aqueous evolution of carbonaceous asteroids, as well as how many of them were present initially in the proto-Solar System, is a hotly debated topic. Clues to the diversity of processes at work within these primitive bodies can be understood by exploring the microstructure and texture of meteorites and samples returned from these bodies. Using a multi-dimensional correlative approach underpinned by big data principles, we will group these materials by their texture and in so doing understand the dominant processes at work on primitive asteroids, and constrain how many there were. \n\nIn order to send fragments to Earth, the carbonaceous asteroids must have experienced collisions. There is also evidence of a much more violent event in the early history of the Solar System that led to the breakup of a body the size of Mercury or Mars. Fragments of this planet-size body have fallen to Earth as the ureilite meteorites. These rocks are very special as they contain minerals rich in carbon, including diamonds, that come from deep inside the planet. The chemical composition of these minerals and the rocks within which they occur can tell us much about the carbon cycle of this doomed planet, and how other planets including Earth formed and evolved.\n\nThe Cosmic Carbon Observatory will leverage cutting edge correlative micro to atomic scale analysis of precious extraterrestrial materials and thereby transform our understanding of crucial carbon-driven processes in the Solar System.","isTelecoms":0}
{"text":"Title: Reconstructing the Tree of Life: Are molecular phylogenies really better than morphological ones? Abstract: The phenomenon of evolutionary convergence has intriguing implications for the extent to which\nevolution may be predictable (https:\/\/theconversation.com\/what-do-aliens-look-like-the-clue-is-inevolution-63899).\nHowever, it often makes it difficult to reconstruct evolutionary relationships with\naccuracy. In particular, it is often assumed that convergence is a problem that particularly bedevils\nmorphological phylogenies, making them less accurate\n(http:\/\/www.42evolution.org\/videos\/researcher\/professor-matthew-wills\/), but is this really the\ncase?\nIt is increasingly easy to generate phylogenetic trees from molecular data, with analyses routinely\nconcatenating sequences from many tens or hundreds of genes. Despite their data-rich\nunderpinnings, new molecular trees often contain surprises, and frequently imply relationships that\nare at odds with established and traditional hypotheses derived from morphological data. One such\nexample is the phylogeny of mammal orders: the 'new mammal phylogeny' overturns many\n'traditional' groups (Fig. 1). Another example is the arthropods. How are we to view these conflicts?\nShould we necessarily conclude that the new molecular trees are likely to be the correct ones; swayed\nby the mass of molecular data and greater complexity of analytical models? To do so implies that many\ndecades of comparative anatomy and morphological scholarship have yielded data that are - at best\n- simply more noisy and error prone than the data from molecules. At worst, it may indicate that\nconvergence within morphological data implies relationships that are positively misleading.\nSince phylogeny cannot be known with certainty, there can be no objective test of accuracy. However,\nit is possible to assess the congruence of competing trees with independent sources of data on\nevolutionary history. Firstly, where the stratigraphic first occurrence dates of terminals (species,\ngenera and higher taxa) are known with reasonable accuracy, the extent of implied ghosts lineages\n(relative to theoretical limits) offers an index of the 'goodness of fit' to the fossil record. Secondly, the\nbiogeographical or palaeobiogeographical distributions of many groups contain a residual\nevolutionary signal, and this can also be tested for its fit to competing trees. While neither stratigraphy\nnor biogeography necessarily offers foolproof discrimination in any particular case, their application\nto a large statistical sample of cases - different major clades, different taxonomic levels, different ages\nof radiations - allows for some level of generality. The project will also identify which clades under\nwhich circumstances are most prone to morphological convergence, and therefore most suitably\nanalysed with molecular data.\nThe student will acquire an interdisciplinary and transferrable skill set: bioinformatics, phylogenetics,\nstatistics and palaeontology.","isTelecoms":0}
{"text":"Title: A.I. forecasting to reduce food waste - COVID-19 impact Abstract: The UK hospitality industry generates over 1 million tonnes of food waste each year, equivalent to approximately &pound;3 billion in cost and over 4.5 million tonnes of CO2\\. At the same time, UK restaurants yield a meager 3-5% average profit margin, making it one of the least profitable industries in the country. This economic struggle has been dramatically exacerbated by the COVID crisis. Through effective food waste reduction, restaurants can boost profitability by up to 2pp, while drastically reducing the environmental impact of their operations.\n\nThe key to reducing food waste lies in accurate demand forecasting. Restaurants order their perishable inventory days and weeks before selling dishes to their customers. Given that most restaurants rely on rigid 4-week demand averages and gut instinct to make their procurement decisions, food orders are routinely in excess of real demand - creating food waste.\n\nTenzo will research &amp; develop a cutting-edge forecasting tool, which will allow restaurant businesses to accurately forecast customer demand. Utilising powerful artificial intelligence algorithms, the tool will achieve the following objectives:\n\n* Generate accurate restaurant sales forecasts based on historical sales, weather, public events and other features\n* Split daily forecasts into item-level and hourly projections\n* Provide those forecasts to frontline workers (chefs, section managers, etc.) within a user-friendly mobile app - enabling them to know easily how much food to:\n * prepare and when (e.g. how much chicken to grill every hour); and\n * order and when (e.g. how much fish to order for next week).\n\nTenzo's project will focus on finding the most accurate forecasting algorithms and combining them with a user-friendly software interface to ensure frontline workers are empowered to reduce food waste in their day-to-day operations. By 2024, our tool could reduce annual UK hospitality food waste by over 38,000 tonnes, CO2 by over 175,000 tonnes and restaurant costs by over &pound;20 million.","isTelecoms":0}
{"text":"Title: TNOC Research Integrator Abstract: An important feature of this TNOC initiative is the development of new innovative, cross-disciplinary approaches in an attempt to improve our understanding of the evolution, success and impact of TNOC over time, in different cultural contexts and across societies; these improvements in understanding should lead to more effective ways to prevent and mitigate its impact. There is likely to be a read-across to other PaCCS themes (Conflict and Cybersecurity), and there is the potential to engage the interest of a broad range of non-academic stakeholders (at home and abroad).\n\nI will frame the work of the Research Integrator within this context. I can provide a realistic and disciplined approach to the role. But I won't stifle innovative and creative of projects likely to have been chosen for their willingness to take risks. Given limited time available to perform the role, it is also essential that nothing is done to duplicate the plans and networks established by the projects themselves. This has been a key principle of my time as PaCCS Champion, which would continue to apply here.\n\nThere are a number of phases to my proposed approach (although I see the programme of work developing organically and flexibly, with opportunities to accelerate or integrate different phases, in response to the needs of the projects themselves). \n\nPhase 1: Familiarisation. I hold one-to-one discussions with PIs and partners in all projects. I convene an early networking workshop where the PIs get to know one another: we compare and contrast research proposals, identify common themes, and understand the needs of non-academic stakeholders.\n\nPhase 2: Network Infrastructure. I liaise with the PaCCS Communications Coordinator, looking for an opportunity to establish the database of projects on the TNOC page(s) of the PaCCS website and exploring opportunities for introducing TNOC-specific blogs from projects, a collaborative workspace, etc.\n\nPhase 3. Early Collaboration. I work with PIs to enhance impact and knowledge exchange, offering clinics to develop tailored plans, making recommendations to extend links to non-academic stakeholders (in Government, Industry and the Third Sector); I will hold parallel discussions with potential beneficiaries of research in order to finesse opportunities for impact. I will draw on any related academic work, for instance work to map the different research projects and produce a &quot;synthesis piece&quot;. A workshop at the end of Year 1 would bring the projects together, ideally with their nominated non-academic stakeholders.\n\nPhase 4. Generating Early Impact &amp; Knowledge Exchange. Further clinics are run, looking for synergies between projects (facilitating the sharing of data, networks and findings). I design and deliver speed-dating and\/or placement schemes; and organise a Policy Workshop where researchers join with stakeholders to promote impact and knowledge exchange. \n\nPhase 5. Dissemination of Outputs. I draw on findings and recommendations from our Policy Workshop to draft, design, publish and launch one or more Policy Briefings (with a focus on synergies), pursuing follow-up action to increase likelihood of impact. This is done in collaboration with PIs and their partners. I also support individual projects to maximise their outreach, helping draft messages to relevant audiences.\n\nI will work with the communications infrastructure that I developed as PaCCS Champion: the Communications Coordinator, the website , and the Twitter handle (with almost 800 followers). Another important resource is the website being established by RUSI and funded by ESRC to support the Strategic Hub on Organised Crime. Channels for communication include broadcasting on social media (Twitter) and websites (publishing news stories, blogs and success stories); I have also worked with media outlets, including The Conversation UK which delivers product into the Creative Commons and is read around the world.","isTelecoms":1}
{"text":"Title: Subglacial Access and Fast Ice Research Experiment (SAFIRE): Resolving the Basal Control on Ice Flow and Calving in Greenland Abstract: Marine-terminating outlet glaciers drain 88% of the Greenland Ice Sheet and are responsible for at least half of the ice sheet's net annual mass loss, which at present is around 200 km3\/year. Understanding the processes that drive the fast flow of these glaciers is crucial because a growing body of evidence points to a strong, but spatially varied and often complex, response to both oceanographic and atmospheric forcing. While the bed of glaciers elsewhere is known to strongly influence the flow of ice, no observations have ever been made from beneath a marine-terminating glacier in Greenland; a potential and likely cause of significant error in current predictions of sea level rise. This project will correct this paucity of observational constraint by gaining access to the bed of a major marine-terminating outlet glacier (Store Gletscher) in West Greenland, in order to observe and characterise the basal interface. With instruments deployed at the bed and on the glacier's surface and forefield, the project will fully resolve the basal control on ice flow and the glacier's response to iceberg calving, including the effects of meltwater input to the bed. The observational outcome will inform the glacier's sensitivity to atmospheric as well as oceanographic forcing while also enabling numerical ice flow modelling of unprecedented detail and accuracy.","isTelecoms":0}
{"text":"Title: Self-consistent annihilation simulations of dark matter Abstract: The annihilation signal of dark matter relies significantly on the local properties of dark matter and how it self-interacts. Using the latest cosmological N-body simulations will help in our understanding of the interactions and the resulting signal. The aim of this project is to develop a self-consistent self-annihilation N-body simulation of dark matter, in which the dark matter is removed. An efficient, massively-parallel code will be created in order to carry out the self-consistent self-annihilating dark matter simulations. This code will use probabilistic calculations to remove dark matter mass on-the-fly, as the interactions take place. The code will be implemented into the EAGLE simulations and the results analysed. The results from this project will provide a theoretical model of the annihilation signal expected from dark matter. This will allow new constraints to be placed on the annihilation signal, which is of great importance to the detection experiments such as the Cherenkov Telescope Array as they search for dark matter in the universe.","isTelecoms":0}
{"text":"Title: How should we measure school performance and hold schools accountable? A study of competing statistical methods and how they compare to Progress 8 Abstract: In 2016, the Department for Education radically overhauled their secondary school accountability system and introduced 'Progress 8', arguing it to be the simplest and fairest school performance measure to date. Progress 8 aims to quantify and communicate the average academic value each school adds to their pupils' learning. Specifically, Progress 8 measures how much higher each school's pupils score in their age 16 GCSE examinations than expected given their age 11 KS2 test scores when they started secondary schooling. Progress 8 scores are used to hold schools to account, with the lowest scoring schools judged 'underperforming' and 'coasting'; classifications that trigger intense scrutiny and intervention from the school inspectorate, Ofsted. Given the high-stakes involved, research is urgently needed to first evaluate the strengths and weaknesses of the statistical method underlying Progress 8, and second, to explore the potential benefits of alternative methods for measuring school performance. Our proposed research will address these needs and in doing so will advance scientific understanding about school performance measurement.\n\nThe first aim of the proposed research is to study how sensitive Progress 8 and other value-added measures' scores, rankings and classifications are to the statistical modelling decisions and assumptions implicit in their design. These include fundamental decisions over whether value-added measures should additionally consider pupil non-academic outcomes and whether they should account for the substantial differences in pupils' demographic and socioeconomic characteristics between schools. We will also explore an assumption implicit in Progress 8 and many other value-added measures which is that there is no relationship between pupils' family backgrounds and the quality of the schools they attend (i.e., confounding or selection into school). We will study the extent to which alternative value-added approaches can address this (using fixed- and random-effects models). We will also explore another assumption of Progress 8 and many other value-added measures which is that the GCSE outcomes of low scoring pupils at KS2 are no more variable than those of high scoring pupils at KS2 (i.e., homoskedasticity). We will study different approaches proposed in the literature to address this concern.\n \nThe second aim of the proposed research is to adapt and evaluate a range of cutting edge statistical methods not yet applied to measuring school performance. We will study their advantages and disadvantages over standard value-added approaches including Progress 8. These include methods that allow users to compare not just the average progress made by pupils in each school, but to also study the variability in pupils' progress (i.e., mixed-effects location scale models and multilevel quantile regression). These also include methods that are less reliant on extrapolating the relationships in the data and may therefore lead to fairer and more meaningful school comparisons (i.e., propensity score and other matching methods for comparing multiple treatments).\n\nWhereas the above aims will advance the academic research in the school effectiveness and methods literatures, our third aim is to make fundamental contributions to the wider non-academic understanding of alternative methods for measuring school performance in England. We will therefore disseminate our findings to the users and producers of school and public-sector institution performance measures. These groups include policy makers and their advisers, statisticians and researchers in relevant Government departments and charities, as well as schools, the media and parents. Planned activities include: knowledge exchange meetings, research briefings, a data visualization website, an end-of-grant symposium, online training materials, and a face-to-face short training course.","isTelecoms":0}
{"text":"Title: Electron impact vibrational excitation in plasmas Abstract: The vibrational excitation of molecules by electrons in diffuse plasma, such as those found in cometary coma or used in industrial etching, is a key but poorly understood process. Excited vibrational states can either emit photons giving rise to tell-tale observable signature emissions or be a stepping-stone to further processes such as dissociation via further electron impacts. \n\nVibrational excitation cross sections are hard to measure even for excitations from the vibrational ground state and essentially unmeasured for excited states. The proposal is to study vibrational excitation for key molecules naturally (such as water) and etching plasmas (such as NF, NF2 and NF3). This study will be performed by developing the UK Molecular R-matrix code (UKRMol) which were developed under various EPSRC grants and forms the basis of the Quantemol-N expert system distributed by Quantemol Ltd. Both these codes have been used to study electron collisional excitations of importance both for pure physics investigations (eg electron impact rotational excitation) and plasma physics (eg electron impact dissociation and ionisation). Thus far vibrational excitation has only been studied for the special case of resonant excitation of diatomic molecules using a standalone code and a non-extendable procedure.","isTelecoms":1}
{"text":"Title: Dopaminergic and glutamatergic contribution to the formation of decision variables in fronto-parietal brain circuits Abstract: We make innumerable decisions every day. Decision making requires accumulation of evidence for or against a proposition and ultimately for a specific action. However, it is not sufficient to simply accumulate evidence, the evidence must be evaluated. How useful it is? When is enough enough? Many of these aspects of decision making have been studied at the psychological and, to some extent, the neuronal level. Accumulation of evidence has been studied in the context of value based decisions, social decisions, economic decisions, gambling decisions, memory-based decisions, and, importantly, perceptual decisions. These studies have provided a rich theoretical background within which decision making can be explained, and they have generated tools to delineate the different cognitive components that are involved in decision making. \nAt the neuronal level, signatures of decision making have been found in various cortical and subcortical areas. Neurons in these areas gradually alter their activity as evidence in favor or against a proposition is gathered, and they retain the representation of accumulated evidence even when the evidence is removed, i.e. a memory trace of evidence exists. Finally, many of these neurons convert the evidence into a categorical decision, when sufficient evidence has been gathered, or when urgency so dictates. \nDespite these insights, we currently do not understand how brain areas involved in decision making exchange information, or how the process of evidence accumulation, evidence evaluation, and categorization is made possible. Specifically we do not understand which brain chemicals (transmitters and their related receptors) are critical in enabling these processes. An understanding thereof is essential to understand decision making at a mechanistic level, and to understand how deficits in decision making come about in mental disorders such as Schizophrenia, Impulsive compulsive disorders, or Parkinson (for example). \nWe aim to study these questions in macaque monkeys, the most appropriate animal model to relate neuronal data to human conditions. Neuronal signatures of decision making are best understood in the domain of perceptual decisions. In the laboratory, this is studied by confronting subjects with noisy sensory stimuli, who have to discriminate what stimulus has been presented. We will exploit well established paradigms which have helped understand the neural computations involved in perceptual decision making, namely a reaction time version of a coherent motion discrimination task, and a task where sequential information about the likely choice location has to be integrated over time. In the coherent motion task the subject is confronted with noisy motion stimuli and has to decide what direction of motion is present. In the sequential sampling task, monkeys are presented with different symbols which indicate a likelihood that a given choice location will yield a reward. We will record neuronal activity in the parietal and the frontal cortex, which have been studied in the context of these tasks. We intentionally copy existing paradigms and record in areas where the basic response properties are well delineated, as this allows to test specific predictions how different brain chemicals support different components of the decision making process. We focus on the dopaminergic and the glutamatergic system, as these have been implicated with different cognitive dysfunctions that affect decision making (e.g. working memory, evidence accumulation, evidence evaluation), but their contribution at the neuronal level remains poorly understood. We will determine how these systems contribute to evidence accumulation, evidence evaluation, and threshold setting to form a categorical decision.\nThe study will generate a better understanding of the neuronal mechanisms of decision making in health and disease, aiming to help improve therapeutic approaches in the future.","isTelecoms":0}
{"text":"Title: Autocat - Autocatalysis: A bottom-up approach to understanding the origins of life Abstract: \"The origin of life is not well understood, and is one of the great remaining questions in science. Autocatalytic chemical reactions have been extensively studied with the aim of providing insight into the principles underlying living systems. In biology, organisms can be thought of as imperfect self-replicators, which produce closely related species, allowing for selection and evolution. Autocatalysis is also an important part of many other biological processes. \nThis project aims to develop new autocatalytic reactions where two simple chemical building blocks come together to give a more complex product, and then the product aggregates to give primitive cell-like structures or \"\"protocells\"\" such as micelles or vesicles. The protocells allow the starting materials to mix more efficiently, speeding up the reaction in time and giving rise to complex behaviour of the protocells. These reactions will serve as models that I hope will contribute to understanding how cell-like systems can emerge from simpler chemicals and be relevant to how life started on earth.\nThis project will give the opportunity to study chemical systems that may be able to evolve in time, allow development of useful chemical models of important biological processes, and provide \u2018bottom-up\u2019 approaches to synthetic biology. This research will potential allow the study evolution in a new ways, develop technology useful to a number of scientific fields, and potentially shed light on the processes that allowed chemistry to become biology on the primitive Earth.\"","isTelecoms":0}
{"text":"Title: General Purpose, Form Agnostic, Robot oversight and Tele-operation Abstract: We are creating cloud-based back-end tools and services that cover things from secure access and authentication to customer facing dashboard, so that Robotics companies can quickly and securely get their robots online and better serve their customers, meaning they can focus on product differentiation and get to market faster.","isTelecoms":1}
{"text":"Title: Surface Mixed Layer at Submesoscales (SMILES) Abstract: Our current understanding of the Earth's climate is largely based on the predictions of numerical models that simulate the behaviour of, and interaction between, the atmosphere and the ocean. These models are crucially limited in their resolution, however, such that processes within the ocean that have horizontal scales of less than approximately 10 km cannot be explicitly represented and need to be parameterised for their effects to be included within the models. The purpose of this project, Surface Mixed Evolution at Submesoscales (SMILES), is to identify the potentially crucial role played by one variety of these unresolved processes, referred to as submesoscales, in influencing the structure and properties of the upper ocean, and thereby the transformation of surface water masses, within the Southern Ocean. Submesoscales are flows with spatial scales of 1-10 km that occur within the upper ocean where communication and exchange between the ocean and the atmosphere occurs. Previously considered unimportant to climate-scale studies due to their small scale and the presumed insignificance of their dynamics, recent evidence from high resolution regional models and observational studies is now emerging which suggests that submesoscales are actually widespread throughout the upper ocean and play a key role within climate dynamics due to their ability to rapidly restratify the upper ocean and reduce buoyancy loss from the ocean to the atmosphere. The impact of such a process is particularly important to the surface transformation of water masses such as Subantarctic Mode Water (SAMW), which is an important component of the Meridional Overturning Circulation (MOC) that redistributes heat, freshwater and tracers around the globe. Within the MOC, dense water masses such as SAMW are formed and transformed at high latitudes by surface processes before being subducted into the ocean interior. The properties of the subducted water masses and the tracers and dissolved gases such as carbon dioxide contained within them are vitally important to the global climate and geochemical cycles as these water masses remain out of contact with the surface over decennial to centennial timescales. \n\nIn the light of the recent discoveries concerning the ability of submesoscales to substantially influence the properties of the upper ocean, we will directly study the impacts of submesoscales on SAMW properties within the Scotia Sea. Using an integrated approach, we will both observe and simulate submesoscales within the upper ocean at a range of spatial and temporal scales, spanning from turbulence up to mode water formation. The principal goal of the study is the diagnosis of the role played by submesoscales in water mass transformation so that we can accurately incorporate these effects into climate-scale models which cannot explicitly resolve them. Our methods will entail a cruise approximately 200 miles south of the Falklands Islands at the Subantarctic Front (SAF), to the north of which SAMW is transformed, and a concurrent modelling study using a state-of-the-art global circulation model. During the cruise, we will use towed instruments to measure the length scales of variability in the temperature, salinity and related fields throughout the upper 300 m of the ocean. The data will enable us to identify the intensity and distribution of submesoscales within the vicinity of the SAF, and to ascertain the forcing mechanisms that generate them. In conjunction with the modelling component of the project, which will include both high resolution and coarse-scale simulations with the MITgcm and large eddy simulations (LES), we will assess how submesoscales ultimately impact on the properties of SAMW within the region and the ultimate effect this has on the formation of SAMW.","isTelecoms":0}
{"text":"Title: Are there different mechanisms of oligodendrocyte recruitment when new myelin is made during nervous system plasticity and regeneration? Abstract: Our central nervous system (CNS), which comprises brain and spinal cord, consists of myriads of cells that constantly interact and influence each other. Nerve cells (neurons) are the main information processing unit in the CNS, which form a network that is interconnected via long cell processes called axons.\n\nNeurons and their axons are not alone in the brain, but their function critically depends on the presence of surrounding support cells, for which the umbrella term 'glial cells' is used. One specific type of such glial cells are oligodendrocytes. Oligodendrocytes form an insulating substance around axons which is called myelin, and which is in fact the 'white' in the white matter of our brain.\n\nMyelin formation by oligodendrocytes is absolutely crucial for nervous system function. It insulates and feeds axons, and in doing so enables rapid information processing between neurons.\n\nNew myelin can dynamically be formed in the healthy CNS almost lifelong and is of importance for structural changes within our CNS that underlie learning. Damage of myelin has devastating neurological consequences and is a hallmark of demyelinating diseases such as Multiple Sclerosis (MS). Damaged myelin can get repaired in an endogenous regenerative process called remyelination. Both, myelination in the healthy CNS and remyelination in the diseased CNS are carried out by oligodendrocytes. \n\nFor a long time, oligodendrocytes have been considered a homogenous cell population. However, recent research results revealed that oligodendrocytes are diverse and have different properties and functions.\n\nTherefore, it is an important open question if new myelin formed in the healthy and diseased CNS is made by the same or by different oligodendrocytes and how this is controlled. It is important to gain knowledge of the regulatory principles that underlie these processes in order device strategies of how to specifically target oligodendrocytes when these processes naturally fail to occur.\n\nIn this proposal, we use a unique approach with which to address the question of how new myelin is made in the healthy and in the damaged CNS. We will use small tropical zebrafish as model organisms because young zebrafish are optically transparent, allowing us to investigate all oligodendrocytes in the CNS of a living animal in real time without the need of any surgical intervention. Being able to easily see how different oligodendrocytes master myelin formation in the healthy CNS, as well as remyelination in the damaged CNS, will allow us to unambiguously answer whether oligodendrocytes with similar or different properties are involved. Furthermore, because we will also analyse genetic information of the oligodendrocytes that we investigate, we will gain knowledge on how this is controlled by our genes. \n\nTogether, our work will lead to the discovery of potentially new pathways which govern myelin formation in the healthy and damaged brain; and may therefore permit the development of new strategies to specifically manipulate these processes where they fail to occur naturally.","isTelecoms":0}
{"text":"Title: ATLAS Abstract: ATLAS","isTelecoms":0}
{"text":"Title: The role of the beta2-adrenoceptor in wound scarring Abstract: Wound healing is a complex process requiring the activation of numerous processes in concert. Evolution has primed responses to heal adult wounds quickly, but imperfectly, resulting in scar formation. High levels of pro-fibrotic chemical signals in the wound promote excessive inflammation and dermal fibroblast activity and result in wound scarring. However, in the embryo, low levels of pro-fibrotic chemical signals and high levels of anti-fibrotic chemical signals temper these processes and ensure that the wound regenerates perfectly. 100 million patients in the developed world heal with a scar every year as a result of elective procedures, trauma and burn injuries, causing serious cosmetic and functional problems that can be emotionally and physically debilitating and place a heavy financial burden on Health Care Systems. There are currently no clinically tested pharmaceuticals available to prevent the occurrence of wound scarring. \n\nPreviously, I have demonstrated that a functional beta2-adrenoceptor (B2AR) network exists in the skin, but the role of the B2AR in wound scarring is unknown. Preliminary data shows that B2ARs activation alters the balance of chemical signals in the wound towards levels seen in embryonic wounds, where wounds heal without scars. Indeed, B2AR agonists reduce wound inflammation and reduce dermal fibroblast activity in wounds. In contrast, B2AR antagonists shift the balance of chemical signals in the opposite direction and enhance fibroblast activity in wounds. The ability of B2AR agonists to alter the composition of the chemical cocktail in the wound to resemble that found in the embryo, together with their ability to reduce inflammation and fibroblast activity, support their investigation as an anti-scarring treatment. B2AR agonists are known to be safe, well-tolerated pharmaceuticals evidenced by their long-standing use for the treatment of asthma and could have significant potential as a future treatment to reduce wound scarring. \n\nHere we describe a proof of concept study to determine if B2AR agonists can reduce wound scarring. We also explore the underlying mechanisms in focused studies using appropriate models to investigate these physiological processes. \nThe results will lead to a better understanding of the physiological processes of wound healing and scarring and hopefully lead to the development of a treatment to prevent wound scarring in patients.","isTelecoms":0}
{"text":"Title: Multi-Agent Knowledge Based Reinforcement Learning Abstract: Recent work has scaled up game playing Artificial Intelligence (AI) to \nworld champion performances in Go and generalised applicability to a \nwide range of early digital-games. However,\nthe focus of most work in this area has been on using AI to beat (or \noutperform) human players and not on the betterment of humans. It is our \nview that AI should augment (not automate) human\nabilities. This project focuses on the development of intelligent \nassistants for human game players in the context of multi-player games.\n\nThe main aim of this research is to apply reinforcement learning to \ngenrate an intelligent assistant, i.e., a collaborative AI that enables \nnon-player characters (NPCs) to enhance the experience of human players \nattempting a range of tasks in multi-player games. The performance of \nthe intelligent player assistant will be measured by human player \nenjoyment, immersion, engagement and performance. To do so we will \nresearch (1) imitation learning to provide a predictable companion; (2) \nreward functions for encouraging contribution towards a shared goal \ninstead of individual performance; and (3) predictive models of player \nbehaviour to identify human goals in domains with no explicit extrinsic \nreward.","isTelecoms":1}
{"text":"Title: Elucidating novel pathways and regulation of nitrogen assimilation in alpha proteobacteria exemplified by the soil organism Paracoccus denitrificans Abstract: Nitrogen is one of the critical elements that is required for all forms of biological life on Earth because it is a building block for DNA and proteins. All biological life forms must therefore have mechanisms by which they can capture nitrogen from the environment and incorporate it into important cellular components. This process is called NITROGEN ASSIMILATION. Life forms at the top of the food chain, such as Humans, assimilate nitrogen from organic nitrogen sources extracted from the plants and animals that they ingest and digest. However, some life forms lower down in the food chain, such as bacteria, can assimilate nitrogen from simple inorganic forms such as nitrogen gas, nitrate or ammonium as well as from simple organic forms such as amino acids. Many agricultural soils are rich in nitrates as they are applied by farmers to encourage high yielding plant crop production and water run-off from soils is in turn enriching rivers, lakes and oceans in nitrate. This then provides a source of nitrogen that can lead to proliferation of the bacteria that can utilise nitrate as a nitrogen-source for assimilation. In agricultural fields the diversion of nitrate towards a 'food source' for soil microbes, rather than the crops for which it was intended, is economically wasteful. However, some estimates suggest that this may be happening on a large scale. It is then timely to seek an academic knowledge base from which it might be possible to develop strategies to lessen these losses. This requires an understanding of the molecular machinery with which soil bacteria incorporate nitrogen from nitrate into cellular nitrogen in the process of NITRATE ASSIMILATION and also the means by which this process is regulated when other sources of nitrogen are present. However, under certain conditions the metabolism of nitrate in soils by bacteria takes on an added complication. If a soil becomes anaerobic, for example through water logging, some species of soil bacteria can begin to 'breathe' nitrate. Essentially, this NITRATE RESPIRATION process is an alternative to oxygen-respiration enabling the bacteria to sustain energy generation for growth. It also consumes the costly fertilisers added to soils. What then if the bacterium can do both NITRATE ASSIMILATION and NITRATE RESPIRATION? Many species of soil denitrifying bacterium can indeed do just this and so provide what amounts to a double whammy for the availability of nitrate to crops. What is not yet clear many species of soil denitrifying bacteria is how the NITRATE ASSIMILATION process is regulated and.to what extent the molecular systems involved in NITRATE ASSIMILATION overlap with those involved in NITRATE RESPIRATION. In this research programme we will address these questions using a soil bacterium called Paracoccus denitrificans. For many years this species of bacterium has been a model organism for the study of the nitrate respiration as part of a process called denitrification in which the soluble soil nitrate is converted to nitrogen gas and so lost to the atmosphere. The importance of this species as a model organism led to the United States Department of Energy providing the funds to enable the sequencing of the DNA of it's genome. This has allowed us to identify the genes that encode a nitrate assimilation system, which we term the Nas system. The study of this Nas system provides the focus for this research programme.","isTelecoms":0}
{"text":"Title: Design and modelling of piezoelectric transformers. Abstract: Jack has constructed analytical and empirical models of piezoelectric transformers, linking their equivalent circuits to their physical parameters. He has used these findings to produce a set of design rules, including loci of design parameters where performance is inhibited by unintended spurious modes. The research has been augmented with new measurement and parameter extraction techniques for practical devices. We expect the project to end with the development and proof of piezoelectric transformers for new applications.","isTelecoms":1}
{"text":"Title: Understanding the role and regulation of a tumour suppressor's oscillatory gene expression in cancer cell plasticity Abstract: Advances in breast cancer treatment mean that more patients survive cancer than ever before. However, in estrogen positive (ER+) breast cancer, the most common type of breast cancer, some patients either develop resistance to anti-estrogen therapies during the treatment itself or relapse after the end of treatment. Developing resistance to therapies means earlier mortality due to treatment failure while relapse means cancer-related loss of life a few years after the treatment regime is over. Relapse occurs due to the re-awakening of some cancer cells, which become dormant and are not targeted by conventional cancer therapy. \n\nCell plasticity is cellular phenomenon whereby cells show reversible transitions between cell states may underlie the problems of cells becoming resistant to the current therapies, and also their entry into and the exit from dormancy. But how do cells acquire such plasticity? Our hypothesis, based on our work on neural stem cells, is that cancer cell plasticity is caused by an underlying fluidity in the dynamics of gene expression. This fluidity, which can manifest itself as oscillatory gene expression, is an inherent property of some gene expression networks that are based on negative feedback, biological delays and instability of molecular components. Using these criteria in a bioinformatic screen, we have identified and validated novel oscillatory genes in a breast cancer context.\n\nIn this project, we aim first, to understand how dynamic gene expression of a key oscillatory gene that we have identified, the repressor element 1 silencing transcription factor (REST). REST is already known as a tumour suppressor but the dynamic propertied of its expression have not been studied before. We will examine whether and how dynamic REST expression leads to the creation of different cellular states within a tumour. Then, we aim to manipulate the dynamics of expression of that gene with new technologies in order to lock cells in a desired state, for example preventing dormancy or preventing exit from dormancy. Intuition and biological methods are not enough to understand complex dynamic behavior therefore we will use a combination of cutting-edge experiments and mathematical theory.","isTelecoms":0}
{"text":"Title: DTP 2021 The Rosalind Franklin Institute Abstract: Improving cryo-electron ptychography for bioimaging","isTelecoms":0}
{"text":"Title: Simultaneous Localisation and Aerial Mapping in the Built Environment (SLAMBE) Abstract: Defects in construction work cost billions globally and &gt;&pound;9bn \/ year in Great Britain alone. Spotting defects quickly and reliably is key to avoiding or reducing these costs. Current surveying\/monitoring techniques are labour-intensive, slow and prone to repeating errors. No solution currently exists to autonomously survey the inside of a construction project, where most problems are hidden (even if drones can do so externally). In this project we propose developing an autonomous drone-based solution that can quickly, cost-effectively and reliably verify accuracy of a recently built internal environment with respect to its proposed design, in order to identify construction defects. Such a service will offer big benefits to the construction industry and building contractors in particular, because, for a relatively small investment, it will help lower overall project costs and risk, while also helping increase quality, client confidence and ultimately sales.","isTelecoms":1}
{"text":"Title: Expanding the scope and scale of first-principles quantum-mechanical simulations with the ONETEP linear-scaling method on high performance computers Abstract: Computer simulations play an important part in our society e.g. flight simulators allow pilots to be trained more cheaply and safely than in the air. In science and technology, computer simulation is a powerful tool for understanding and predicting complex processes in materials. Simulations are often used alongside conventional experiments, but they can also be used when experiments are too expensive or even impossible to perform, e.g. when studying materials in extreme conditions such as the high temperatures and pressures at the centre of the Earth.The turn of the last century saw the start of a scientific revolution with the discovery of quantum mechanics (QM). On very small scales, nature behaves in a radically different way from our everyday experience. If we were shrunk down to the size of an atom navigation would become very difficult, as the uncertainty principle says that it is impossible to know at the same moment precisely where you are and where you are going! In spite of this bizarre behaviour, QM is astonishingly accurate, and provides the foundation for all our science and technology.Such claims are of no use unless the equations of QM can be solved for problems of interest to scientists and engineers today. The challenge is that the equations are very complicated - even two electrons are too much for finding a solution on paper. In a way, QM has itself provided the answer as it led to the invention of the transistor and so to the computer. However, even on the fastest computers it is only possible to solve the equations of QM exactly for small molecules, whereas the systems of interest to scientists today involve many thousands. Even the rapid and relentless progress of computer technology cannot provide the whole answer, because of the scaling of the problem.The work needed to accomplish a certain task generally increases with its size e.g. the time taken to mow a lawn is proportional to its area: if you double the size of your garden it will take you twice as long. This is an example of linear scaling, but the effort involved in many tasks increases faster than this. Sorting a set of books or CDs into alphabetical order or arranging your hand in a game of cards usually scales as the square of the number of objects involved: if you triple the number it will take nine (three squared) times as long. There are some tasks which are much worse, such as solving the travelling salesman problem to find the quickest route to visit a given set of places. Adding one more location doubles the time it takes to solve. Even if you can solve the problem for three locations in one minute, just 22 will take you a whole year. Solving the equations of QM exactly scales like this. However, in the 1960s a significant leap forwards was made with the introduction of density-functional theory (DFT), for which Walter Kohn won the 1998 Nobel Prize in chemistry. The origin of the unfavourable scaling is that electrons are charged particles. Like charges repel, so one electron's trajectory depends on all the others', as it wants to avoid them. So solving the equations which describe these trajectories becomes much harder as more electrons are involved. But the remarkable result of DFT is that the physical properties of the whole system, the answers to the questions we want, do not depend upon the details of these individual trajectories, but only on the average. So a linear-scaling solution of the equations is possible, which promises dramatically to expand the scale of quantum simulations accessible.The aim of this work is to adapt a recently-developed linear-scaling DFT code called ONETEP to take advantage of recent developments in computer technology so that it runs efficiently on the most powerful computers now available. Harnessing the power of linear-scaling methods and modern computers will allow scientists to perform simulations based on QM for systems made of tens of thousands of atoms for the first time.","isTelecoms":0}
{"text":"Title: Developing a wellbeing measure for public health evaluations: integrating capabilities and happiness Abstract: Public health programmes are considered to be complex because they often require people to change their behaviour and involve interventions that cut across multiple sectors. For this reason, public health programmes are more likely to generate a wide range of benefits, including health gains. This makes the evaluation of such programmes a challenge, particularly when compared to clinical interventions that are focused on testing a spcific drug, for example. Conventional measures used in economic evaluations focus on one dimension of wellbeing (health) and there are concerns that assessing public health programmes with such measures may be too narrow. Important benefits of the programme could be missed which could result in a failure to capture the full value of the intervention. \n\nTo respond to this challenge, there are calls to develop new methods to measure wellbeing. Two main approaches to the measurement of wellbeing have thus far gained traction: the capability approach and happiness research. Despite their promising features for the assessment of wellbeing, the use and interpretation of these approaches face significant challenges, especially in a low-income settings. This study aims to tackle these challenges and to answer the following questions: \n\n1) Do materially deprived people report high or low level of happiness? Are happiness measures developed for high-income countries suitable in a low-income context?\n2) Do these two concepts of wellbeing (capabilities and happiness) complement each other, or are they the same thing?\n3) Can we combine capabilities and happiness into a unique measure of wellbeing? \n4) Can we use this wellbeing measure for evaluating public health programmes in a low income setting?\n\nThe wellbeing measure developed during the fellowship will be able to provide a broader picture of the effects of complex public health interventions, such as mental health programmes, which are not easily captured with standard evaluation methods. While the measure is intended to support evaluators in low-income countries, the methodology developed in this study will also be of interest for researchers and policy makers in middle-and high-income countries. It will contribute to the global debate on how to measure progress in society.","isTelecoms":0}
{"text":"Title: Interactions between HIV-1 and iron Abstract: Infection with HIV-1 leads to AIDS. Around the world, the number of people infected with HIV-1 is increasing, and current forms of medicine do not adequately control the spread of the virus. There are clues in previous scientific studies suggesting that HIV-1 needs iron to grow efficiently, and we have found evidence that HIV-1 itself manipulates people?s cells in order to obtain this iron. The research proposal has two parts; the first is to find out how HIV-1 affects the handling of iron by infected cells. The second is to find out if deliberately altering how infected cells obtain iron can reduce the spread of HIV-1. Together the two sections should increase our understanding of the HIV-1\/AIDS problem and may suggest more effective methods of controlling the virus.","isTelecoms":0}
{"text":"Title: Bone analogue phantoms: redefining standards in patient specific MRT dosimetry Abstract: Molecular Radiotherapy (MRT) is a relatively common procedure in counties with developed healthcare systems. In this\nprocedure, a labelled radioisotope is administered to the body in order to irradiate and kill tumour cells whilst sparing the\nsurrounding healthy organ tissue. In the UK alone, there are some 200 departments performing over 11000 MRTs annually\nand ~200,000 therapies in some 28 EU countries.\n\nIn a recent development towards personalised healthcare, a new EU directive 2013\/59 was introduced which requires that\nall Member states performing any form of radiotherapeutics (including MRT) must provide dosimetry treatment planning for\neach patient by 6th February 2018. Although this may sound like an obvious situation, MRT has in fact been used clinically\nfor around 75 years with no fully established dosimetry practice for calculating the absorbed dose delivered to tumour\ntargets or to organs at risk. Even though the general steps have been agreed, there still exists a wide variation in the\ncurrent acquisition, quality and treatment of images used to determine dose. As a result, treatment protocols have often\nevolved locally, based on experience with a relatively small numbers of patients. Although such patients would all have\nreceived similar administered activities, the actual dose received to particular organs could have large variations.\n\nAs a consequence of the complexities involved, the application of radionuclide dosimetry has been restricted to those\nacademic groups with the facilities to develop in-house techniques. Very few therapy centres currently can validate dose\ncalculations to a known level of accuracy and only a few academic therapy centres can perform MRT Monte Carlo (MC)\ncalculations. Our group, established between The University of Manchester and The Christie, has developed the ability to\ndeliver this within a very large MRT practice. We were recently selected to lead the EU work on validating dose calculations from simulated patient phantoms and physical 3D printed phantoms in the EMPIR MRTDosimetry project (2016-19). The\nproject will provide a standardised European framework for clinical implementation of MRT dose planning. In our approach,\ndeveloped with an STFC Mini-IPS grant, 3D-printed patient analogues (phantoms) are constructed based on patient CT\nimages. This novel technique has clear potential to provide the foundation of a clinical service to provide a basis for\nimproved activity quantification to all clinical centres and MRT patients in the UK.\n\nWe are uniquely positioned to deliver this work, having access to a large data base of MRT patient data at The Christie.\nWorking with these data, we can provide the foundation for establishing a future national clinical service. The Christie has\nthe experience in both MRT dosimetry research and in providing training and support for a national clinical service\n(PET\/CT) required to provide a MRT dosimetry service. In addition our collaboration has strong links with industry, in\nparticular Hermes Medical Solutions Ltd, a leading provider of nuclear medicine workstation software. By developing a\ncomprehensive validation methodology for clinical dosimetry systems, and thereby demonstrating that the HERMES\ndosimetry system meets this standard, our collaboration will be able to provide a de-facto validation standard for clinical\ndosimetry systems and a market leading package. These links provide a pathway to distribute the techniques to the wider\nEU and international nuclear medicine market. In turn, this improves patient outcomes by allowing modification of therapy\nbased on disease response and also benefits the healthcare provider by maximising outcome for the same or reduced\nresource.","isTelecoms":0}
{"text":"Title: An investigation of socially-mediated emotional transfer in the chicken Abstract: To ensure good animal welfare we need to identify, and then take steps to alleviate, causes of possible distress. Much research has focussed directly on physical, environmental and social situations that are distressing to laboratory or farm animals. Our proposed research takes a different angle and addresses the possibiity that animals might additionally experience distress when their own situation is good, but when they witness distress in others. In its most advanced form, this capacity might be called empathy, implying that the witness understands the reasons for its companion's distress. In humans, and perhaps great apes, such advanced abilities to understand the plight of another may promote positive social behaviour or &quot;helping&quot;. However, the roots of empathy probably lie in a set of much simpler, building block, processes. One of these building blocks is emotional matching, also called emotional transfer or emotional contagion. These terms refer to situations where physiological or behavioural signs of distress in one animal to trigger a shared or matching response in an observer. In human infants emotional transfer is shown when the crying of one baby produces a similar crying response in others nearby. \n\nOur recent work has shown that, under some circumstances, chickens show this type of emotional transfer. We found that mother hens react strongly and consistently (with changes in heart-rate, comb-temperature, vocalisations and other behavioural changes) when their chicks receive a mild air-puff. The aim of this research is to discover much more about the situations under which this emotional transfer takes place in chickens. The research will be useful in clarifying a field of research where results can often be over-interpreted and advanced abilities claimed when they may not really exist. But the research also has important animal welfare implications. If animals are upset by seeing distress in others this may guide our veterinary, transport or even slaughter practices. It is also possible that animals in a poor state of welfare are more likely to show emotional transfer, leading to harmful outbreaks of group panic. \n\nWe will address a number of fundamental questions in small-scale experiments with chickens: \n- does the observing hen find it unpleasant to witness distress in her chicks? \n- does emotional transfer occur when the observing hen is in a good emotional state herself, and when she &quot;knows&quot; she is in no personal danger? \n- does emotional transfer help the observing hen to acquire important information about pleasant and unpleasant situations? \n- to what extent does emotional transfer depend on the strength of the social relationship between the observing hen and the individual (chick or adult chicken) that receives the mildly unpleasant stimulus?\n- is emotional transfer more likely if a hen is in a poor welfare state? \n\nTaken together these studies will shed new light on the extent to which non-primate animals may share emotions. Although our laboratory studies will not directly inform policy decision on animal handling, transport or slaughter, the results will be highly relevant to these areas, and will therefore provide a platform for more applied studies on farms, laboratories and abattoirs.","isTelecoms":0}
{"text":"Title: HOMEs under the microscope: Citizen-led characterisation Of airborne micropLAstic sources (HOME Co-LAb) Abstract: The negative impact of plastics on the marine environment are relatively well understood, and both Stockholm and Basel Conventions aim to limit its impact, however, little attention is paid to their presence in air. Evidence from the sparse literature show that microplastics abound in air, from densely populated urban environments to remote environments such as the Arctic and fibrous microplastics predominate. Their origin is unknown. Indoor exposure to airborne microplastics through inhalation is a potentially significant health risk, increasing the risk of COPD. In one study, plant and plastic fibres were identified in 97% of malignant lung specimens. Clothing accounts for 75% of all textiles bought in the UK and is known to release significant quantities of microplastics into the watercourse when washing. We hypothesise that clothing is also releasing significant quantities into the air during drying and use. An outline of our science and engagement approach is set out below. Engagement Design: The project design allows different levels of engagement, with high engagement citizens undertaking the pilot's developmental and stress-testing Phase 1, which is intended to facilitate interaction in Phase 2 with those citizens preferring a low-engagement approach. This approach of using highly engaged citizens to create opportunities for others with low-engagement preferences is designed to allow for engagement with a broader cross-section of society and maximise sample collection. The project will evolve across two phases. Phase 1 (Pilot): The purpose of this phase is three-fold. First, collect initial microplastic samples from a range of different domestic settings; second, to test the accessibility and quality of various clip-on microscopes, and to develop the python-based automated image analysis platforms for the analysis of samples; and third, to obtain feedback from citizens on these points with a view to improving the method for a wider roll-out. Citizens will be recruited via community partner networks. Samples will also be returned to UWE for further analysis by Raman spectroscopy, a spectroscopic technique typically used to provide a molecular structural fingerprint by which molecules can be identified, to determine microplastic composition. Phase 2 (Bristol and Bradford roll-out): This phase will see the roll-out of the piloted and refined sampling, analysis and reporting approaches to the Bristol and Bradford areas. Citizens will collect data using the passive sampling and analysis approaches developed in Phase 1 and analysis will be undertaken using a bespoke image processing tool and analysed further by Raman spectroscopy. In addition, citizens will interact with industry to understand their perceptions of plastic use, clothing treatment and current behaviour patterns. These phases will be delivered across three work packages, summarised here and set out in more detail within the case for support. WP1: This work package will focus on the recruitment of citizens from a range of community groups, ensuring that participation is a positive, enjoyable and informative experience and establishing a two-way dialogue between project members and participants. WP2: Focuses on the development and implementation of the sampling and analysis approach. This work package will, with the aid of citizens, test the sampling procedures, develop an online platform for citizens to analyse their samples and allow the Raman sample preparation and analysis to be refined. The outcome from this work package will be an understanding of both particle count, shape and microplastic composition. WP3: Brings together citizens and the clothing industry, a key stakeholder in the field of airborne microplastics, through a two-way dialogue, to co-develop policy recommendations leveraging the full potential of citizen science to drive bottom-up change.","isTelecoms":0}
{"text":"Title: Strengthening South Africa's health system through integrating treatment for mental illness into chronic disease care (Project MIND) Abstract: Integrating mental health care into primary health care services could reduce the impact of both chronic communicable and non-communicable diseases (NCDs). Like many low- and middle-income countries (LMICs), South Africa (SA) faces the challenge of how to reduce the high prevalence and impact of communicable diseases and NCDs, including mental disorders where limited services are available. Mental disorders are important to address among patients with chronic diseases as these problems are associated with poor adherence to treatment, more rapid disease progression and treatment failure. As treatment failure increases the use of health services and health service costs, chronic disease care in LMICs must be expanded to include mental health care. The integrated delivery of mental health services and chronic disease care has been shown to not only improve access to mental health care but also the mental health of patients living with a chronic disease. . \n\nYet, limited knowledge of how mental health care can be integrated into chronic disease services in ways that are acceptable to patients and providers and feasible to implement with few resources has delayed the integration of services in SA. The provision of integrated mental health and chronic disease services has also been delayed by questions about whether services should be vertically or horizontally integrated. Vertically integrated services are delivered at the same location, but mental health and chronic disease services are provided by separate cadres of health workers. Horizontally integrated services are delivered at the same location by the same staff are responsible for mental health and chronic disease care. The goal of this project is to answer these questions by assessing current capacity and barriers to integrating mental health services into chronic disease care and by comparing the effectiveness and cost-effectiveness of a vertically and horizontally integrated model of service integration among patients receiving treatment for HIV or diabetes and who are at risk for treatment failure in Cape Town, SA. Through this project we hope to identify a feasible, acceptable and effective model for integrating mental health services into chronic disease care that is applicable to other LMICs. Findings from this study are likely to be highly relevant for use in other LMICs given similarities between the burden of disease, treatment populations, and treatment systems in SA and other LMICs.\n\nThe study will comprise two phases. In the first phase, we will conduct in-depth interviews with a range of healthcare providers in HIV and diabetes services to assess barriers to integration and the feasibility and acceptability of our proposed models of service integration (Aim 1). Findings from this phase will be used to adapt our evidence-based mental health service package for optimal integration into chronic disease services. In phase two, a clustered randomised controlled trial will be conducted. We will select 24 HIV and 24 diabetes clinics to randomise to a vertically integrated arm, horizontally integrated arm, or treatment as usual (no integration). We will recruit 25 patients at risk for treatment failure from each of these clinics (total 1200 patients). After study enrollment, a baseline assessment will be completed by a fieldworker. Participants recruited from clinics randomised to either the vertically integrated or horizontally integrated arm will then receive their intervention sessions. All participants, irrespective of their intervention arm, will be tracked for 6- and 12-month follow-up interviews. At these interviews, fieldworkers blinded to their intervention arm will re-administer the baseline assessment and biological specimens will be collected to assess for chronic disease outcomes. Findings from this phase will be used to evaluate the relative effectiveness and cost-effectiveness of our proposed models of service integration (Aims 2-3).","isTelecoms":1}
{"text":"Title: Global Study of Thalassaemia Abstract: The inherited disorders of haemoglobin are by far the commonest genetic diseases and will cause an increasing global health problem in the future. This programme is directed at trying to develop better ways of estimating the true global burden of these diseases, and, in particular, better to understand the reasons for why some of them are so remarkably diverse despite being due to the same genetic defect. A better understanding of these mechanisms are absolutely critical to improving the future management of many of these diseases in the developing countries.","isTelecoms":0}
{"text":"Title: Monitor the free-living physical behaviour of lower-limb prosthetic users Abstract: The aim of this project is to develop a system that can monitor that can provide detailed information on the free-living physical behaviour (PB) of lower-limb prosthetic users, both below-knee and above-knee, and to deploy this system in an LMIC partner. The system will\nneed to be able to be embedded in the prosthesis, record for a minimum period of six-months and communicate with a mobile phone device to enable data transfer to a smartphone and hence to a database in the cloud. The system will be based on the activPAL family of devices, produced by PAL Technologies Ltd (Glasgow).\nTo achieve this we envisage the following work:\n1. Follow on literature review from a GCRF project, looking at outcome measures for lower-limb usage and activity.\n2. PPI work leading to device specification. This include potential outcomes like loading, turning, stair climbing etc.\n3. Development of algorithms for calculation of outcomes \n4. Development and\/or refinement of communications protocol (device to mobile phone app) \n5. Testing and evaluation of algorithms in UK amputees 6. Refining algorithms and test communications protocols 7. Testing and evaluation of deployable system in amputees in LMIC partner","isTelecoms":0}
{"text":"Title: University of Sheffield and CW Fletcher &amp; Sons Limited Abstract: To explore, develop and embed novel data-driven methods into the aerospace and nuclear manufacturing systems to increase throughput, resolve production bottlenecks and minimise waste.","isTelecoms":1}
{"text":"Title: Analytical properties of scale functions Abstract: Levy processes may be thought of as a class of models that describe the motion or path of a randomly moving particle which may diffuse or undergo independent random jumps whose order of magnitude may be both arbitrarily large or arbitrarily small. Levy processes have several distributional properties built in to their random structure that make them particularly attractive to work with as a mathematical tool when building and analyzing certain themes from within the field of applied probability.One particular class of Levy processes which has proved to be particularly popular from the point of view of applied probability are those which undergo jumps only in the negative direction. For this class of process recent developements in the last 10 years or so in their fluctuation theory has produced many distributional identities regarding the way in which such process (and variants thereof) move around in space (for example the probability that the process when starting at the origin hits a prespecified point below the origin). Principally these identities pertain to a field of mathematics known as potential analysis. Many of these identities are expressed in terms of functions known as `scale functions'. The main drive of this proposal is to obtain a firmer understanding of the analytical properties of these scale functions: smoothness, convexity\/concavity and their role as a basis for solutions to certain linear systems whcih appear frequently in applied probability. Following the ever growning use of scale functions in the literature, the proposed study would make scale functions an even more robust mathematical tool to work with in the future. The proposal requests funding for an academic exchange between the PI and Prof. R. Song in the US who is an expert in the field of potential analysis and Levy processes.","isTelecoms":1}
{"text":"Title: Retinal prosthetics: a novel opto-bionic approach to the restoration of functional vision. Abstract: Hereditary degenerative diseases, collectively classed as retinitis pigmentosa (RP) affect the rod and cone photoreceptors and are the second largest cause of blindness in the developed world. These conditions may be characterised by a catastrophic loss of the primary light sensitive cells in the outer retina. Most common are rod-cone dystrophies, where there is initially a loss of peripheral vision followed by a decay of central vision leading to total blindness. Age-related macular degeneration (AMD) and diabetic retinopathy (DR) are fast becoming the most prevalent forms of blindness. In AMD central vision is affected, and it is now the commonest cause of blindness in the western world in the over 60's. It is predicted that there will be a significant healthcare crisis as the population is ageing and AMD is prevalent. Sufferers of RP, AMD and DR generally all retain a normal optic apparatus and a viable population of retina ganglion cells that form the optic nerve \/ the communication superhighway to the visual cortex. These features raise the possibility that clinical prosthetic intervention could bypass the diseased tissue and stimulate the remaining healthy cells, a strategy that avoids the complexities associated with repairing the degenerate retinal tissue Attempts to date in this area have come in two forms: subretinal implants which attempt to stimulate the remaining neural processing layers of the degenerative retina, and epiretinal implants which have attempted to stimulate the retinal ganglion cell layer directly. While there is some progress in these areas, and recently even clinical trials, there are four substantial problems that this technology has yet to fully address:1) Surgical access and biocompatibility2) Long-term efficiency of information transfer from the physical prosthesis to the RGCs, leading to high stimulation current requirements3) The lack of spatial resolution associated with the very low density of electrodes available using current technology4) The inability of the current technologies to approach restoration of near macular function, because of the lack of retinotopic mapping of the afferent ganglion cell bodies in the vicinity of the optic diskOf all these issues the most serious is the energy power consumption required per electrode to stimulate ganglion cells. Required currents can be as high as 2mA meaning that the large pixel arrays required for recreating images would require unfeasible quantities of energy. A recent development that opens the possibility of a new paradigm in vision restoration technology has been the discovery that a small percentage of RGCs (&lt;0.1%) are themselves directly light sensitive. They overcome the problems of light detection in RGCs by employing a novel opsin photopigment that is quite different from rod and cone opsins. The function of these photoreceptive RGCs appears to be the regulation of time-of-day dependent photoresponses such as circadian entrainment rather than generating visual images. More recently there have also been developments in other opsin systems such as channel rhodposin and nanoparticle light stimulation.Mark Hankins has been expressing and characterising melanopsin in neuronal cell lines. In addition Patrick Degenaar has been investigating alternate methods of nanoparticle stimulation which does not involve genetic engineering. This, combined with our experience in the development of intelligent imaging chips and retinal algorithm development, gives us a great opportunity to develop a whole new class of retinal prosthesis. A photostimulation-based prosthesis can be external, not suffer the power problems of electrical stimulation, and be easily tuned and upgraded.Using light to couple an intelligent retinal processing system to the surviving retinal ganglion cells represents an important and significant paradigm shift in field of retinal prosthetics.","isTelecoms":1}
{"text":"Title: Bovine and human TB: probing the genetic, molecular and structural basis of lipid-mediated pathogenesis mechanisms. Abstract: Tuberculosis is one of the greatest causes of death due to an infectious disease worldwide (joint with HIV). It is caused by members of the Mycobacterium tuberculosis (MTB) complex, which demonstrate 99.9% similarity at a nucleotide level (Boddinghaus, B. et al., 1990) yet differ greatly in their host trophism and pathogenicity. This project will focus mainly on the evolution of members of the MTB complex. One approach will involve delineating differences between two members, Mycobacterium tuberculosis (M. tuberculosis) and Mycobacterium bovis (M. bovis) through the generation of knockout recombinant strains that represent intermediates in the evolution of these pathogens; these strains will be employed in infection studies. A second approach involves the utilisation of differing cell lines in similar infection studies, due to the tissue trophism observed during mycobacterial infection. Finally, a third approach will involve delineating the fundamental processes that drive pathogenicity, to determine the differences between non-pathogenic environmental pathogens from pathogenic members of the MTB complex.","isTelecoms":0}
{"text":"Title: Sense of self, social functioning and response to multidisciplinary treatment for chronic pain Abstract: As an acute response to noxious stimuli, pain prompts vital behaviour aimed at avoiding or limiting further damage. In many cases, however, pain endures beyond the healing process, or occurs in the absence of tissue damage and other pathophysiological causes. Pain lasting longer than 12 weeks is defined as chronic pain (CP). Every year, over five million people in the UK develop CP but only two-thirds recover. \nDespite the personal and societal impact of CP, surprisingly few studies have considered why so many patients do not respond to conventional psychological treatments. High initial pain intensity, depression, fear-avoidance beliefs and pain acceptance are all factors that have been associated with differential response to PMPs but the evidence is mixed and further research is urgently needed to improve treatment options.\nThe aim of the proposed research is to test a novel model of treatment response in CP. The model is derived from psychodynamic-interpersonal therapy, which has an evidence based for treating other pain conditions but has not been studied in relation to CP. According to this model, people will be less likely to respond to treatment if they have a poor sense of themselves and problems forming supportive relationships with others, which together undermine their ability to access social support and use self-management strategies.","isTelecoms":0}
{"text":"Title: STAMINA: Strategies to Mitigate Nutritional Risks among mothers and infants under 2 years in low income urban households in Peru during COVID-19 Abstract: Peru's progress in combatting malnutrition may be reversed with the current COVID-19 pandemic which has caused disruption of maternal and infant nutrition services, closure of health centres and rising unemployment. Peru has experienced one of the highest mortality rates from COVID-19 in South America. Deteriorations in infant nutrition will lead to poorer health outcomes for the next generation. Government and community stakeholders in Peru have highlighted the unknown impacts of the pandemic on the nutrition of mothers and their infants and young children.\n\nThis study will examine how the COVID-19 response is impacting on the nutritional risks of mothers and infants (aged 0-23 months) within the household setting in low-income areas of two cities, Hu&aacute;nuco and Lima. This information will be compared with detailed nutritional assessments conducted in the same communities immediately before the national State of Emergency due to COVID-19. To address the emerging nutritional risks, we will work with stakeholders to co-create adapted methods for the delivery of nutritional services including iron supplementation and support for exclusive and continued breastfeeding. \n\nWe will identify the nutritional risks resulting from the COVID-19 pandemic by examining short, medium and longer term changes in:\n\n- exclusive breastfeeding rates for infants aged 0-6 months; continued breastfeeding for infants aged 6-23 months, and the extent to which WHO recommended complementary feeding practices are being met. \n\n- the uptake of iron supplementation in infants and young children - a national priority to combat anaemia - in the context of the disrupted health services and new delivery strategies implemented since the pandemic. \n\n- household food security, maternal psychological wellbeing, and changing quality of diet in relation to nutritional risks of undernutrition as well as overweight and obesity at the household level.\n\n- how household dietary practices adapt and respond to the ongoing pandemic.\n\nWith these insights, we will co-create support systems for the design or adapted delivery of nutritional counselling, growth monitoring and iron supplementation for infants and young children using information and communication technologies or socially-distanced health services. \n\nWe will work with UNICEF Peru as a project partner in order to ensure that efforts to address malnutrition target the most vulnerable groups and are tailored to the challenges experienced by urban communities which make up the majority population of Peru.","isTelecoms":0}
{"text":"Title: The University of Sheffield And Land Instruments International Limited Abstract: To develop novel multi-colour radiation thermometry for use in the range of radiation thermometers and line-scanning thermal imaging cameras.","isTelecoms":1}
{"text":"Title: ALPHA Agriculture - Cloud integrated cameras for agriculture Abstract: This project entails the construction of the ALPHA AI cloud platform for the precision agriculture sector. FOTENIX currently produces multispectral 3D cameras with particular use cases, e.g. disease detection in strawberries. The products are developed in conjunction with machinery\/robotics providers and trained on trial data before being deployed in the field. This project focusses on a cloud architecture to sit between the camera systems and the customer's dashboard, which will enable an additional revenue stream that supports the translation of FOTENIX's software and data analytics capabilities to its customers (machinery) and end-users (growers).","isTelecoms":1}
{"text":"Title: M-PHiL Study - Mental and Physical Health in Lambeth Abstract: The MRC 2010 review of mental health research underlined the importance of understanding the links between physical illness and poor mental health and noted the difficulties faced by some patients in obtaining satisfactory treatment when mental and physical conditions co-occur. The report called for an improvement in access to anonymised data based on NHS contact &quot;for example, by data linkage across cohorts&quot;.\nWe plan to link Lambeth Data Net (LDN) established by Lambeth Primary Care Trust (PCT) containing the primary healthcare records from patients from all but two GP practices in the London Borough of Lambeth (population ~ 300 000) with CRIS, the Case Register Interactive Search system containing the entire electronic patient record of the South London &amp; Maudsley Trust, the sole provider of NHS mental health services to patients in Lambeth (n=180000 of whom 36 000 live in Lambeth). The Caldicott Guardians for SLAM and for Lambeth PCT have both already approved the linkage plans. Each dataset has been linked before - LDN with primary care databases in east and south-west London and CRIS with the Thames Cancer Registry and Hospital Episode Statistics data. The study will be based in the Biomedical Research Centre for Mental Health, recently given a national leadership role to develop e-health for research in recognition of the advances made by CRIS.\nThe aim of the study is to generate a unique resource to improve research into the course and outcomes of mental ill health. Specifically our objectives are: [1] to create a one-off link between two established datasets containing information on the health of an entire London borough [2] to demonstrate the utility of this new dataset by using it to examine in detail why some patients with severe mental illness have excellent physical health and some very poor physical health [3] to develop the methods to be able to update the linkage so that the impact of any interventions we might develop from the proposed work can be assessed in real time.\nAddressing health inequalities is a major area of interest both nationally and locally within London. Patients with severe mental illness such as schizophrenia have worse physical health than the general population- in south London we have shown that patients with severe mental illness die up to 17 years early. Whilst we know that on average patients with severe mental illness have more risk factors for poor physical health &amp; they seem less likely to be offered the best medical care in hospital, we know little about which individual factors (e.g. ethnicity), disease factors (e.g. medication) and systemic factors (e.g. single-handed GP) are associated with good and bad physical health. Creating from scratch a dataset detailed enough to answer these questions would be prohibitively expensive but by linking two datasets comprising routinely collected data on the whole population (~36 000 in both datasets) we have sufficient data on sufficient individuals to address all these important issues.\nIn meeting the challenges thrown down by the 2010 MRC Review head on, our proposal has the potential to deliver both clinically and academically. Our study, linking the complete primary care and mental health records of one ethnically diverse London borough, is population-based and uses datasets specifically designed to enhance ease of access and which have themselves already produced major research findings. Our study will produce a methodological template for other groups wishing to exploit the possibilities of data linkage, a linked dataset that can be interrogated to address multiple issues of physical and mental comorbidity locally and beyond, and will provide a structure to monitor any interventions arising from such analyses almost in real time.","isTelecoms":0}
{"text":"Title: To be determined Abstract: Project to be determined after 6 month rotational period.","isTelecoms":0}
{"text":"Title: FENTEC - Functional Encryption Technologies Abstract: Functional encryption (FE), has been recently been introduced as a new paradigm of encryption systems to overcome all-or-nothing limitations of classical encryption. In an FE system the decryptor deciphers a function over the message plaintext: such functional decryptability makes it feasible to process encrypted data (e.g. on the Internet) and obtain a partial view of the message plaintext. This extra flexibility over classical encryption is a powerful enabler for many emerging security technologies (i.e. controlled access, searching and computing on encrypted data, program obfuscation\u2026). \nFENTEC\u2019s mission is to make the functional encryption paradigm ready for wide-range applications, integrating it in ICT technologies as naturally as classical encryption. The primary objective is the efficient and application-oriented development of functional encryption systems. FENTEC\u2019s team of cryptographers, software and hardware experts and information technology industry partners that will document functional encryption needs of specific applications and subsequently design, develop, implement and demonstrate applied use of functional cryptography. \nUltimately, a functional encryption library for both SW and HW-oriented application will be documented and made public so that it may be used by European ICT entities. With it, the FENTEC team will build emerging security technologies that increase the trustworthiness of the European ICT services and products. Concretely, the FENTEC team will showcase the expressiveness and versatility of the functional encryption paradigm in 3 use cases:\n\u2022 Privacy-preserving digital currency, enforcing flexible auditing models\n\u2022 Anonymous data analytics enabling computation of statistics over encrypted data, protecting European Fundamental Rights of Data Protection and Privacy\n\u2022 Key and content distribution with improved performance & efficiency as foundational technology for establishing secure communication among a vast amount of IOT devices.","isTelecoms":1}
{"text":"Title: Studying generalised Thompson's group with tools from geometric group theory and operator algebra Abstract: Many mathematical concepts first arose in descriptions of physical systems, and later took on a life of their own after they proved to be deep and relevant for other areas of mathematics. A remarkable insight of Heisenberg in 1925 suggested that the observables of a quantum system could be realised as infinite matrices satisfying certain commutation relations. This did not really make sense at the the time, but mathematicians quickly developed the necessary tools, and now we know that he was really talking about operators, which are linear transformations on a vector space, and his insight was that this vector space had to be infinite-dimensional. Thus mathematicians were led to the study of operator algebras, which is now a vast area of mathematics that influences many other areas of mathematics, such as group theory, ergodic theory, dynamics, geometric topology, differential topology, noncommutative geometry, logic and set theory, and number theory.\n\nWe shall study this connection with group theory from a group theorist's point of view: a group is a mathematician's tool to capture the notion of symmetry in the abstract. The study of symmetry provides a powerful guiding principle in a wide varietyof research problems not only in operator algebra, but in many areas of mathematics and the sciences. For that reason applications of groups abound in these fields.\n\nThe study of examples is essential to the general understanding of the theory. One class of examples in particular are R. Thompson's groups F,T and V and their generalisations, which exhibit some very surprising properties, and, for the past 50 years, have been studied extensively in a wide variety of mathematical subjects: homotopy theory, dynamical systems, infinite simple groups, the word problem, group cohomology, logic and analysis. For instance, Thompson's groups provided the first known examples of infinite, finitely presented simple groups. Since then, Thompson's groups and their various generalisations have generated a large body of research trying to understand their properties, some of which are not completely settled.\n\nOne powerful approach to generalised Thompson's groups is their description as automorphism groups of certain Cantor algebras; under some mild conditions one can use this viewpoint to apply discrete Morse theory to determine cohomological finiteness properties of these groups. On the other hand, many of the generalised Thompson's groups can be viewed as topological full groups of a Cuntz algebra. This was recently generalised to include groups that are obtained from higher-dimensional graphs. Hence tools including groupoid homology and the K-theory of the groupoid C*-algebra have become available.\n\nThe purpose of this project is to develop a comprehensive dictionary between the two approaches to be able to answer open questions arising in both fields. For example, we expect to apply Morse theoretic methods to the groups arising from higher rank graphs to determine their cohomological finiteness conditions. On the other hand, tools like groupoid homology promise to be helpful when distinguishing isomorphism types of automorphism groups of Cantor algebras. This project is a feasibility study designed to not only answer questions such as these but also to to develop a far reaching programme for tackling other involved problems from either area.","isTelecoms":0}
{"text":"Title: SiC Power Electronics- The Route to a Resilient Energy System (SiCER) Abstract: The improvement of the UKs energy infrastructure is critical moving into a low carbon economy. A paradigm shift in technology will be required in order to cope effectively with an ever increasing amount of renewable energy being brought online. The UK has committed to connecting 32,000 MW of offshore wind power by the year 2030 in an effort to meet ambitious (low) carbon emissions targets. It is envisaged that other forms of renewable energy e.g. tidal, solar could also play a role alongside traditional coal fired power stations and nuclear energy generation. Revolutionary changes to large (multi gigawatt) scale power conversion is indispensable if these carbon emissions targets are to be met. The objective is to enable a step change in power conversion, transmission and distribution through silicon carbide (SiC) power electronics. This will be achieved by bringing together world leading companies and academics in the fields of high voltage power electronics, semiconductor technology and power generation, transmission and distribution. The consortium will build upon existing materials knowledge, attained through academic research to deliver the project.","isTelecoms":1}
{"text":"Title: 'How do you want to do this?' An examination of Dungeons and Dragons as transformative fantasy narrative Abstract: My project will establish Dungeons &amp; Dragons' (D&amp;D's) meaningful, extensive contribution to fantasy. Examining how D&amp;D has transformed fantasy literature since its creation in 1974, this project will use D&amp;D as a lens to investigate how contemporary fantasy narratives are generated, influenced, and (re)shaped within multiple communities of practice. A collaborative storytelling medium revolutionised by digital technologies, D&amp;D exemplifies a mode of fan-made narrative which empowers reader-led definitions of fantasy, typically resisting the genre norms it is presumed to epitomise. This investigation will explore, taxonomise and analyse the transformative properties of the narratives D&amp;D gameplay enables readers themselves to produce.","isTelecoms":0}
{"text":"Title: Size Matters: Determination of critical control parameters for assay performance Abstract: Over 250 million antibiotic prescriptions are issued annually; nearly half are done blindly. Incorrect prescriptions lead to drug resistant infections, which kill 1.2 million people annually and will kill more people than cancer by 2050\\. FluoretiQ's mission is to provide clinicians with rapid tests to make their first antibiotic prescription, the right prescription. Our rapid testing platforms (NANOPLEX &amp; SCFI) reduce diagnosis and antibiotic selection turnaround time from days to minutes, making the first prescription, the right prescription. NANOPLEX is an advanced latex agglutination test that uses glycan probes and machine learning to identify and quantify bacteria in 15 mins rather than 2 days, with over 90% accuracy. The first of our products is (codenamed) P5; a 15-minute diagnostic test from the NANOPLEX family. P5 addresses the unmet need for accurate point of care testing of urinary tract infections (UTIs) that affects 150 million people globally each year. P5 will provide a clear treat\/do not treat evidence from the first consultation. P5 identifies the most important uropathogens.\n\nFor this project, FluoretiQ will collaborate with experts from the National Physics Laboratory (NPL) and Newton Gateway to Mathematics (Newton) to create a mathematical model of the NANOPLEX assay which will help identify additional control parameters for maintaining performance of the test.","isTelecoms":1}
{"text":"Title: An existence not a life: Investigating human rights violations against learning-disabled and autistic children and young people engendered by current Abstract: This research project draws on social science research methods and a participatory approach to understand the limitations of the existing legal framework which governs the treatment of learning-disabled and autistic children in assessment and treatment units. It aims to provide an academic evidence base for policy change which has a foundation in the experiences of the child stakeholders. The applicant has long standing connections with the learning disabled and autistic community, and a clear understanding of the ethical issues that underpin this research. She will be supported in navigating these issues and optimising the research outcomes by Dr. Simon Hoffman and Dr. Anthony Charles, both of whom have relevant expertise in this and related fields","isTelecoms":0}
{"text":"Title: Connecting Ca2+ and cell migration to development and cancer Abstract: Changes in the concentration of cytosolic Ca2+ drive a multitude of cellular events from those at the very start of life (fertilization), through development and ultimately to those culminating in cell death. These Ca2+ signals often initiate from intracellular Ca2+ stores which includes a variety of acidic organelles such as lysosomes referred to as &quot;acidic Ca2+ stores&quot;. Defective signalling through acidic Ca2+ stores has been implicated in a number of disorders including Parkinson disease highlighting the need to understand organellar Ca2+ transport and the cellular processes that it regulates.\n\nThe neural crest is a transient, migratory population of cells found in all vertebrate embryos that differentiate into a wide range of cell types, including neurons and glial cells of the peripheral nervous system and cartilaginous and skeletal elements in the head. Understanding the mechanisms driving migration is critically important to understand not only morphogenesis but also cancer metastasis - a process to which neural crest migration is often likened.\n\nThis project builds on our very recent findings that have identified novel Ca2+ transporters on acidic Ca2+ stores and shown that they regulate migration of neural crest cells in vivo. The overall aim is to combine expertise in endo-lysosomal Ca2+ signalling (Patel) and cell migration (Mayor) to further test the hypothesis that acidic Ca2+ stores are required for cell motility. \n\nThe student will use both chemical and molecular methods to manipulate Ca2+ signaling proteins and examine the effect on cytosolic Ca2+ and migration. This will be achieved using a range of molecular cell biology and imaging approaches, amphibian neural crest cells to study cell migration in vivo, and neuroblastoma, one of the most common childhood cancers, for in vitro analyses.\n\nThe successful outcome of this project will provide urgently needed molecular insight in to the mechanisms of endo-lysosomal Ca2+ signalling and cell migration during (patho)physiologically relevant processes.","isTelecoms":1}
{"text":"Title: Biological photochemistry for chemical synthesis Abstract: This project will develop biological photochemistry, using proteins as catalysts for new chemical transformations under visible light irradiation. Chemical photoredox catalysis has changed the way molecules are made in recent years, using simple visible light sources in combination with metal catalysts to mediate electron transfer reactions. Fundamental limitations of the approach, however, exist in the form of reliance on precious metal catalysts, and serious difficulties associated with control of absolute stereochemistry. We aim to develop biological photocatalysts that use organic photoredox cofactors, with the chiral active site of the protein creating possibilities for enantioselective reactions.\nThe project will take place in the Greaney (chemocatalysis), Green (biocatalysis and enzymology), and Hay (biological photophysics) laboratories, who all share an interest in creative organic chemistry and chemical biology to solve problems in synthesis. The PhD studentship will provide comprehensive training in both chemical and biological catalysis, to develop a new approach to photocatalysis that can deliver valuable chiral building blocks under the rubric of sustainable chemistry. Students with a degree in chemistry and an interest in next generation molecule-making methods are encouraged to apply.","isTelecoms":1}
{"text":"Title: Development of advanced in situ methods for the study of heterogeneous catalysts Abstract: Heterogeneous (solid) catalysts underpin the manufacture of &gt; 90% of fuels and chemicals and the chemicals sector contributes &pound;50bn yr-1 to the UK economy. The need to develop new or improved catalysts (more efficient, selective, cheaper, greener) has never been greater, with an expanding, more developed population, depletion of fossil resources and enormous concerns about global warming. The key enabler in delivering the catalysts needed is systematic insight into the molecular \/ atomic mechanisms that control catalyst function.\n\nThis project will develop new approaches to the use of in situ X-ray and optical spectroscopies, at the analysis or resulting data. It will particularly focusing on Raman spectroscopy to provide insights into heterogeneous catalytic reactions such as selective oxidation or hydrogenation. \n\nThe project will employ purposefully synthesized nanomaterials to simplify the spectroscopy data, but also catalysts prepared through wet impregnation methods close to those employed industrially as reference materials to show the applicability of the techniques\/approaches used to real and 'idealized' systems.","isTelecoms":1}
{"text":"Title: Structure and composition of interfaces between 2D materials and dielectric substrates Abstract: The rich and exciting electronic and mechanical properties of two-dimensional (2D) materials have inspired novel ideas for post-silicon nanoelectronics. Some of the most far-reaching of them concern the possible substitution of Si with 2D materials in modern field-effect transistors (FETs) and applications in next-generation memory and neuromorphic computing chips. Success of these applications relies on solving the materials problems related to defects at interfaces between 2D materials and gate dielectrics or metal electrodes. For example, the sandwich structure of memristive devices is usually composed of an insulating active layer (e.g., transition metal oxides (TMOs)), 2D material (graphene, MoS2) and top\/bottom metal electrodes. This project will combine theoretical modelling of such interfaces with experimental investigations of their properties using hard x-ray photoelectron spectroscopy (HAXPES). Theoretical simulations of interfaces of 2D materials, such as MoS2 and WSe2, with SiO2, HfO2 and CaF2 insulating layers will be used to analyse the experimental HAXPES spectra of these systems and study the properties of point defects at interfaces. HAXPES measurements at DIAMOND and other facilities will help us to elucidate the effects of deposition and adsorbates on the chemical composition of interfaces. Theoretical calculations using both atomistic simulations and density functional theory calculations should allow us to identify interface defects as well as oxide defects near interfaces and relate them to reliability issues pertaining to FETs and mechanisms of resistive switching of oxides.","isTelecoms":1}
{"text":"Title: FLEX-RAIL - Paradigm shifts for railway \u2013 Technology uptake strategies for a lean, integrated and flexible railway system Abstract: Project FLEX-RAIL has the vision to target a lean, integrated and flexible railway system, which will stimulate further innovation within the rail sector and will ensure that rail services can address the future user needs. To achieve this, the following objectives and actions are defined:\nTo have a Forecast of evolution of key fundamental technologies, identification of technical risks and of potential blocking points project FLEX_RAIL will review relevant existing and upcoming trends, influencing factors, innovations & earlier projects on blue-sky transport system. \nTo look forward the possible achievement of the following future impacts the definition and implementation of a impact assessment framework and modelling tool for the defined rail scenario and transition pathways will be done.\nTo formulate technological concepts a future rail system scenario will be developed based on a participatory process involving all users of the rail system.The scenario will build on the analysis of trends and innovations happening in other transport sectors and of railways sector blue-sky projects and disruptive technologies.\nAssessment of the scenario feasibility, considering the transition pathways, the potential business models and the governance processes will be done to the:\n\u2022 Identification of key aspects for business feasibility  \n\u2022 Analysis of the current safety requirements and how the introduction of \u201ctrain-centric\u201d automated concept, the introduction of disruptive technologies and the digitalisation affect will change the railway safety approach.  \nConclusions, recommendations and implications for the S2R activities will end the project. \nMaximisation of impact will be achieved by interaction with other projects and dissemination with the objective to maximise the impact of the project amongst the rail sector and wider society thru co-operation with all existing bodies, parallel H2020 and S2R projects, scientific journals, trade publications.","isTelecoms":1}
{"text":"Title: Digital Prosthetics: Machine Learning and Human Challenges in Designing and Testing Next-Generation Personalised Limbs Abstract: Background and rationale :\nThis studentship proposal addresses the major challenge of inefficiency and lack of evidence base in design of prosthetic limbs, despite the opportunities offered by digital CAD\/CAM design tools and the data they generate. It is a first-of-kind machine learning analysis of prosthetic socket design and outcome data (comfort and function), informed by user-needs analysis to maximise potential for clinical translation.\n\nProsthetic socket provision will probably always be an iterative process, due to stabilisation and adaptation of the residual limb, especially in newly amputated cases (1,2). However, considerable cost, discomfort and inconvenience could be saved by reducing iteration if expert clinicians were able to make better use of carefully selected and presented data. These data might be built upon a combination of a strong base of evidence from successful past clinical practice, either from their own practice or from experienced colleagues, alongside predictive biomechanics and optimisation approaches (3). This would be intended to assist the prosthetist in the labour-intensive, low value added aspects of their work, freeing them to spend more time and focus on the final, high value added, detailed design.","isTelecoms":0}
{"text":"Title: Direct Numerical Simulation of Jets in Cross-Flow with Application to Turbine Blade Cooling Abstract: The proposed work aims to carry out a numerical study of jets in cross-flow (JICF) with application to turbine blade cooling by addressing the important dynamic vortices and turbulent mixing &amp; entrainment. Although extensive research has been done in the past few decades, there is still a lack of clear understanding of the interaction processes between the jet and the cross-flow, for example the unsteady behaviour of the vortex system. The work is of particular relevance to turbine blade cooling application, but is also of importance in other engineering problems. Recent developments in turbulence simulation and code parallelization technique make it possible to carry out a detailed numerical study by using high-accuracy, temporally and spatially resolved direct numerical simulations (DNS) technique. In this proposal, we are going to perform simulations of (1) single jet in cross-flow at three different angles (normal and inclined), and (2) multiple jets in cross-flow with in-line and side-by-side arrangements, both representing typical blade cooling configurations. Finally, high quality DNS databases including turbulence statistics will be analysed to identify the key turbulence model terms to be improved and derive useful guidelines for blade cooling designer. This project is expected to provide fundamental knowledge as well as useful datasets, and also to improve the capability of current industry CFD modelling for turbine blade cooling.","isTelecoms":1}
{"text":"Title: A systems-level evaluation of conservation agriculture within the UK Abstract: Soil degradation is one of the greatest challenges facing us today. Conservation agriculture is proposed as a means of reducing soil degradation associated with food production. Conservation agriculture is predicated on no-till management practice with direct drilling of seeds to achieve minimal disturbance of the soil combined with cover crops and the return of crop residues to the soil. The aim is to disturb the soil and its biological communities as little as possible, while facilitating them to do work that traditionally the plough and agrochemicals would otherwise do.\nThis project aims to take a systems-level approach, comparing the performance of two agricultural management systems in a replicated and randomised experiment in which the agronomy is specifically designed for each system by experts in each management practice. This project will then investigate the impacts on soil health, both at the macro and micro-scales, as well as impacts on water flow, soil erosion, greenhouse gas emissions, and carbon footprints of the two management systems. Costs and returns will be analysed to economically evaluate risks and externalities of the two systems. This multidisciplinary approach will allow an objective investigation into the environmental and economic impacts of conservation agriculture for UK farmers and society.","isTelecoms":0}
{"text":"Title: Doctoral Training Centre - Imperial College London Abstract: World class research and training in Chemical BiologyThe development of experimental and theoretical technologies for the solution of biological problemsThe establishment of engineering rules at the molecular level for systems of clinical interest...and need for the centre:The centre will address the acknowledged shortage of well-trained physical scientists capable of contributing to bioscience.","isTelecoms":0}
{"text":"Title: Aspects of Growth in Infinite Groups Abstract: We will study various kinds of growth in infinite groups, with particular focus on the growth of conjugacy classes. Benson's 1983 proof that the standard growth series of a virtually abelian group is rational with respect to any generating set introduced the idea of partitioning the language of words over the generators into 'patterned sets', which allows a linear algebraic approach to growth. The same paper also provides a criterion for growth to be rational. We hope to make use of these ideas to investigate the growth of conjugacy classes in virtually abelian groups. Other areas of investigation include growth of cosets, and relative subgroup growth.","isTelecoms":0}
{"text":"Title: Evaluation, Quantification and Identification of Pathways and Targets for the assessment of Shale Gas RISK (EQUIPT4RISK) Abstract: The project will identify, characterise and parameterise the multiple direct and indirect pathways within the shallow subsurface and the atmosphere (and across interfaces), which link sources of contamination and hazards associated with shale gas (SG) operations to human and sensitive environmental receptors, and surface infrastructure. \nFor each component of the domain (Water, Air, Solid Earth), Source-Pathway-Receptor combinations will be examined and then integrated in a probabilistic risk assessment (PRA) framework for quantification of the risks to humans, infrastructure and the environment. A key aspect of the study will be to understand how the risk profile evolves over the life cycle of shale gas operations - from single site to multiple operations across an area. \nThe focus will be on investigating the processes that affect and influence the near-surface (i.e. &lt;400 m bgl) Source-Pathway-Receptor combinations (and their interactions). Processes that will be investigated include; hydro-geochemical controls on contaminant behaviour and transport, climatological and chemical controls on air quality, and attenuation of ground motion e.g. from seismic events. The on-going environmental monitoring at the shale gas sites in North Yorkshire and Lancashire, along with their detailed conceptual and geological models will provide rich and continuous quality-assured high precision datasets and information. The sites represent different types of shale gas operation in different geo-environmental settings. Information from these sites, along with other non-UK sites where project partners have worked, will be a starting point, with additional data from UKGEO supplementing the evidence base. Analysis of these data will then support the design of experiments at UKGEO and other sites to improve confidence in process understanding and test different aspects of the risk model under controlled conditions, quantifying properties and better characterising\/quantifying uncertainty through evaluation of the sensitivity of environmental and human receptors. The experiments will also consider non-shale gas-related activities such as analogues and crowd-sourcing of information on ground movement. Attention will be given to identifying the key indicator parameters and techniques required to detect environmental changes arising from shale gas activity in both the short-term, providing early warning, and the long-term. This will include new technology tested as part of the experiments and case studies that will allow differentiation of stimulated reservoir source fluids and other contaminants from extraneous natural and anthropogenic sources in measured groundwater, soil gas or atmospheric samples. Improved measurement, monitoring and quantification will be critical to effectively evaluating and managing the risks arising from shale gas development and supporting the integrated risk model developed as an outcome of this project.\n\nThe project will address the following scientific questions:\n1) What properties, parameters, and processes (biogeochemical and physical) of the shallow subsurface and atmosphere are most important for characterizing the key Source-Pathway-Receptor linkages and combinations? \n2) What are the contaminant fluxes and physical hazard characteristics of a UK shale gas play and how do these evolve over time? What are main sources of uncertainty in such quantification?\n3) What proxies\/indicators\/measures of environmental change\/impact are most sensitive to the stresses induced by shale gas operations in the shallow subsurface and in the atmosphere?\n4) How can the risks quantified for a single site be scaled up to assess the overall risks for a fully developed wellfield comprising multiple wells and the full lifecycle of operations?","isTelecoms":0}
{"text":"Title: Effect of Nematode and Mycobacterium avium subspecies paratuberculosis Infections on the Ovine Intestinal Microbiome Abstract: Disease in the agricultural industry is a problem for farmers as it negatively impacts their income as well as reducing the welfare of their livestock. Mycobacterium avium subspecies paratuberculosis (MAP) is the causative agent of Johne's disease in sheep and found in other economically relevant ruminants such as cattle and goats. The disease is characterised by emaciation as a result of thickening of the intestinal wall, reducing nutrient absorption and causing the animal to starve despite appearing to eat normally. MAP is also known to co-occur with parasitic nematode worms such as Teladorsagia circumcincta and Oesophagostomum columbianum which can have a synergistic or mechanical vectoring effect on the disease. Farmers face many challenges when trying to control MAP or prevent it from entering their flocks. MAP is transmitted via the faecal-oral route and shed from infected animals in faeces to the surrounding environment where it can survive for over a year. Transmission may also occur via wildlife reservoirs including wild deer, foxes and rabbits. \n\nSheep will often become infected with MAP in their first few months of life either from faecally-contaminated soils, water, surfaces or shedding from their mother's milk. This infection can go undetected as many cases are sub-clinical; problems with diagnostic testing can also lead to Johne's disease being under-diagnosed. MAP is also controversially associated with Crohn's disease in humans and so represents a potential public health threat. \n\nPreliminary studies carried out by our group have shown that treating sheep with anthelmintic leads to changes in the intestinal microbiota, specifically that an unresolved nematode infection leads to reduced levels of the potentially-beneficial Actinobacteria. In other work leading up to this project, faecal samples have been collected from a flock of farm-raised sheep in Angus with co-occurring nematode and MAP infections over a three-year period, providing a longitudinal profile of the changes in the microbiota within individual sheep and the flock as a whole. These baseline data will form the reference against which the effects of worm treatment and vaccination against Johne's disease will be assessed. By studying the fluctuations in the intestinal microbiota, the effect of anthelmintic treatment on the efficacy of vaccination against MAP in farm-raised sheep will be investigated.\n\nThe project will aim to:\nCharacterise the prokaryotic component of the gut microbiota in a farm-raised sheep flock using metataxonomic DNA sequencing. \nInvestigate the persistence of MAP in soils at different locations on the study farm using qPCR and culture techniques, and link this to soil conditions, other soil microbiota and disease in the sheep which graze these areas.\nInvestigate the relationship between MAP infection, parasitic worm infection and intestinal microbiota in a farm-raised sheep flock. \nAssess vaccine efficacy against Johne's disease using diagnostic testing and microbiota profiling. \nEvaluate the impact of anthelmintic treatments on vaccine efficacy.\n\nThis information will be used as a basis for improving diagnostic and treatment strategies for MAP and nematode infection to improve animal health and welfare. \n(492)","isTelecoms":0}
{"text":"Title: IDR TOOLKIT - Inclusive Design Rating (IDR) Toolkit.  The design and assessment tool for tailoring environments for everyone. Abstract: Europe is ageing and the changing needs of the population are constantly shaping the way we live and interact in communities and environments.\nAccessibility, sustainability and inclusivity are now prominent keywords that are driving the design of products and of the built environment.\nThe United Nations, the World Health Organisation and the European Commission (through the H2020 Programme) have supported the idea that accessible solutions for improving environments can effectively support well-being & socialisation of all members of society.\nDespite the proliferation of guidelines, design approaches and regulations, there is still a significant gap in the current awareness among the general public, of accessible, inclusive designed buildings that has yet to be covered.\nThis proposal, will contribute to filling this gap by developing an Inclusive Design Rating (IDR) Toolkit that will enable stakeholders to design and certify accessible, inclusive dwellings.\nThe project will be deployed through a framework for analysing the stakeholders\u2019 point of view that will be used to co-design a certification toolkit for assessing inclusive, smart age-friendly environments. This IDR Toolkit will be used by professionals to assess the accessibility, usability and fitness for purpose of dwellings and by individuals to enable them to make decisions about how best to adapt their home to their specific needs.\nThe research will be carried out at University of Cambridge by using the Inclusive Design and the Quality Function Deployment approaches which enable the constant involvement of stakeholders in the co-design process, avoiding a top-down approach. \nThe project will have impact by increasing awareness of inclusive dwellings with a scientifically validated methodology for designing, re-designing and assessing environments suitable for the changing needs of a growing ageing population and by communicating that knowledge to a wide audience in a striking, accessible way.","isTelecoms":1}
{"text":"Title: GLACIAL IMPACTS ON LACUSTRINE ECOLOGY, GEOPHYSICAL SYSTEMS AND POLLUTANT CHEMISTRY IN THE HIGH ARCTIC Abstract: This project will utilise a multi-proxy approach to analyse lake core sediments at high temporal resolution and reconstruct a historical record of the changing glacial history and sedimentological processes affecting the study sites, sediment chemistry profiles (including the presence of a selection of nutrients, POPs, mercury and lead) and shifts in diatom assemblages (key primary producers in Arctic environments; Ryves et al., 2002). This will provide a diverse spatial and historical overview of Arctic lake sedimentation, ecosystem variability and pollutant accumulation, putting the present processes into climatic context, and providing key data to develop models on the impacts of future climate change on these freshwater ecosystems.","isTelecoms":0}
{"text":"Title: Everyday Life with Irritable Bowel Syndrome (IBS): Accessibility, Mobilities and Belonging Abstract: Irritable Bowel Syndrome (IBS) is a common health condition involving symptoms of diarrhoea, constipation, pain, wind and an urgency to use the toilet (The IBS Network, 2020). It affects up to one-third of the UK population and is one of the most commonly reported conditions seen in general practice (Guts UK, 2020). Despite the fact that IBS often has symptoms that have a profound impact on the everyday lives of those who experience it, it is often underestimated and overlooked in both public life and research agendas. Little research has advanced understandings of the social implications of living with an incredibly common, but hidden condition. For example, it has explored what it means to experience symptoms that require urgent access to a toilet in public life. My research has increased knowledge of living with IBS, how its navigated in everyday practice, and what social and political issues a focus are brought to the fore through the lens of IBS. Specifically, the research offered a contribution by demonstrating the impact that IBS can have on the places people can or cannot go, the routines and reorganisations of their working day, and the social interactions and things that come to matter when living with a common, but often dismissed, health condition. The findings include issues of toilet accessibility whether that be a visit to a friends house or a trip to the toilet on a train journey, the role of 'Can't-Wait Cards' and 'Radar Keys' that can prioritise access to toilets in public life, together with the reassurances gained from having tissues and spare change kept in a person's back pocket and within the zip of a handbag. The research also highlighted the role of daily routines - from the pressures of getting up in the morning and getting to work on time, to the time allowed in the toilet at work and the comfort and privacy afforded in using such a space. My work has shown that these matters are not only important for those living with IBS, but are relatable features for everyone, and are thus important for an inclusive society as a whole. This fellowship enables me to communicate these social messages to multiple publics, including academic, the general public and policy audiences.\n\nThe core activities of this fellowship are directed towards disseminating key findings, bringing to attention the important accounts of living with a common condition that often falls under the public and academic radar. Communicatingsuchfindingswillbeachievedthroughthecarefulinterplayoftellingpersonalaccounts of lived experiences whilst also highlighting the social and political implications of these narratives in broader public life - from being given time at work to go to the toilet, to being granted disabled toilet access in spite of IBS being an 'invisible' health condition. These findings will come to life in the form of written pieces for academic audiences including journal articles, blog posts and presenting at UK and international conferences. This fellowship will also include the production of a short video detailing everyday accounts of living with IBS. This will be showcased at a stakeholder engagement workshop, aimed at those living with IBS and those who also provide support including charities, local councils, occupational health groups and healthcare professionals. Finally, the latter period of this fellowship will involve developing a new research agenda and\npilot research that covers life (and work) on the move and the implications of public toilet access. This builds not only on my research to date, but the growing social pertinence of toilet access and working life coming to the fore in political and social agendas. This fellowship will be hosted in the Department of Sociological Studies at the University of Sheffield. The work of this fellowship compliments the sociological research agendas in the department and across the university that include health, inequalities and everyday life.","isTelecoms":0}
{"text":"Title: Graphene Alliance for Sustainable Multifunctional Materials to Tackle Environmental Challenges Abstract: GIANCE offers innovative solutions to environmental challenges and establishes a holistic, integrated, and industrial-driven platform for the design, development, and scalable fabrication of the next generation of cost-effective, sustainable, lightweight, recyclable graphene and related materials (GRM)-based multifunctional composites, coatings, foams, and membranes (GRM-bM) with enhanced properties (e.g. thermal, mechanical, chemical), functionalities (e.g. wear, corrosion, chemical and fire resistance, hardness and impact resistance, high temperature resistance, structural health monitoring, ultralow friction surfaces), and as enablers for hydrogen storage. GIANCE will also advance manufacturing processes, enhancing synthesis and stability and reducing environmental impact. Such GRM-bM and manufacturing capabilities will allow robust connections with end-users and thus develop and qualify the commercial propositions to high TRLs. GIANCE will develop, demonstrate, and validate the efficacy of GRM-enabled products (11 use cases) which will underlie future technologies for different sectors (e.g. automotive, aerospace, energy (hydrogen economy) and water treatment). GIANCE also supports the innovation output and industrialization efforts of the Graphene Flagship initiative, building a credible pathway for the newly accumulated knowledge to impact EU industry and society. GIANCE will support a strong EU value chain in translating technology advances from TRL4-5 into concrete innovation opportunities and production capabilities (TRL6-7), with first-mover market advantages of scale in the defined industrial sectors. The consortium consists of 23 partners from 10 countries, representing the full value chain, with leading OEMs, large industries, world-class research and education organisations, and innovative SMEs. GIANCE is designed to ensure maximum impact for the defined industries and society as a whole, significantly contributing to the evolving field of GRM.","isTelecoms":0}
{"text":"Title: Performing Medical Diagnosis in Contemporary Artistic Representation Abstract: My project will explore how different mediums of artistic practice can disrupt the medical framing of diagnosis. I will look at the impact of diagnosis beyond the doctor's office and examine artistic representations that focus on lived experiences of diagnosis. Located at the emerging arts and medicine interface, diagnosis and its relationship to performance has thus far been neglected. This project, in addressing an overlooked area, will bring much needed insight and prove to be of great significance to the fields of performance, medical education and health.\n\nIn researching artistic representations that are concerned with diagnosis, I will examine the role of spectatorship and how it straddles both life, medicine and performance. Drawing on Michel Foucault, I will explore how diagnosis evokes a type of spectatorship that assesses the body. His coinage of the clinical gaze acts as a critique on how modern medicine, starting at diagnosis, discards personal experiences of illness, objectifies the body, and only sees or examines through scientific fact. Conversely, these medical observational strategies can be juxtaposed with Maaike Bleeker who situates theatrical spectatorship as a vision machine of political subjectivity. Here, I will critically add to theatrical and diagnostic research by teasing out the nuances separating medical and artistic spectatorship. Adding further knowledge to the intersection between medicine and art, I will explore how diagnosis can be read as a performative mode. \n\nThrough leaning on the works of J.L. Austin and Judith Butler, I will explore how diagnosis and its declarative delivery performs and constitutes the initial and founding construction of illness identity.","isTelecoms":0}
{"text":"Title: LUMINOUS - Studying, Measuring and Altering Consciousness through information theory in the electrical brain Abstract: What is consciousness? Can it be measured? While humankind has struggled with these questions for millennia, our project will focus on more modest but nonetheless ambitious and related goals. Inspired by recent developments in neuroscience and the potential role of fundamental concepts such as information integration and algorithmic complexity, we will study, model, quantify, and alter observable aspects of consciousness.  Our vision is that consciousness will someday be electromagnetically measured and altered, and that the associated needed insights will prove crucial to the development cognitive sciences. \nThe conceptual framework of the project rests on information theoretic developments that link consciousness to the amount of information that a physical system can represent and generate as an integrated whole, and from the related idea that consciousness can be quantified by metrics reflecting information processing and representation complexity. \nSupported by computational neuroscience models, we aim to create non-invasive consciousness-probing technologies integrating electro- and magneto-encephalography, peripheral and non-invasive brain stimulation (NIBS) with advanced techniques to analyse brain activity \u2013 including functional and effective connectivity. Based on the derived brain activity metrics, we will explore intervention, ie the use of NIBS to alter consciousness. To achieve these goals we will pursue computational neuroscience models and human studies \u2013 in perception, sleep, anaesthesia, locked-in syndrome, disorders of consciousness, and in utero \u2013 supported by machine learning to disentangle the essential aspects of consciousness.\nThe project will also explore the ethical implications of such technologies and the prospects for clinical translation. If successful, this paradigm-shifting work will have profound social and clinical impact and provide key insights in fundamental neuroscience and  artificial cognition research.","isTelecoms":1}
{"text":"Title: Police, Press, Public and the 'Celebrity Female Victim' in Britain, 1926-1930 Abstract: This project will examine the historical roots of a phenomenon that is commonplace today: the large impact that media sensationalism regarding crime victims and suspects has on initiating and shaping public policy priorities. In interwar Britain, growing public anxieties about the police reached an important peak in 1928, culminating in the Royal Commission on Police Powers and Procedure (that concluded the following year). High profile cases involving female suspects significantly drove those concerns. These women were often turned into media celebrities, discussed not only on the front pages of newspapers but also in parliamentary debates and committees. Their cases spoke not only to narratives of crime and femininity but also to issues such as the presentation and reception of stories of women's victimisation, the police treatment of suspects (particularly women) and the political and press responses to accusations regarding the illegitimate use of police powers. Research will take place in two stages. The first involves detailed attention to cases from 1928; the second puts those events into context through a broader survey of the popular press and police records.\\n\\nThe year 1928 will serve as the project's chronological anchor and be the focus of the first phase of research, not only due to initial indications suggesting that police power and female victimhood seem to have been particularly significant media topics then but also because of the calling of the Royal Commission. Based upon their extensive coverage of relevant issues, we have chosen selected newspapers as our main sources, including popular papers targeted at a female readership as well as more serious and politically oriented papers, thus providing a broad spectrum of styles and perspectives on the main issues to be studied. Police files and parliamentary debates and reports regarding these cases will also be important sources. Press and official sources will be analysed qualitatively to identify the key themes (such as innocence, femininity, helplessness and vulnerability) in the construction of relevant narratives; the factors that affected the ways cases were presented and treated; and the different roles played by the press, the police and women themselves.\\n\\nThe second phase will contextualise the results of the first by examining newspaper reporting in the two years that preceded and followed 1928. A newspaper search from 1926-27 would determine the extent to which the narratives common in 1928 built upon -- or deviated from -- previous discourses surrounding issues of gender, crime and police power. A study of 1929-30 would then evaluate the impact that repeated scandals and parliamentary inquiry had on press reporting about female victims of police power and the relationship between police and public. For the period 1926-27, research would focus on locating instances of alleged or demonstrated abuse of police powers (particularly those involving women) and identifying the extent to which their themes or presentation would make them precursors of the more in-depth case profiles developed in the first research phase. For the years 1929 and 1930, stories dealing directly with cases examined in the first research phase and coverage of police reforms instituted in the wake of the Royal Commission on Police Powers and Procedure will also be analysed, as will commentary on other legal issues that arose from key cases from 1928 (e.g., coroner's court reform or the need for a public defender).\\n\\nBy exploring the interrelations between gender, media and the issue of police power, this project will not only provide a detailed cultural history of the late 1920s -- a period for which the historiography of crime is underdeveloped -- but also speak to the interrelations between press reporting and policy development, topics of considerable contemporary relevance.","isTelecoms":0}
{"text":"Title: The Tibetan Sustainable Heritage Initiative Abstract: In recent decades, the rapid reshaping of the global economy and the emergence of digital technologies have drastically altered the lives of communities around the world, whilst simultaneously threatening the existence of marginalized languages, traditions, and ecosystems. In response to these changes, grassroots activists, scholars, and national and international organizations have sought new ways to &quot;safeguard&quot; and &quot;preserve&quot; languages and traditions. More recently, &quot;cultural sustainability&quot;-based in equity, collaboration, and supporting continued practice and transmission of traditional practices-has shown promise for working collaboratively with communities to find ways to document and revitalize endangered expressive practices. However, while much research has been done with indigenous populations in the democratic West, marginalized communities in authoritarian contexts have largely been overlooked. This tendency to exclude the experience of marginal and indigenous communities in authoritarian contexts risks misrepresenting the nuanced concerns of indigenous communities at a moment of rising authoritarianism around the globe. It also risks misunderstanding how these communities, and how individual cultural brokers are actively working to keep endangered traditions alive in the face of both economic and institutional pressures.\nBuilding on my established record researching expressive cultures and developing collaborative cultural programming in Tibetan areas of China, I will lead a diverse team of stakeholders including academics, and grassroots cultural documentarians, to advance scholarship on cultural sustainability through examining how everyday digital technologies can be deployed not merely as a threat to traditions, but also to sustain traditional knowledge. In developing and deploying new applications and content management systems we will create ways for Tibetans to document their own traditions. In then working alongside educators and tradition bearers to co-create methods that use social media and other everyday tools to support the transmission and continued vitality of traditions in Tibetan classrooms. I will use the UKRI Future Leaders Fellowship for the Tibetan Sustainable Heritage Initiative (TaSHI, the Tibetan word for auspiciousness), to conduct the first such large-scale investigation of cultural sustainability in an authoritarian context.\nUsing cases ranging from both well-supported traditions like the Tibetan Gesar epic-inscribed on UNESCO's Representative List of the Intangible Cultural Heritage of Humanity-to endangered practices like a rare genre of extemporaneously composed satirical verse called dakpa, this comparative approach will reshape our understanding of cultural sustainability and broaden our understanding of the Tibetan traditional ecosystem. At the same time, recognizing the factors that make some forms successful is only the first step. TaSHI also creates new digital tools for cultural documentation and works with teachers and community members to document traditions and co-create strategies to encourage further transmission and practice of cultural forms, thereby supporting the continued vitality of the traditional knowledge system more generally. \nAs traditions and languages around the world go silent in the face of social, technological, and political pressures, increasingly affordable and ubiquitous digital technologies are shaping how communities engage with their endangered traditions. TaSHI provides an unprecedented opportunity to develop and test new ways of sustaining traditions in China's Tibetan communities. Findings from minority communities in authoritarian China, in turn, will model new ways to co-create more equitable and sustainable futures for endangered traditions and help to develop theoretical and practical perspectives of cultural sustainability that can be further applied to work with indigenous and marginalized communities within China, and around the globe.","isTelecoms":0}
{"text":"Title: IFU OBSERVATIONS OF GAS KINEMATICS IN CENTRES OF GALAXIES Abstract: The aim of this project is to analyse gas kinematics in centres of galaxies observed with integral-field spectrographs MUSE and SINFONI. The observed gas velocity fields will be interpreted in terms of the existing gas flow models, and correlations between particular types of flows and the galaxy's activity and its underlying gravitational potential will be explored. The expected outcome is identification of nuclear components in galaxies from patterns in gas flow imposed by them, and establishing types of gas flows that are capable of feeding active galactic nuclei. We are in possession of the data for the centres of 23 nearby galaxies, which include MUSE and SINFONI integral-field spectra with accompanying HST imaging. The size of this sample is sufficient for studying the relation of gas flows to the nuclear activity and to the nuclear components.","isTelecoms":0}
{"text":"Title: Which chromatin modifications regulate the initiation of V(D)J recombination? Abstract: To be able to combat a vast number of potential infections, we need to produce a highly diverse set of antibody and T cell receptor molecules. Millions of antibodies are needed and if every cell carried a distinct gene to encode each of these antibodies, thousands of megabases of DNA would be required. Instead, antibody genes are assembled de novo from individual gene segments by a process known as V(D)J recombination: One gene segment is randomly chosen from a vast pool and joined to a gene segment from a separate pool. The huge number of different combinations results in an enormous number of antibody genes. Although this strategy has its advantages, it also carries dangers: DNA must be broken and rejoined and mistakes in this process can result in the wrong pieces of DNA being rejoined. In the most extreme cases, DNA from different chromosomes becomes joined, resulting in a chromosome translocation. The latter are a major cause of leukaemias and lymphomas. \n\nThis research aims to understand how V(D)J recombination is regulated in normal individuals to then understand how mistakes lead to leukaemias and lymphomas. More specifically, it aims to determine how the DNA breaks are targeted. This knowledge will then enable us to determine which environmental factors increase the risk of breaks at inappropriate sites in the genome that can trigger leukaemias and lymphomas.\n\nTo date, we know that sequences must be made accessible for them to be cut: DNA in the nucleus exists in a highly packaged structure, known as chromatin; this protects DNA from the initiation of recombination. However, in response to the appropriate signals, this chromatin packaging is specifically unravelled to allow recombination to occur. Sequences, known as enhancers, are thought to be important in controlling chromatin unpackaging; they regulate transcription that passes through the gene segments used in recombination. Transcription results in physical changes in chromatin by modifying the packaging proteins. This project aims to understand whether transcription itself, the modifications that it induces, or the modifications induced by enhancers target DNA breaks for the initial stages of recombination. Once the modifications that target DNA breaks are known, we will be able to determine which factors increase the risk of DNA breaks occurring in inappropriate regions of the genome and thus gain a better insight into the risk factors for leukaemias and lymphomas.","isTelecoms":0}
{"text":"Title: STRiDE: Strengthening responses to dementia in developing countries (GCRF) Abstract: Dementia is not a &quot;developed world&quot; condition: there are already more people with dementia in LAMICs than in high-income economies, yet LAMICs are typically less equipped to respond to the high and increasing prevalence. By 2050, there will be 90 million people with dementia in LAMICs (Prince et al 2015). \nPeople with dementia, particularly at more severe stages, require intensive care and support, which is very costly. These costs are mostly borne by unpaid family carers, primarily women, who often have to leave paid work, risking personal impoverishment and societal productivity losses. LAMICs face rapid growth in numbers of people with dementia without well-developed or well-funded health and care systems. Family care availability is decreasing as a result of demographic, societal and economic changes. \nWe will build research capability using economics, epidemiology and policy analyses to help LAMICs respond to the needs of the growing numbers of people with dementia in an ethical and sustainable way. The co-applicants, from the UK and South Africa, have strong track-records in dementia research in high-income countries (HICs) and LAMICs, research on health and long-term (social) care in LAMICs. We will partner Alzheimer's Disease International (ADI), a federation of 85 national Alzheimer\/dementia associations. \nWe will work with local researchers and NGOs in 7 LAMICs: Brazil, India, Indonesia, Kenya, Jamaica, Mexico, South Africa. To build capability we will offer formal training in research methods, application of those methods to generate new evidence and tools, and training and practice in use of evidence to inform policy. We will apply the best methodological approaches and publish our results in peer-reviewed journals, but more importantly we will ensure that our research generates practical tools for use directly by stakeholders to develop services and improve practice, or to influence policy.\nWe will use systematic reviewing and meta-analysis to review evidence on what works in LAMICs and what can be delivered in particular contexts, but also make that research available online and in DVDs as evidence summaries written in plain (dementia-friendly) language and translated to relevant local languages.\nWe will use Theory of Change (ToC) to co-develop with local partners (researchers\/NGOs) and stakeholders (including people with dementia and carers) the research and training agenda for the project to ensure that our activities achieve maximum impact. ToC will also help us develop indicators to evaluate the project's impact. \nOur research programme will involve development and evaluation of an intervention to increase dementia awareness and reduce stigma, a qualitative study of costs and other impacts of providing family care to people with dementia in different contexts, generation of quantitative evidence on impacts and costs of dementia on individuals and families, and instruments to collect these data.\nWe will use the evidence generated to develop, for each country, credible estimates of the costs and impacts of dementia, and use simulation modelling to project future dementia care needs, the health and social services required to meet those needs, their costs, and the impacts of implementing evidence-informed dementia care pathways and better coverage. Models for each country will be simple to update and adapt. \nWe will assess the policy implications of our projections, consider the barriers presented by current organisation and financing systems and the availability of trained workers, and outline reform opportunities to improve dementia, considering the wider health and social care systems.\nFinally, we will work with ADI and other policy partners to produce local recommendations to support the implementation of National Dementia Plans. We will organise stakeholder workshops in each country to present project outcomes, and high level stakeholder meetings in each of the regions, in collaboration with WHO.","isTelecoms":0}
{"text":"Title: Geography Abstract: My research will investigate how the implementation of 'green' smart projects in Bristol and Manchester has impacted environmental justice (EJ) issues comparatively.","isTelecoms":0}
{"text":"Title: Neuroglobin in the Retina. Use of a Knockout Mouse for Functional assessment \/ Phenotyping and examining Human relevance, towards Neuroprotection. Abstract: Neuroglobin (Ngb) is a recently discovered nerve specific oxygen binding &quot;globin&quot; protein.\nIt was discovered recently through the use new research techniques - even though it had been present for hundreds of millions of years.\nIt has been present for longer than the more well known Haemoglobin ( which carries oxygen around the body and removes waste products in blood) or Myoglobin which carries out a similar function in muscle.\n\nNeuroglobin is a newly discovered protein which is found in nerve tissue such as the retina and the brain and its function is not clearly understood at present.\nThe importance of this protein is that it is found in nerve tissue ( retina and brain) that work very hard to provide essential functions such as eyesight and the many important functions of our brain. \nThe retina can be though of as being &quot;the film or sensor in a camera&quot; in that it converts light energy from an object in front of us, into an electrical signal that then travels up the Optic nerve to the brain, where it is processed to allow us to see the object.\nIf there is a fault anywhere along this pathway, the person may have problems with their vision and may not be able to see well or they may not see at all. This can have a severe impact on their lives.\nRetina, nerve tissue and brain may have genetic abnormalities that mean these tissues may not work as they should from an early age or they may degenerate later in life. As these tissues all &quot;work&quot; very hard even in people who do not have a faulty cell or tissue, with time &quot;ageing&quot; their blood an oxygen supply may become impaired of the tissue can lose function. Many diseases can affect the retina and eyesight and the brain.\nDiseases of the retina include age-related macular degeneration, genetic errors or dystrophies, problems with blood supply, problems with the pressure inside the eye &quot;glaucoma&quot; and problems with the main nerve (Optic nerve) connecting the eye to the brain.\nGlaucoma is the most common cause of irreversible loss of vision in the world. Once the sight is lost in glaucoma it cannot be recovered. We do not fully understand why glaucoma occurs. The aim of this neuroglobin project is to try to work out why nerves are damaged, before it is too late, so that we can work out ways to try to prevent the nerves being damaged so that we can prevent loss of vision.\nDiseases of the brain include strokes, degenerative conditions such as Alzheiners disease and dementia. Again research into neuroglobins function may help to prevent loss of brain function.\n\nMany of these retina and brain diseases are due to problems with blood supply, oxygen transport and build up of waste products or abnormal material. \nNeuroglobin has been implicated in many of these diseases and the aim of this project is\nPrimarily to try to find out what its function is in the retina.\nSecondary aims include applying what we find out about Neuroglobin in the retina to brain research\n\n\nWe will compare mice that have neuroglobin in their retina and brain with some that do not have neuroglobin.\nThis will be done by taking specialist photographs and measuring what the retina &quot;sees&quot;. We will see how this changes over time &quot;ageing&quot; to try to work out how neuroglobin works in the retina and in the brain.\nWe have some clues about how neuroglobin works and we believe that it doe have a vital function in retina and in brain.\nWe are working with many other reseachers in other institutes in a collaborative effort.\nTogether, if we can work out how neuroglobin works, then we can try to increase its effectiveness and prevent loss of function in the retina to try to prevent loss of vision and to try to prevent loss of brain function.","isTelecoms":0}
{"text":"Title: HADES - Benthic diagenesis and microbiology of hadal trenches Abstract: With this project, called HADES, we aim to provide the first detailed, combined analysis of benthic diagenesis and microbial ecology of some of the deepest oceanic trenches on Earth. We argue that deep trenches, some of the most remote, extreme, and scantly explored habitats on Earth, are hotspots of deposition and mineralization of organic material. With the development of novel autonomous in situ instrumentation to overcome large sampling artifacts from decompression, we will i) determine rates of benthic metabolism and the importance of the deep trenches for the marine carbon and nitrogen cycles, ii) explore the unique benthic microbial communities driving these processes, and iii) investigate the proposed great role of virus in regulating microbial performance and carbon cycling in hadal sediments. By comparing trenches from contrasting oceanic settings the project provides a completely novel general analysis of hadal biogeochemistry and the role of deep trenches in the oceans, as well as fundamental new insights into the composition and functioning of microbial communities at extreme pressure.","isTelecoms":0}
{"text":"Title: Efficient tuning of quantum devices using machine learning Abstract: Controlling materials on the nanoscale is now sufficiently refined that new methods are needed for fabricating the structures and tuning their performance. In many cases we are reaching the limits of our ability to do this using human control of the process, all the more so when a key consideration is scalability for technological applications. The project identifies quantum devices where machine learning will provide the key to speeding up, scaling up, and opening up new technologies\n\nThe objective is to develop theoretical models that can account for transport in semiconductor quantum devices to inform machine learning techniques which will allow for fast tuning and measurement of these devices. These techniques will be focused towards measurement algorithms which prioritize information gain, determining which is the most informative measurement to perform next. The algorithm will combine information theory with a probabilistic deep-generative model that can generate full-resolution reconstructions from scattered partial measurements. An optimised measurement method that can prioritise and select important configurations is key for fast characterisation and automatic tuning. A physical model will aid the training of the algorithms to prevent over-fitting. This project will involve statistical problem-framing, to identify what is to be predicted as a function of what, and it will require to select and evaluate different models of quantum devices.\n\nMost machine learning techniques dedicated to the tuning and measurement of quantum devices so far have no knowledge about the physics behind the operation of these devices. This project is dedicated to produce adequate physics models which can inform the machine learning methods in the efficient measurement of quantum devices. \n\nThis project is key to unleash the potential of quantum technologies by allowing fast measurement of quantum devices, and thus the possibility to control technologically relevant quantum circuits. \n\nA collaboration with University of Basel provides us with the quantum devices we require for our experiments, and a collaboration with the Department of Engineering at University of Oxford allows us to benefit from the expertise of computer scientist dedicated to the study of artificial intelligence, in particular Bayesian optimisation and other machine learning techniques which do not require large amounts of data, which is not available for quantum devices. \n\nThis project falls within the EPSRC Quantum technologies research area.","isTelecoms":1}
{"text":"Title: Democratic Party Presidential Primary Campaigns and the Left, 1980-1988 Abstract: This project will use the American Democratic Party Presidential primary election campaigns of Edward Kennedy and Jesse Jackson to assess the power of the American left during the 1980s. Applying the methods of comparative history and Freeden's morphological analysis, the project will examine the campaign material of Kennedy and Jackson to ascertain whether the fundamentals of the Democratic Left shifted over the decade in response to the Reagan presidency, and the degree to which interest groups on the left were able to influence these campaigns. It will examine the changing centres of institutional power within the Democratic Party and the relationship between these campaigns and the politics of race and ethnicity, especially the extent to which constituencies of the Left (e.g. unions and civil rights groups) could influence campaigns in the context of apparent rightward drift in the nation and the party. My analysis will rely on a detailed exploration of C-SPAN's online campaign video archive, campaign media commentary from the Vere Harmsworth Library at the University of Oxford, material from the Edward Kennedy collections at the John F. Kennedy Library in Boston and collections from figures connected to Jackson like Chicago Mayor Harold Washington in the Chicago Public Library. \nI have consistently focused on this period in my work, writing a first-class undergraduate dissertation that considered two prominent African-American athletes' interaction with black politics during the 'long1970s'. For this, I won the 'Sport in History Undergraduate Essay Prize 2019' and the University of Nottingham's School of Humanities Masters Bursary. I am building on this work through my MA dissertation's focus on the Kennedy and Jackson campaigns and their significance for understanding liberal ideology in the 1980s. Through my time at the University of Nottingham I have developed a strong working relationship with my prospective supervisor Joe Merton, who supervised both my previous projects, and has expertise on the politics of race and ethnicity that comprise a key part of the project. Moreover, the university's American and Canadian Studies department provides further research expertise, not least Professor Ling as second supervisor, as well as the Centre for Research in Race and Rights and the Centre for the Study of Political Ideologies that make Nottingham the ideal centre forstudying the subjects my project examines.","isTelecoms":0}
{"text":"Title: Real-Time Imaging of Epileptic Seizures with stereo Electrical Impedance Tomography (sEIT) Abstract: Around 400,000 people suffer from epilepsy in the UK, and 30% of this population do not respond to any anti-epileptic drug. For a significant proportion of these, surgical removal of the brain tissue generating the seizures is the best treatment option for becoming seizure-free. However, with the existing methods (3T MRI and stereo-electroencephalography (sEEG)), it can remain a challenge to map the seizure pathways in the brain and localise the seizure onset zone (the &quot;focus&quot;) with precision. Difficulties in the precise localisation of seizure foci have limited the number of patients eligible for surgery and lowered its effectiveness, evidenced by seizure recurrence in over half of these individuals. sEIT is a recently developed method that has great potential to localise the focus more accurately, without disrupting current pre-surgical practice at the hospital. The idea is that physiological changes that occur during seizures - such as swelling of the brain cells and synchronous neuronal activity - change the electrical resistance of the brain tissue. By injecting safe levels of current into the brain (using the 'depth' electrodes already implanted into the brain for presurgical evaluation), we can image these changes in resistance and map the initiation and propagation of seizures. This method has already been validated in animal models in which the seizure focus and subsequent propagation were identified with the accuracy of 5 mm. We propose to translate sEIT technology to human patients with the aims to first (a) increase surgery uptake and improve post-surgical outcomes, and eventually (b) replace the surgery with the sEIT controlled closed-loop deep brain stimulation. If successful, this method will directly benefit pre-surgical planning in the short-to-medium term and revolutionize epilepsy treatment in the long term.\n\nThe specific aims of the project are:\n1) Improve localisation accuracy of seizure foci and study subsequent seizure progression by sEIT using the depth electrodes already routinely placed for presurgical evaluation.\n2) Study the mechanisms of seizure progression and areas of the eloquent cortex, which should not be resected to minimise postsurgical functional deficits.\n3) Design and test the optimal closed-loop stimulation paradigm to suppress the seizures without the need of surgical recession.\n\nNovelty:\nThe sEIT method has been validated in animal models, however the technique is not yet implemented in human patients. Successful translation will allow to use sEIT to improve surgical outcomes and potentially create a close-loop DBS paradigm, which would replace a human brain resection surgery.\n\nAlignment with EPSRC:\nThe research will be focused on the implementation of novel sEIT technique in human patients. The project has a potential to transform epileptic seizure focus localization procedure and following resection surgery. National Hospital for Neurology and Neurosurgery Telemetry ward patients will be recruited once the technology is optimised and tested for compliance with corresponding standards. The collaboration with a world-renown UK hospital will attract additional investment opportunities in the UK R&amp;D sector and provide opportunities for other researchers and engineers to join in later stages of the technology implementation into a marketable product.\n\nAny companies or collaborators involved:\nCyqiq LTD","isTelecoms":0}
{"text":"Title: The SofTMech Statistical Emulation and Translation Hub Abstract: There have recently been impressive developments in the mathematical modelling of physiological processes. As part of a previously EPSRC-funded research centre (SofTMech), we have developed mathematical models for the mechanical and electrophysiological processes of the heart, and the flow in the blood vessel network. This allows us to gain deeper insight into the state of a variety of serious cardiovascular diseases, like hypoxia (a condition in which a region of the body is deprived of adequate oxygen supply), angina (reduced blood flow to the heart), pulmonary hypertension (high blood pressure in the lungs) and myocardial infarction (heart attack). A more recent extension of this work to modelling blood flow in the eye also provides novel indicators to assess the degree of traumatic brain injury. \nWhat all these models have in common is a complex mathematical description of the physiological processes in terms of differential equations that depend on various material parameters, related e.g. to the stiffness of the blood vessels or the contractility of the muscle fibres. While knowledge of these parameters would be of substantial benefit to the clinical practitioner to help them improve their diagnosis of the disease status, most of the parameters cannot be measured in vivo, i.e. in a living patient. For instance, the determination of the stiffness and contractility of the cardiac tissue would require the extraction of the heart from a patient and its inspection in a laboratory, which can only be done in a post mortem autopsy.\nIt is here that our mathematical models reveal their diagnostic potential. Our equations of the mechanical processes in the heart predict the movement of the heart muscle and how its deformations change in time. These movements can also be observed with magnetic resonance image (MRI) scans, and they depend on the physiological parameters. We can thus compare the predictions from our model with the patterns found in the MRI scans, and search for the parameters that provide the best agreement. In a previous proof-of-concept study we have demonstrated that the physiological parameters identified in this way lead to an improved understanding of the cardiac disease status, which is important for deciding on appropriate treatment options.\nUnfortunately, the calibration procedure described above faces enormous computational costs. We typically have a large number of physiological parameters, and an exhaustive search in a high-dimensional parameter space is a challenging problem. In addition, every time we change the parameters, our mathematical equations need to be solved again. This requires the application of complex numerical procedures, which take several minutes to converge. The consequence is that even with a high-performance computer, it takes several weeks to determine the physiological parameters in the way described above. It therefore appears that despite their enormous potential, state of the art mathematical modelling techniques can never be practically applied in the clinical practice, where diagnosis and decisions on alternative treatment option have to be made in real time.\nAddressing this difficulty is the objective of our proposed research. The idea is to approximate the computationally expensive mathematical model by a computationally cheap surrogate model called an emulator. To create this emulator, we cover the parameter space with an appropriate design, solve the mathematical equations in parallel numerically for the chosen parameters, and then fit a non-linear statistical regression model to this training set. After this initial computational investment, the emulator thus created gives predictions for new parameter values practically instantaneously, allowing us to carry out the calibration procedure described above in real time. This will open the doors to harnessing the diagnostic potential of state-of-the art mathematical models for improved decision support in the clinic.","isTelecoms":0}
{"text":"Title: Stabilising hydrogels using dipeptides Abstract: For my project three dipeptides (a molecule containing two amino-acid residues) at a very low concentration (1 mM) are used to stabilise aqueous foams and emulsions. By dispersing the dipeptide in a basic solution, hydrogels can be formed via addition of an appropriate salt. These hydrogels can then be either aerated to form a foam, or emulsified by using different oils. By changing the physicochemical conditions of the dispersion phase, we study how to stabilise these systems for long periods of time.","isTelecoms":0}
{"text":"Title: NAIADES - Na-Ion bAttery Demonstration for Electric Storage Abstract: Wide scale implementation of renewable energy will require growth in production of inexpensive, efficient energy storage systems. The extension of battery technology to large-scale storage will become necessary as intermittent renewable energy sources such as wind, solar and wave become more prevalent and integrated into electrical grid. Lithium-ion battery appears as quite mature for this application but its cost per mWh remains high in comparison to high temperature technology such as Zebra, which integrate low cost sodium base materials. Furthermore, as the use of large format lithium battery becomes widespread; increase demand for lithium commodity chemicals combined with geographically constrained Li mineral reserves will drive up prices. Based on the wide availability and low cost of sodium, ambient temperature sodium-based batteries have the potential for meeting large scale grid energy storage needs. In NAIADES we will demonstrate the feasibility of ambient temperature Na-ion battery from the knowledge and achievement that has been done at the laboratory scale, up to a module demonstration in a realistic application environment.  \nSeveral European industrials, institutes and universities belonging to ALISTORE-ERI have decided to join their efforts to assess the Na-ion technology for stationary storage application through building a 1 kW modules system Na-ion cell which will serve as data base to demonstrate economical and public acceptance.\nThese module prototypes will be developed to meet performances in a 1kW system in a cost-effective, sustainable and environmental-friendly manner. New energy policy will be developed to integer the Na-ion battery in the Smart Grid initiative and promote the penetration of renewable energy in the electric network.","isTelecoms":1}
{"text":"Title: The Role of Breastfeeding in Ancient Egyptian Religion and Kingship Abstract: This project examines the religious and political role played by the divine nursing motif (depictions of the ancient Egyptian king being breastfed by a goddess) in ancient Egyptian temples and tombs from the Old Kingdom through the Greco-Roman period (ca. 2450 BCE - 31 CE). I am analyzing every known divine nursing scene from a temple or tomb complex during this period through an iconographic analysis of the regalia and subjects of each scene and a textual analysis of each scene's accompanying inscriptions. Additionally, certain scenes will act as case studies for a contextual analysis of their location in the temple or tomb as well as their relationship to surrounding scenes.\n\nI will focus on the following research questions:\n\nWhat is the role of the divine nursing motif in the context of Egyptian temples and tombs? How do these scenes relate to and interact with other scenes?\n\nWhat can these scenes reveal regarding the nature of divine kingship in ancient Egypt?\n\nWhat do these scenes reveal regarding the role of women in Egyptian religion, kingship, and worldview?\n\nFor this analysis, I have begun to create a database of each appearance of the Egyptian divine nursing motif (approximately 130 scenes). As all of these scenes have not been published or were published without usable line drawings or photos, a trip to Egypt to photograph such scenes will be essential. The database and photos will be made available with the final dissertation.\n\nDivine nursing scenes are believed to have symbolized the king's adoption by the gods and his reception of the divine protection and power needed to be king. This generally accepted understanding relies largely on the writings of Jean Leclant (1951 &amp; 1960). Leclant and later scholars (Maruejol 1983; Budin 2011; Gomez-Landero 2016) have generally focused on only a select number of scenes such as those of a certain period or location and have largely examined the scenes independent of their larger decorative context. While these methods of study have proven useful in many ways, these scenes were meant to be part of a larger program and more understanding will be gained when their context is considered. As such, the contextual analysis of the selected case studies will allow my research to make unique and important contributions to our understanding of this motif and its use in various contexts.\n\nMy research will also contribute to our understanding of ancient Egyptian kingship and the role of women in religion and politics. These scenes create a personal connection between the king and a goddess. Thus, their use, iconography, and texts can illuminate beliefs regarding the king's relationship with the divine and how these beliefs may have changed over time. In addition, these scenes depict the king dependent on a goddess for nourishment and care. In this way, this study of the motif can help us better understand the roles played by women in the ancient Egyptian worldview and its application in politics and religion.","isTelecoms":0}
{"text":"Title: Blue-Cloud 2026 Abstract: Blue-Cloud 2026 builds upon the pilot Blue-Cloud project which established a pilot cyber platform, providing researchers access to multidisciplinary datasets from observations, analytical services, and computing facilities essential for blue science. Core services delivered are the federated Data Discovery &amp; Access Service (DD&amp;AS), the Virtual Research Environment (VRE) and Virtual Labs. Blue-Cloud 2026 aims at a further evolution of its pilot ecosystem into a Federated European Ecosystem to deliver FAIR &amp; Open data, analytical services, instrumental for deepening research of oceans, EU seas, coastal &amp; inland waters. It develops a thematic marine extension to EOSC for open web-based science, &amp; serves needs of the EU Blue Economy, Marine Environment and Marine Knowledge agendas. Blue-Cloud 2026 in 42 months covers activities at a growing number of federated environmental RIs to improve &amp; optimise services for uptake of new data sets from a multitude of data originators and for discovery and access to their structured data collections. The advanced ecosystem will provide a core data service for the Digital Twin of the Ocean (DTO), mobilising and making available major additional data resources as validated and harmonised in-situ data by means of Data Lakes. The modular architecture of the VRE is scalable &amp; sustainable, fit for connecting additional e-infrastructures, integrating more blue analytical services, configuring more Virtual Labs, and targeting broader (groups of) users. Blue-Cloud 2026\u2019s overall Objective is to expand the federated approach of Blue-Cloud, involving more aquatic data stakeholders, and interacting with European Open Science Cloud (EOSC) developments, in support of the EU Green Deal, UN Sustainable Development Goals (SDGs), EU Destination Earth, and the EU Mission Starfish on healthy oceans, seas, coastal and inland waters, ultimately to provide a core data service for the European Digital Twin of the Ocean. Blue-Cloud 2026 is co-ordinated by the same organisations behind the pilot Blue-Cloud project (Trust-IT &amp; MARIS), supported by a core team of existing and new Blue-Cloud partners; overall it mobilises a solid, multidisciplinary, &amp; committed team of 40 partners from 13 European countries.\n\n\n\n\n\nBlue-Cloud 2026 builds upon the pilot Blue-Cloud project which established a pilot cyber platform, providing researchers access to multidisciplinary datasets from observations, analytical services, and computing facilities essential for blue science. Core services delivered are the federated Data Discovery &amp; Access Service (DD&amp;AS), the Virtual Research Environment (VRE) and Virtual Labs. Blue-Cloud 2026 aims at a further evolution of its pilot ecosystem into a Federated European Ecosystem to deliver FAIR &amp; Open data, analytical services, instrumental for deepening research of oceans, EU seas, coastal &amp; inland waters. It develops a thematic marine extension to EOSC for open web-based science, &amp; serves needs of the EU Blue Economy, Marine Environment and Marine Knowledge agendas. Blue-Cloud 2026 in 42 months covers activities at a growing number of federated environmental RIs to improve &amp; optimise services for uptake of new data sets from a multitude of data originators and for discovery and access to their structured data collections. The advanced ecosystem will provide a core data service for the Digital Twin of the Ocean (DTO), mobilising and making available major additional data resources as validated and harmonised in-situ data by means of Data Lakes. The modular architecture of the VRE is scalable &amp; sustainable, fit for connecting additional e-infrastructures, integrating more blue analytical services, configuring more Virtual Labs, and targeting broader (groups of) users. Blue-Cloud 2026\u2019s overall Objective is to expand the federated approach of Blue-Cloud, involving more aquatic data stakeholders, and interacting with European Open Science Cloud (EOSC) developments, in support of the EU Green Deal, UN Sustainable Development Goals (SDGs), EU Destination Earth, and the EU Mission Starfish on healthy oceans, seas, coastal and inland waters, ultimately to provide a core data service for the European Digital Twin of the Ocean. Blue-Cloud 2026 is co-ordinated by the same organisations behind the pilot Blue-Cloud project (Trust-IT &amp; MARIS), supported by a core team of existing and new Blue-Cloud partners; overall it mobilises a solid, multidisciplinary, &amp; committed team of 40 partners from 13 European countries.\n\n\n\n\n\nBlue-Cloud 2026 builds upon the pilot Blue-Cloud project which established a pilot cyber platform, providing researchers access to multidisciplinary datasets from observations, analytical services, and computing facilities essential for blue science. Core services delivered are the federated Data Discovery &amp; Access Service (DD&amp;AS), the Virtual Research Environment (VRE) and Virtual Labs. Blue-Cloud 2026 aims at a further evolution of its pilot ecosystem into a Federated European Ecosystem to deliver FAIR &amp; Open data, analytical services, instrumental for deepening research of oceans, EU seas, coastal &amp; inland waters. It develops a thematic marine extension to EOSC for open web-based science, &amp; serves needs of the EU Blue Economy, Marine Environment and Marine Knowledge agendas. Blue-Cloud 2026 in 42 months covers activities at a growing number of federated environmental RIs to improve &amp; optimise services for uptake of new data sets from a multitude of data originators and for discovery and access to their structured data collections. The advanced ecosystem will provide a core data service for the Digital Twin of the Ocean (DTO), mobilising and making available major additional data resources as validated and harmonised in-situ data by means of Data Lakes. The modular architecture of the VRE is scalable &amp; sustainable, fit for connecting additional e-infrastructures, integrating more blue analytical services, configuring more Virtual Labs, and targeting broader (groups of) users. Blue-Cloud 2026\u2019s overall Objective is to expand the federated approach of Blue-Cloud, involving more aquatic data stakeholders, and interacting with European Open Science Cloud (EOSC) developments, in support of the EU Green Deal, UN Sustainable Development Goals (SDGs), EU Destination Earth, and the EU Mission Starfish on healthy oceans, seas, coastal and inland waters, ultimately to provide a core data service for the European Digital Twin of the Ocean. Blue-Cloud 2026 is co-ordinated by the same organisations behind the pilot Blue-Cloud project (Trust-IT &amp; MARIS), supported by a core team of existing and new Blue-Cloud partners; overall it mobilises a solid, multidisciplinary, &amp; committed team of 40 partners from 13 European countries.","isTelecoms":1}
{"text":"Title: Microbial degradation of isoprene in the terrestrial environment Abstract: The Blue Mountains in Australia and Blue Ridge Mountains of Virginia, are so-named because of the blue haze that results from atmospheric reactions with isoprene, a gas produced in abundance by plants and especially many tree species. Trees that are starting to be grown widely as a source of bioenergy, namely willow and poplar, are among the highest isoprene emitters. Isoprene protects plants against heat and light-induced damage, and can also serve as a signaling molecule. Isoprene is so reactive with other chemicals in the lower atmosphere that it limits their capacity to react with methane and also generates ozone. Both ozone and methane are potent greenhouse gases, and ozone impairs plant growth. On the more positive side, isoprene can indirectly stimulate cloud formation which provides a cooling effect. Hundreds of studies have investigated isoprene production, primarily from trees, and examined the effect of a changing environment on its flux from tree to atmosphere. \n\nIn stark contrast, only a handful of studies have shown that microbes in the soil consume isoprene, and a few of those microbes have been grown in the laboratory. Microbes are abundant (several billion per teaspoon of soil and more than a million per square cm of leaf) and the most important catalysts for cycling chemicals in the environment. We know from studying the cycles of other climatically important gases, like methane, that microbial consumption is an extremely important process that is greatly influenced by climate change. From hundreds of methane-consuming bacteria in culture, we have extensive knowledge of their metabolic pathways, which allows the development of investigative tools to help inform land-use management decisions. For isoprene, which is produced in similar abundance to methane, we lack this knowledge and tools.\n\nTherefore, in addition to those bacteria that we already have in culture, we propose to culture isoprene-degrading microbes, focusing on soil and leaf inhabitants. Using powerful genomic-based techniques, we will determine the DNA sequences of the genes involved in isoprene degradation. Additionally, we will use tools developed by the PI to identify and investigate those isoprene degraders that are not easy to grow. Most bacteria look alike and so we frequently use DNA sequences to study their roles in nature. Selected unique DNA sequences will be used to identify, view and count key species of isoprene-degrading bacteria in natural samples. This will enable us to determine precisely where they live, e.g. we envisage that they will be especially abundant around stomata (pores in the leaf) from where most isoprene escapes; and the use of state-of-the art imaging techniques (developed by our project partner) will allow us to identify which individual microbes are actively degrading isoprene in the soil or on the leaf surface.\n\nComplementing this study, a PhD student will measure isoprene consumption in forest soils, and for the first time, on leaves from various tree species, comparing isoprene emitters with non-emitters as well as sun and shade leaves. We will test whether adding permutations of isoprene-degrading microbes to leaf surfaces enhances consumption, and by measuring the microbes' ability to survive or grow on the leaves, we will obtain insights into whether this is a potential strategy for reducing isoprene flux. All of the data emanating from this project will be valuable for management of natural woodlands and bioenergy crops, in relation to greenhouse gas emissions.","isTelecoms":0}
{"text":"Title: The Verse Forms of Middle English Romance Abstract: Before the fifteenth century, Middle English writers wrote stories in verse. The three broad streams of narrative verse in medieval England are the poetry of Chaucer and his followers, alliterative verse, and the metrical romances. The oldest of these, King Horn (c1220) immediately exposes our ignorance about the kind of verse the poet of Middle English romance thought they were writing. The Horn poet's rhyme range was evidently wider than that of poets such as Chaucer and Gower, and his prosody remains the subject of controversy: were his verses short couplet lines in alternating three-beat rhythm or more like the half-lines of alliterative poetry? A number of romances composed after Horn give rise to similar problems of scansion and versification. Sir Tristrem, from the later thirteenth century, was written in an unusual 11-line bob-and-wheel stanza that has seemed to some parodic and to others lyrical. To judge which of these views is the correct one, we would need to know which other poems (in English, Anglo-Norman and Latin) used the form. Two stanzaic patterns recur regularly in Sir Tristrem but a third pattern is only attested in just two stanzas: are these anomalous stanzas due to scribal invovement or are they authorial? This project addresses these and other questions by investigating the particular metrical systems that obtained in the Middle English romances, and it explores their textual and literary history to answer the question of what their verse forms meant to poets, scribes, and audiences. \\n\\nThe importance of these topics to editors, literary critics, and philologists has long been appreciated in the field of Chaucer studies and more recently in the field of alliterative verse, where new discoveries about poets' metrical practices have revolutionized editing and enriched literary criticism. Regrettably, the renewal of interest in the formal aspects of verse has largely passed the Middle English romances by. Since little is known about their metrical systems, editors have not been able to use metrical criteria as an aid to textual criticism, with the result that romances often circulate in editions that give the misleading impression that, where rhyme, stanza form, and rhythm are concerned, everything goes. There are good reasons, on the contrary, for assuming that romance poets had a determinate range of metrical possibilities, and that these conditions of metricality are recoverable. The accidental survival of autograph copies of Sir Ferumbras (consisting of fragmentary draft and a final version) provides a rare opportunity to measure the poet's range of permissible rhymes and rhythms. In romances that are extant in multiple copies (such as Horn and Eglamour), the unreliable evidence of scribal manuscript witnesses, invariably corrupted by error, can be checked against the evidence provided by other witnesses. \\n\\nThe potential benefits of this programme of research are wide-ranging. For example, our publications and CD and DVD recordings of illustrative readings from the metrical romances will enable modern readers to familiarize themselves with forgotten conventions of rhyme and rhythm; a knowledge of these conventions will help editors when weighing up the reliability of particular manuscript readings; and the data we seek to collect about imprecise rhymes and rhythmical patterns will be of permanent value for linguistic research into pronunciation, sound changes, and the perceptual salience of phonological distinctions.\\n","isTelecoms":0}
{"text":"Title: Development of High Integrity Well Abandonment Plugs Abstract: This project addresses the need for high integrity offshore oil and gas well abandonment plugs, required for the North Sea in the upcoming wave of platform removals (decommissioning). Currently, abandonment is achieved through plugging the well bore with two columns of cement up to 160 meters in length and there remain questions regarding its cost effectiveness and its ability to effectively seal long term.\nThe overall objective of the project is to develop a cost effective and high performing\nalternative to the current system of cement plugs qualified to the appropriate industry\nstandards. Specifically, this is to be a range of metal alloy plugs to act as a highly reliable, lightweight plugging and abandonment solution for offshore facilities utilisation that will be simpler and cheaper to install than the current solution. The use of metal alloy plugs for well abandonment has already been demonstrated in the onshore environment in Canada and this project will show that the principles are transferrable to the more demanding conditions seen in the North Sea.\nThe development of the solution shall be split into two phases: -\ni. Phase 0 \u2013 Material testing to confirm viability of a range of metal\nalloys as a material suitable for use in well abandonment, proving the principal of casting this material under various conditions of: pressure, temperature and aqueous solutions and determining the as cast mechanical properties of the alloys to enable detail design to be progressed.\nii. Phase 1 - Prototype design, development and manufacture of a different\nconfigurations of plugs that can be tested in accordance with the appropriate industry\nstandards determine the plug performance envelopes","isTelecoms":0}
{"text":"Title: The epithelial junction protein MarvelD3 in cell proliferation and migration Abstract: Epithelia are continuous layers of cells that delineate our tissues and organs. Individual epithelial cells interact with each other via molecular complexes that mediate adhesion but also function as sensors that transmit information about the environment, such as the presence or absence of neighbouring cells, to the cell interior. Integrity of epithelia is important for our organs to develop and function normally, and to protect us from our environment. For example, breaches in epithelial layers such as the skin or in the lining of the intestine can lead to serious infections and can occur due to chronic inflammations or acute infections by viruses and bacteria. Similarly, a characteristic of cancer cells is that they have lost the capability to sense the presence of neighbouring cells and hence continue to proliferate and migrate on top of their neighbours, or leave their tissue of origin by migrating to and invading other tissues and organs and, thereby form metastasis. On the other hand, in many adult tissues cells do no longer multiply and this can lead to reduced cell numbers and loss of normal organ function due to age or tissue damage. It is thus of fundamental importance to understand how cells in a tissue adhere to and recognise each other, how this influences their proliferative and migratory properties, and how we can exploit such mechanisms to manipulate their behaviour to address medical problems. \n\nHere we propose experiments to investigate a new mechanism that, based on our unpublished results, links adhesion between cells to the regulation of cell migration and proliferation. Our first aim is to determine how this mechanism works during epithelial repair processes and, our second aim, how it contributes to normal development of epithelial tissues. Our third aim is to use this information and address a medical problem that is caused by a lack of cell proliferation. The cornea is a tissue at the front of the eye that is required for normal vision. It is formed by an epithelium on the outside and a layer of cells on the inside, called corneal endothelium. As cells in the corneal endothelium do normally not proliferate and regenerate, their numbers decline with age or when the cornea gets damaged. If their numbers are too low, the cornea loses its transparency resulting in a loss of vision. This seriously affects the availability and quality of human corneas for transplantation that are donated to treat patients with damage to the surface of the eye. Hence, we propose experiments to test whether the here-identified mechanism can be exploited to enhance the quality of donated human corneas and thereby enhance the number of corneas that are adequate for transplantation. \n\nKnowledge of how cells sense their neighbours and transmit such information to the cell interior, and how we can manipulate such processes has a wide range of potential applications apart from the one that we will test here. The expected results will help us to think of new ways to aid wound repair after surgery and to treat devastating diseases such as chronic inflammations, certain infections and cancer.","isTelecoms":0}
{"text":"Title: Patient Specific Computational Modelling of Human Upper Airway Collapse Abstract: The upper human airway related problems have been recently recognised as a problem affecting a significant portion of the human population all over the world. One of the major human airway diseases is 'sleep apnoea', a sleep related disorder. A patient with a severe sleep apnoea can develop hypertension and severe heart disease including pulmonary hypertension, in addition to sleepless nights, traffic accidents, failure to work in the environment and marital disharmony. Though some treatment methods have been developed, they are not always user friendly and enforcing these treatment methods is difficult. Thus, no wonder that development of alternative treatment methods and improved diagnosis methods have been undertaken by many clinicians. Though many clinical trials have been conducted on human airway related problems, the understanding of the human airway diseases is far from satisfactory. The proposed 'patient specific' computational modelling, however, is expected to develop an excellent understanding of the human airway collapse, one of the major reasons for human airway diseases. The patient specific scans and some experimental flow, displacement and pressure measurements will be provided by the collaborating clinicians, who are dealing with human airway problems on a daily basis. The scans will be transformed into human airway geometries with the help of clinicians and relevant software. The collaborating clinicians will help the engineering scientists to differentiate the human airway walls and muscle from the air space. The skeleton of the geometry will be constructed using curves and surfaces. Once the geometries are extracted, a linear tetrahedron finite element mesh will be generated using the in house mesh generator. The mesh will be then used in the fluid and solid dynamic calculations. With the coupled analysis of the air and solid movement, it is expected that the model will be able to pinpoint the location\/locations of human airway collapse. The majority of the software required for the analysis will be developed within the applicant's institution and some of them have already been developed. For geometry extraction standard software referred to as 3D-DOCTOR will be used in addition to the in house software. Fluid and solid dynamic calculations will be carried out using the finite element based in house turbulent flow and viscoelastic solid codes. The development of these tools for the human airway and coupling of the proposed software are expected to be completed by the fellow within the first three years of the proposed research. The last two years of the project period will be spent to generate more patient specific data to create a data base for airway collapse analysis. Towards the end of the project a correlation between various human airway parameters such as flow rate, pressure distribution, characteristic dimensions of nasal passages, tongue, uvula and neck, airway muscle tone (muscle properties), position of sleep (gravity) and obesity factor of patients and human airway collapse will be developed. This correlation will be put together in a spread sheet form so that practicing clinicians will be able to use the software to assess human airway related diseases. All human airway problems of interest such as sleep apnoea and new treatment methods, throat cancer and speech therapies, air way corrective surgeries etc. are within the remit of the proposed project.The outcome of the proposed project will benefit enormously the clinicians dealing with human airways, patients with airway problems, computational mechanics researchers and academics all over the world.","isTelecoms":0}
{"text":"Title: Borrowing crime control policy from the USA: 'compulsory sobriety' and the rise of 'alcohol tags' Abstract: Alcohol-related crime is a policy problem that is currently attracting significant political and academic attention in the UK, and it is not difficult to understand why. Taking into account the worth of property damaged or stolen, the loss of productive output, and victim support and emotional impact, this type of crime has been estimated by the Cabinet Office to cost between &pound;8 billion and &pound;13 billion per year. Just over half of all violent incidents involve an offender being under the influence of alcohol, and in 2015 drink-driving accidents produced 8,000 casualties. Across the UK, the ratio of alcohol-related crime is eight per 1,000 people. In London specifically however, this number is higher at 12.5 per 1,000 people, with approximately 80 percent of weekend arrests by the Metropolitan Police being linked to alcohol consumption. In judging existing supply and demand-side alcohol policies to be failing, the Mayor's Office for Policing and Crime (MOPAC) scoured the world for alternative solutions. The solution found was the South Dakota 24\/7 Sobriety Project. Launched in 2005 under the direction of Attorney General Larry Long, this project involves those who have committed alcohol-fueled offences being sentenced to period of alcohol abstinence and regular testing to ensure compliance, either via a breathalyser regime or by being fitted with a continuous transdermal alcohol monitoring anklet ('alcohol tag'). Those who skip or fail their tests are subject to immediate incarceration for 24-48 hours prior to receiving a more severe sentence. \n\nSubsequent to MOPAC's initial 'Compulsory Sobriety Pilot', the idea of 24\/7 Sobriety has diffused within the UK, with the Police and Crime Commissioners for Lincolnshire, Humberside, and North Yorkshire launching a 'compulsory sobriety' pilot in June 2017. The notion of mandating domestic violence perpetrators to a period of electronically monitored alcohol abstinence has also been proposed within the May Government's Domestic Abuse Bill. 24\/7 Sobriety as a criminal justice intervention, and alcohol tagging as a technological innovation, have thus infiltrated the policy-making process and captured the imagination of political elites. Notably however, policy, debate, and evidence are not aligned in the UK at present, with evidence and discussion of the benefits and potential hazards of enforced alcohol abstinence lagging behind political ambitions. The aim of my fellowship is to address this bifurcation via undertaking a series of activities, including establishing a multi-level, multi-agency 'compulsory sobriety network', undertaking a qualitative research project that captures existing knowledge concerning the application of 24\/7 Sobriety to domestic violence perpetrators, and publishing a number of academic papers and practitioner-focused blog posts.","isTelecoms":0}
{"text":"Title: Mitigating the cyber security skills shortage: The influence of national skills competitions on cyber security interest Abstract: There is a shortage of cyber security professionals in the current labour market, which is detrimental to countries' economic development and national security. Governments have attempted to deal with this issue by designing policies targeting both the supply and demand of cyber security skills. Among these policies, national cyber security skills competitions (NCSSCs) have been widely implemented to increase the pipeline of students entering the cyber security labour market. However, scientific studies on these interventions are scarce, and many questions are still unanswered: How do participants develop an interest in cyber security before joining a NCSSC? Do NCSSCs influence participants' interest in cyber security as a topic and as a career? What factors contribute the most to influence their interest? By answering these questions, this thesis aims to discuss the role of national skills competitions as a public policy to mitigate the lack of cyber security workers.\n\nThis research used the Italian NCSSC, the CyberChallenge.IT (CCIT), as a case study as it is the skills competition in Europe that provides cyber security training to the largest number of participants. This research employed a before and after design, collecting data from non-randomised comparison groups. Data were gathered following a mixed-method approach: quantitative data were collected through two online surveys and qualitative data through 50 interviews with competition participants.\n\nThis study found that CCIT students became interested in cyber security through a mix of &quot;triggers,&quot; most notably curiosity, formal and informal coursework, and the CCIT itself. Moreover, the CCIT increased interest in both cyber security as a topic and as a career. However, participants differentiated between the two, suggesting that theory should further investigate the relationship between interest development and vocational interest. Finally, this research recommends going beyond the concept of interest to fully appreciate NCSSCs' impact, particularly by including other relevant outcome variables, such as educational and career planning, key choices, and competing interests.\n\nThis thesis argues that NCSSCs organized and implemented like the CCIT could be a valuable solution to mitigate the lack of cyber security professionals. However, on its own, a skills competition programme is unlikely to achieve what a concert of policies might in dealing with the shortage. As the shortage issue has several roots, there are limits to what a NCSSC alone can do. However, it would lay a strong foundation for other policies to further steer students into the cyber security sector.\n\nThis thesis contributes to important debates such as interest theory, the relationship between skills competitions and interest, the design and implementation of NCSSCs and ultimately cyber security education and skills policy.\n\nEPRSC Remit\nThis project falls within the EPSRC Digital Economy research area, where &quot;Trust, identity, privacy and security&quot; is one of the themes or research areas listed on this website https:\/\/www.epsrc.ac.uk\/research\/ourportfolio\/themes\/.","isTelecoms":1}
{"text":"Title: Breast Cancer: Early diagnosis using materials immortalisation Abstract: Within the UK there are &gt;55000 new cases of breast cancer diagnosed every year (world-wide &gt;1.7 million) and the economic cost of breast cancer to the UK is &gt;&pound;1.5bn per annum. Early and accurate diagnoses are critical for the most effective treatments and reduced costs. Current diagnostic inadequacies are characterised by (i) an &gt;80% false positive rate for mammography, (ii) significant overtreatment of some breast cancers, and, (iii) equivocal histopathology leading to uncertain prognoses.\n\nThis proposal will generate a new understanding of the physicochemistry of involved tissues and, as a result, will identify potential new biomarkers and diagnostic methods. We will adopt a new, multidisciplinary approach to disease diagnosis, and combine the expertise of senior clinicians with material scientists to study tissue physicochemistry. We will also exploit a distinct, retrospective approach to sampling that will enable access to unprecedented patient numbers. Successful outcomes from this work will have significant impacts for understanding disease and development of accurate breast cancer diagnostics.\n\nCalcifications within breast tissues are used as a primary marker of malignancy although the precipitation mechanism of biologically derived calcifications remains a matter of considerable debate. In contrast, the capacity of apatites to incorporate 'foreign', environmental ions at the time of precipitation is incontrovertible. Thus chemical features of tissue physiology at the point of formation become immortalised within calcifications. Precipitation of calcific phases in vivo is triggered by slight modifications to tissue chemistry and this, in the case of breast tissue, occurs at the very onset of the cancer.\n\nOur primary hypothesis then is that apatite calcification physicochemical characteristics may be employed as novel biomarkers of cancer. The primary aim of this project is to determine and understand the underpinning physicochemical characteristics of breast tissue calcifications to enable future development of in vivo, accurate diagnostic probes. The project will (a) identify archived specimen populations representing a wide range of tumour subtypes for material analyses, (b) exploit cutting edge physical methods of high resolution calcification characterisation and, (c) relate calcification physicochemistry to clinical diagnosis and prognosis.\n\nSuccessful outcomes from this work will have significant impacts for understanding disease and development of accurate breast cancer diagnostics.","isTelecoms":0}
{"text":"Title: Catalysis in Flow: Investigating Catalyst Deactivation and Leaching Abstract: Catalyst leaching from a solid support is very important issue that needs to be address before any catalytic process can be commercialised.\n\nIn a previously submitted proposal, we have described a tandem flow reactor system to examine and quantify catalyst leaching in situ under continuous flow conditions. In this specific project will be aim to measure and quantify both catalyst leaching and deactivation, in an attempt to understand this important catalytic phenomenon. The work will involve continuous monitoring of catalyst performance over time (or two different time scales). Fundamental changes in the catalyst structure can be interrogated by Operando spectroscopy. This project will allow catalyst deactivation and leaching to be observed in situ under working conditions, to afford fundamental insights as well as process parameters that are important for scale-up of catalysis under continuous flow.\n\nStrategic Themes: Manufacturing the Future. \nResearch Areas: Analytical Science, Physical Sciences, Catalysis","isTelecoms":1}
{"text":"Title: Replacing, Refining, and Reducing Animal Usage in Epilepsy Research Using a Non-Sentient Model Abstract: Epilepsy is a chronic medical condition, whereby patients experience often debilitating seizures, greatly affecting their quality of life. At least 40 million people worldwide (6 million people in Europe) have epilepsy. It has a tremendous impact not only to the individual but also to society - the estimated total cost of epilepsy in Europe in 2004 was ?15.5 billion. Current scientific research into epilepsy almost exclusively employs laboratory animals. These animal experiments, primarily in mice, lead to the accidental discovery of Epilim in 1963 as an effective drug in seizure control, and Epilim is now the most widely prescribed drug for epilepsy treatment worldwide. Surprisingly, how the drug works in controlling seizures is unclear, and this has blocked scientists from developing more effective treatments or treatments with reduced side effects. Currently, thousands of mice are killed annually for epilepsy-based experiments.\nWe have recently tested a simple, single celled organism (an amoeba, Dictyostelium) for use in replacing animals in epilepsy research. In these studies, we have identified a novel effect of Epilim in regulating a critical process in how cells signal - by reducing the processing of a family of chemical within cells. These chemicals are known to control a number of cellular functions that are over-activated in epilepsy, thus this effect is likely to be involved in epilepsy control. We have also confirmed that these experiments are related to epilepsy control since we have tested one drug identified in Dictyostelium in mice and show the novel drug has better seizure control effects than Epilim. \nThe project outlined here will thus develop Dictyostelium as a model for epilepsy research. The model will be used to identify new epilepsy treatments and to understand the basis for the drug action, and then test a small number of lead compounds in animal models. Final compounds will be tested in refined chronic seizure models. This project will therefore develop a simple model to replace and reduce and mice in epilepsy research, and refine experiments on long-term seizure control. We estimate that in this project, screening 40 compounds will need 100 animals, reducing animal usage in the development of these drugs by 3900. The project is highly likely to help to unravel the complex way in which Epilim stops epilepsy in the human population and to develop new treatments for epilepsy.","isTelecoms":0}
{"text":"Title: A Criminological Investigation into the Operation and Effects of Structural Violence on Migrant Offenders within Italy's Criminal Justice System Abstract: Despite representing a mere 13% of the Italian population, immigrants make up 32.5% of the prison population (Antigone, 2020). This research project will examine the reasons behind this overrepresentation, a subject that has received scant academic attention hitherto. An overwhelming focus on administrative immigration detention (see, for instance, Aliverti, 2012; Franco and Bosworth, 2013; Canning, 2017) has, in fact, left the criminal prosecution of migrants largely overlooked. This is a prominent gap in the academic literature that this research aims to address. In particular, this research aims to investigate the relationship between migration, individuality and criminal justice; the contribution of the Italian criminal justice system in the overrepresentation of immigrants in criminal incarceration, to assess whether its functioning acts as a structural expression of oppression which transforms migration into an issue of law and order needing pronounced punitiveness; the contribution of the Italian criminal justice system in the production of oppression and marginality in relation to migration, and how these crystallise into social harm; finally, what works, what does not work and what is promising in terms of mitigating the structured risk of the Italian criminal justice system for injustice in relation to migration. \nIn order to address its aims, this research employs a multiple case study research design of three Italian cities. Rome, Milan, and Florence were purposively selected because they possessed the highest numbers of incarcerated migrants (after sentencing for a criminal rather than administrative offence), as recorded on 31 July 2020 (Antigone, 2020). Significant background data will be obtained and analysed through drawing on case information (i.e., types of crime or length of sentence, ethnicity, country of origin, age, and anything additional), legal and policy documentation. Data collection methods will also involve individual in-depth interviews, which will be utilised for favouring the sharing of personal individual experiences, as well as focus group, for discussing compelling macro level issues around the overrepresentation of immigrants in criminal incarceration. Data will be examined through discourse analysis, which will help understand how participants construct meaning through the language they use in relation to their lives, social structure, and power dynamics. Participants will be migrants who have had contact with Italy's criminal justice system, recruited through snowball sampling; and criminal justice practitioners, community representatives and humanitarian stakeholders, who will be purposively located to select individuals who are knowledgeable about the issues this research aims to address.","isTelecoms":0}
{"text":"Title: Productivity Insights Network Abstract: UK national productivity challenges can be analysed from many different perspectives, including firm-specific, industry-specific, organisational-specific, institution-specific or technology-specific perspectives. In the case of the UK, however, the extent to which productivity problems are regional in nature is almost unparalleled amongst the advanced OECD economies. London and the core regions of southern England exhibit very strong productivity performance by OECD and EU standards whereas the non-core regions of the UK consistently exhibit weak productivity performance by OECD and EU standards. These non-core regions consistently display a very long tail of poor productivity firms, operating alongside numerous high productivity firms in London and its hinterland. \n\nWhen compared to OECD and EU averages the non-core tail of poor performing firms hampers national productivity performance by largely cancelling out the stronger performance of the firms in the more prosperous core regions. The result is that UK productivity has barely changed relative to our international competitors in more than four decades. Yet, these longstanding and growing interregional differences in productivity performance are the very aspect of the UK's productivity performance about which we probably know the least. Therefore, in order to better understand the UK's productivity challenges, we employ a place-based lens to investigate the extent to which many UK productivity-enhancing and productivity-inhibiting processes are related to geography. \n\nThe proposed Productivity Insights Network incorporates these analytical perspectives in a manner that explicitly uncovers the local, city and regional dimensions of productivity performance. This is achieved by developing an innovative multi-disciplinary network though with the thematic productivity challenges aim to unpack the complex interactions between factors of production across different institutional and geographical settings. The network is structured around seven thematic productivity challenges which are addressed and integrated by interdisciplinary teams of experts examining five sets of interaction mechanisms, all operating in a geographical setting. \n\nThe thematic productivity challenges addressed are: a) Skills, education and training b) Employment, work and labour markets; c) FDI, capital and investment markets; d) Health, well-being, ageing and demographic change; e) Technology, innovation, competitiveness, and enterprise; f) Organisation, institutions and governance; and, g) Land use, transport and infrastructure. The five different interaction mechanisms we examine are: 1) knowledge spillovers and interactions; 2) financial interactions; 3) organisational interactions; 4) social interactions; and; 5) governance interactions. These different lines of enquiry are knitted together via four work packages (WPs), namely: WP1. Network Management; WP2. Thematic Productivity Challenges; WP3. Integrated Analysis; and, WP4 Engagement, Dissemination &amp; Learning Activities. \n\nThis Sheffield-led Productivity Insights Network proposal will co-produce new social science insights with a range of partners from the public, private and third sectors, with a view furthering our understanding of the UK productivity puzzle and develop actionable outcomes. Beyond generating new perspectives the Productivity Insights Network will also identify policy options best suited to responding to the UK's productivity challenges. This proposal has been developed in consultation with over 50 academics well as with other non-academic partners and networks, and if funded the NW+ will pursue a portfolio of new interdisciplinary activity. The multi-disciplinary Productivity Insights Network will see early career researchers and established scholars working together in order to develop and disseminate new insights through the network to government, businesses and other stakeholder organisations.","isTelecoms":0}
{"text":"Title: Star Seekers - New Frontiers Abstract: Our project will;\n- Provide access to a new Herschel planetarium experience\n- Upgrade the museum star vault for live streaming of lectures, talks and workshops\n- Develop new content that connects the Herschel story with modern developments in astronomy\n- Build partnerships with institutions, organisations, staff and volunteers in astronomy, connecting them with new and diverse audiences to inspire, inform and excite them about the subject of astronomy.\n\nUsing the unique location of the museum, the very spot where William Herschel discovered the planet Uranus, we will bring novel, high-quality public engagement activities to a wide variety of audiences including visitors, community groups (including mental health support organisations), academic groups and students at both primary and secondary stages of their education. We will uniquely highlight how the sky as it was perceived by William and Caroline Herschel during the Georgian era, can be seen today and how it differs thanks to modern developments in technology and scientific understanding. Through this work we will involve our target audiences with stories of STFC science and technology, also looking to inspire them to make personal connections with the subject matter and develop their own interests in astronomy.\n\nThis key element of the project addresses a need in the South West of England, where there is limited access to planetarium experiences. Schools and groups we have not previously engaged with through our educational workshops and outreach, have expressed an interest in this unique opportunity and have confirmed they would host planetarium sessions in their schools. Through our schools programme we are already engaged with many of the local Bath schools, including those whose pupils come from areas within Bath that are included within the 10% most socioeconomically-deprived areas of the UK. Many of these pupils do not have English as their first language and this project presents an opportunity to bring astronomy, solar and planetary science to life for this audience and provide new, direct engagement through exciting new technology to which they can relate.\n\nUpgrading our equipment would enable us to develop a new event programme in the star vault so that we can reach new audiences in the Museum itself. It widens the scope of our event programme, providing opportunities to build a regional audience for academic lectures, live streaming and talks in Bath from other national and international locations, for which the Royal Astronomical Society will partner with us. \n\nThis project would also enable live streaming during workshops in the star vault with colleagues in the field around the world, bringing them into the room to engage with our diffferent community and education groups. Colleagues at the European Space Agency have indicated their interest in taking part in this initiative. This new equipment would enable streaming of live star gazing events in the star vault when bad weather prohibits live viewings from telescopes, as well as displaying new digital content that addresses different themes depending on our audience, exhibition or access to new research as it becomes available. \n\nThrough the key project elements (planetarium experience, star gazing and astronomy events, lectures, talks and live streaming in the star vault), we are striving to bring astronomy and solar and planetary science to life in a way that is exciting, relevant and inspiring to a wide variety of audiences. We seek to do this through the provision of 'wow' moments driven by an audience led approach that is also supported with carefully considered content, delivered with academic integrity in engaging ways. We will endeavour to use this project to highlight the achievements of STFC science and technology, demonstrating the excitement of research and the value of STEM to the UK, as well as its wider impact on society.","isTelecoms":1}
{"text":"Title: Supporting the development of marine protected area management plans based on fundamental science Abstract: The UK has an extensive network of marine protected areas (MPAs) and they form a fundamental part of the UK marine conservation and management strategy. The Marine Management Organisation (MMO) is responsible for the 77 English Marine protected areas. Of these, less than a third currently have a management plan. Management plans have been shown to be essential for effective MPA implementation; without them MPAs are less likely to meet their objectives. Lack of management plans for the UK Natura sites, a network of European protected areas, has led to the UK facing possible infraction charges from Europe for being in breach of our duties under the Habitats Directive, which could result in substantial fines. Thus there is a need for the MMO to develop a large number of robust MPA management plans, quickly. MPA management plans can have substantial consequences, not just for the marine environment they are designed to protect, but also for the coastal communities that depend on marine resources. Both ecological and socio-economic impacts must be considered alongside resourcing, feasibility, existing management provisions and the plethora of policy and legislation associated with UK MPAs. Just like the designation of MPAs, it is essential that the development of management plans is strategic, holistic, and uses the best available science.\n\nThe overarching aim of this three year project is to support the development of marine protected area management plans, underpinned by cutting edge science. The project will work in close conjunction with the marine management community (MMO, DEFRA, JNCC, CEFAS and Natural England) and outputs will be tailored to maximise their utility to the ongoing work of the MMO. The project will entail a series of strategic literature reviews and an estimated nine workshops. Workshops will be attended by both members of the marine management community and researchers, and they will focus on either filling gaps in the knowledge or developing decision support tools. In years one and two, the project will develop and populate a database on English MPAs, including the features they are designated for and the socio-economics of the coastal community's local to them. The project will also develop a classification scheme, in conjunction with the MMO, which will be used to categorise the strength of evidence contained within that database. In the third year, two workshops will be held to develop a matrix of different MPA management options. Finally, over two further workshops, a decision support framework for MPA management plans will be developed and trialled. This project will involve reviewing both completed and ongoing research and will be supported by a range of academics, including: Professor Callum Roberts, Dr Jan Hiddink, Professor Simon Jennings and Professor Hugh Possingham.\n\nThe project also aims to contribute to future NERC-MMO partnerships activities. Part of this project will involve feeding back to researchers about how they can tailor their research outputs and plan future projects to increase their utility for informing marine protected area management decisions, and hence how they can increase the impact of their work. This part of the project will undertaken in collaboration with Dr Abigail McQuatters-Gallop at University of Plymouth, who is a current NERC KE Fellow undertaking a related project KE project.\n\nThis project will advance the uptake of science into marine management decisions by improving availability of evidence and by providing a framework to support the incorporation of that evidence into governance. In doing so, it will contribute to increasing the impact of associated academic research. The outputs of this project will aid decision makers to simultaneously consider the complex marine environment, the diverse range of stakeholders that use it, the plethora of both national and international policy and legislation, and the realities of resource availability.","isTelecoms":0}
{"text":"Title: Impacts of Atmospheric Turbulence on Wind Turbine Main-Bearing Function and Failures Abstract: The continued expansion of wind energy within nations' energy portfolios requires continued reductions in\nthe levelized cost of energy (LCOE), the ratio of financial cost to purchase and operate wind farms to financial\ngain from the electrical power produced by the wind farm. Major contributors to the numerator include\nreplacement costs for premature component failure on the drivetrain, including, in particular, the main bearing\n(Hart et al. 2020a). Whereas main bearing failure is likely not subsurface fatigue-related (Hart, et al. 2019) and\na number of potential mechanisms likely contribute, the dominant processes underlying premature main\nbearing failures are not currently known (Hart, et al. 2019,2020a). Work has been undertaken to develop a\nsystematic approach to the study of main bearing loading and failure mechanisms (Hart 2020b); wherein, it is\ndemonstrated that a detailed understanding of the loads experienced by the main bearing, and their causal\nmechanisms, is a necessary prerequisite to progress in this field. The proposed research programme centers on\nthe hypotheses that (1) the mechanisms underlying premature main bearing failures result from specific\nrepetitive time changes in the bearing load-zone, and (2) that these deleterious load-zone forcings are in\nresponse to specific temporal characteristics in the moments and forces on the main shaft that result from the\npassage of the energy-dominant atmospheric turbulence eddies through the wind turbine rotor plane.\nUtility-scale wind turbines and wind farms respond to turbulence within the &quot;atmospheric boundary layer&quot;\n(ABL), the 1-2 km region of the troposphere adjacent to the earth's surface. During the day, the structure of the\nturbulence eddies transported within the ABL is driven by strong convection and strong shear, a coherent eddy\nstructure that varies systematically with the global stability state of the ABL (Khanna &amp; Brasseur 1998, Jayaraman\n&amp; Brasseur 2014). As the eddies interact with rotating wind turbine blades, high temporal variabilities in\naerodynamic loads pass from the rotor hub to the main shaft in the form of torque, bending moment and axial\nforce fluctuations (Vijayakumar, et al. 2016) with three characteristic time scales (Nandi, et al. 2017) in main\nshaft moments (Lavely 2017). The shortest of these is below 1 sec. with relative variability on order 50%\n(Vijayakumar, et al. 2016). Lavely (2017) showed that, whereas main shaft torque fluctuations respond to rotoraveraged\nhorizontal winds, shaft bending moment fluctuations respond to time changes in spatial asymmetry in\nhorizontal velocity over the rotor plane, generated as turbulence eddies pass through the rotor.\nIf the above hypotheses are valid, it follows that the turbulence-generated deleterious load fluctuations on\nthe main bearing are likely driven by different classes of turbulence structure and loading response at different\ntime scales as atmospheric eddies pass through the rotor plane. Since ABL turbulence structure varies with\natmospheric stability, deleterious load characteristics change during the day and among seasons, as well as with\ntopography. Furthermore, within a wind farm the hypotheses can be extended to include potential deleterious\nmain bearing responses to combinations of atmospheric and rotor wake turbulence eddying motions due\nespecially to the generation of spatial asymmetries over wind turbine rotor planes.","isTelecoms":0}
{"text":"Title: CoMP-O-RAN Abstract: Coordinated Multipoint Open Radio Access Network (CoMP-O-RAN) is revolutionising the performance and cost of densified 5G New Radio (NR) outdoor small cell clusters.\u00a0 The integration of standard Open Radio Access Network technology with mmWave transport systems enables the deployment of disaggregated multi-transmission and reception multi-node 5G NR without the need for excessive fibre which drives down capital-intensive deployment costs. At the same time, CoMP-O-RAN is providing enhanced radio performance in the form of better coverage and higher capacity. This enables 5G operators to deliver excellent 5G at significantly lower \u201ccost per bit\u201d. \u00a0 The project is developing a novel 5G NR CoMP algorithm and software implementation plus a new 5G RAN product with an integrated mmWave transport. It covers the full lifecycle from concept design through to prototype hardware and proof-of-concept deployment and validation in preparation for mass commercial manufacture and deployment. \u00a0 CoMP-O-RAN, as a project, is generating highly skilled UK 5G technology employment, leading to additional manufacturing and supply chain development here in the UK.\u00a0 Where possible the project is sourcing in areas of regional inequality, building on the governments levelling up agenda and industry 4.0 strategy to promote digital skills. The Coordinated Multipoint Open Radio Access Network (CoMP-O-RAN) will deploy densified outdoor small cell clusters using 5G New Radios (NR) to complement existing mobile networks, reduce the cost-per-bit and deliver enhanced 5G network performance. The project is led by 5G Neutral Host Operator Dense Air, working with Airspan Communications, Blu Wireless, Radisys and the University of Glasgow. Building radio backhaul into a cell significantly reduces the need for expensive fibre installations. At the same time, CoMP-O-RAN will provide enhanced performance in the form of better coverage and higher capacity.\u00a0 This will enable mobile network operators to deliver excellent 5G at a significantly lower cost-per-bit and enabling faster deployment timelines by removing the need for the installation of fibre backhaul at each cell in a cluster. This project will develop a novel 5G New Radio CoMP algorithm and software implementation, plus a new 5G RAN product with an integrated mmWave fronthaul capability developed by Blu Wireless. The project encompasses the full lifecycle, from concept design through to prototyping and proof-of-concept deployments, which will be used for validation in preparation for mass commercial deployment. It is anticipated that the product, developed and prototyped in the UK will be widely exported, initially targeting markets where Dense Air operates. The solution will be validated at the AutoAir testbed at the Millbrook automotive proving ground, an existing DCMS 5G funded project, providing a secure environment to evaluate and document the solutions impact in real-world scenarios ahead of scaled commercial deployments.","isTelecoms":1}
{"text":"Title: New methods for precision predictions at the LHC Abstract: Experiments carried out during the first phase of the Large Hadron Collider (LHC) have produced one of the most fundamental discoveries in recent times through the observation of the Higgs boson. Predicted more than 50 years ago this last missing ingredient of the Standard Model offers an explanation for the origin of mass and electro-weak forces. Despite this, the origins of the Standard Model and it's place within models for cosmological and astrophysical observations remain unclear.\n\nThe second phase of the LHC, which runs until 2018 at twice the energy of phase one, aims to study the properties of this new boson and uncover the true structure of the electro-weak symmetry breaking scale. Astrophysical and cosmological observations predict new forms of matter and energy as yet unexplained by the Standard Model and there are many conjectured theories which point towards new physics around the electro-weak scale at an energy of 1-2 TeV.\n\nStudies of the data from run I of the LHC indicate the expected signals of new physics may be harder to find than originally hoped and it is for this reason that precision predictions and detailed analyses will become the focus for future LHC experiments. The project &quot;New methods for precision predictions at the LHC&quot; addresses the need for new theoretical tools which currently limit our ability to make precision predictions at hadron colliders like the LHC.\n\nHadron colliders produce huge amounts of strongly interacting radiation that must be precisely modelled if we hope to find the tiny signatures that high energy models of new physics predict. This is an extremely challenging task within the framework of Quantum-Chromo-Dynamics (QCD), our model for the strong interaction, where even perturbative approximations quickly run into areas pushing the boundaries of mathematics and computational power. Owing to the relatively large size of the strong coupling constant, high order expansions within QCD are required in order to keep the theoretical uncertainties under control and in line with the experimental errors.\n\nDespite these challenges remarkable progress has been made in recent years that now allow predictions at next-to-leading order in the pertubative expansion to be made for a wide variety of different processes. A particular highlight of these developments is the ability to look at high multiplicity processes which give access to much more flexible analyses. However, these methods are restricted to an accuracy of between 10 and 20% which is above the projected precision expected from phase two collisions. In order to make sure the theory is ready to handle the new data we must now focus on finding new solutions for higher multiplicity QCD predictions at higher order in perturbation theory and push predictions towards 5% precision.\n\nNew mathematical methods developing through formal studies of super-symmetric theories can offer elegant solutions to the problems of computational complexity. To apply these techniques to the QCD environment requires significant extensions however and high degrees of automation and we will develop state-of-the-art analytic tools to compute the necessary amplitude level ingredients. Elements of algebraic geometry and number theory are finding their first applications outside pure mathematics in these studies and the research gives us the opportunity for fruitful discussions between the two disciplines.\n\nA small group will be established within the expert theory group at the University of Edinburgh to study the application of new mathematical techniques in QCD and SM theory. These ideas will be implemented inside public codes that can be used in future experimental analyses when interfaced to Monte-Carlo event generators use to simulate the collisions. By focusing on the theoretical and mathematical techniques now we will be able to perform flexible phenomenological studies of the Standard Model and beyond in the next decade of LHC experiments.","isTelecoms":0}
{"text":"Title: Investigating the role of mindfulness and implementation intentions in mitigating unintended negative consequences of information and communication Te Abstract: Information and communication technologies (ICTs) have become a pervasive part of our day-to-day\nworking lives. Their benefits, including unprecedented levels of connectedness and productivity, are\nwell understood. However, the same technology that is providing organizations and individuals with\nso much opportunity also comes with a 'dark side' that includes a body of unintended negative\nconsequences (D'Arcy et al. 2014). Pirkkalainen &amp; Salo (2016) have identified four 'dark side'\nphenomena: technostress, information overload, IT 'addiction' and IT anxiety. These phenomena\nthreaten to make individuals' relationship with workplace ICTs a toxic one that can have damaging\nconsequences both for individual well-being and organisational outcomes (e.g. Maier et al. 2017,\nAgogo &amp; Hess 2018). This PhD will examine how these 'dark side' phenomena manifest for working\nindividuals and explore the potential of mindfulness and implementation intentions as mitigation\nmechanisms.\nAlthough there is no universally agreed conceptualisation of mindfulness in the academic literature,\nmost definitions agree that attention and awareness are at its heart (Ioannou, Papazafeiropoulou &amp;\nSpanaki 2018). Perhaps one of the best known and widely used definitions is that of mindfulness\npioneer Jon Kabat-Zinn (1994, p.4): &quot;Mindfulness means paying attention in a particular way: on\npurpose, in the present moment, and nonjudgementally.&quot;. The most frequently evidenced and cited\nbenefit of mindfulness is stress reduction in individuals (Ioannou, Papazafeiropoulou &amp; Spanaki\n2018). While there is also limited research suggesting that it may help individuals mitigate the\nunintended negative consequences of technology use (e.g. Miller &amp; Brannon 2017, Wolf, Pintner &amp;\nBeck 2011), this area appears to be under-explored at present.\nNotably, Chatzisarantis and Hagger (2007) found that mindfulness can facilitate the translation of\nintentions into actions, paralleling the approach of implementation intentions. Implementation\nintentions are if-then plans that link environmental cues with specific responses, strengthening the\nnormally weak link between intention and behaviour, thereby facilitating goal attainment (Gollwitzer\nand Sheeran 2006). The relationship between mindfulness and implementation intentions has yet to be\nexplored and it is possible that the two may operate in a similar way or may interact to increase\noverall effectiveness. For instance, mindful awareness may aid mechanisms by which implementation\nintentions work, such as creating and strengthening implicit associations; and implementation\nintentions could be developed specifically to support intentions to be mindful in particular\ncircumstances.\nCommencing with a diary methodology with a sample of individuals currently in the workplace, the\nPhD will explore the predictions that:\n1. Individuals who are higher in mindfulness are less likely to experience the unintended\nnegative consequences of work-related use of ICTs.\n2. Developing mindfulness can support individuals' coping ability and self-regulation in relation\nto work-related use of ICTs, thereby helping mitigate unintended negative consequences.\n3. Mindfulness and implementation intentions can work synergistically to help individuals using\nICT for work to mitigate any unintended negative consequences.\nThe proposed research aims to advance academic understanding of the unintended consequences of\nwork-related ICT use, the ways in which mindfulness and implementation intentions operate, and\ntheir potential as mitigation mechanisms. Practically, the research findings will produce a template for\nbehaviour interventions to reduce negative impacts of work-related ICT use. It will also provide\nguidelines on how organisations can support the reduction of technostress, information overload, IT\n'addiction' and IT anxiety among workers.","isTelecoms":1}
{"text":"Title: Knowledge Transfer Secondments - University of Leeds Abstract: This Knowledge Transfer Secondments (KTS) grant will provide funding to help ensure the exploitation of the research funded by EPSRC at the University of Leeds. It will operate on the principle that the best way to transfer knowledge is to transfer people. Based on the Research Assistants Industrial Secondments (RAIS) scheme previously available from EPSRC, it will allow movement of skilled people both into and out of the University of Leeds.KTS funding will be used to support secondments of staff previously employed on an EPSRC grant or grants, to enable them to take their results further on towards application by users. KTS funds may also be used for inward secondments, supporting a specific research project carried out in the HEI by someone employed by a user organisation. In all cases there will be a strong connection between the secondment activities and one or more EPSRC-funded research projects.","isTelecoms":1}
{"text":"Title: Exploring New Configurations of Network Politics Abstract: The way in which social structures have been reoriented in the wake of new media, particularly the internet, have led to the claim that we are now living in a 'network society', a term coined by Manuel Castells. Such a shift has profound implications for all areas of life, including politics in all its forms.\\n\\nThe aim of this project is to map the challenge to traditional politics (including cultural politics) that this network society poses. In particular the widely held perception that representational democratic politics are under question. We see political hierarchies undermined by networks, claims to specialist knowledge increasingly coming under strain, and notions of the political subject, as defined by a vote every four or five years, no longer making sense in this new situation. Thus we aim to explore the idea that there may be a new kind of politics, and a new sense of what the political might entail, coming to fruition. We aim to develop a perspective on what this might be, through an address to emerging theoretical approaches and to new forms of political practice, both at the grass roots and the formal institutional levels of politics. \\n\\nTo achieve this aim the project will gather together established and emerging scholars who will address topics including: the alter-globalization movement; social networking as a new political force; hacking as a new paradigm of dissent. Also to be explored is a range of new concepts and social forms, for example: smart mobs; viral campaigns; open source production; collective intelligence; rhizomatic multitudes, amongst others. Naturally the technologies of new media that make this all possible will also be a key site of enquiry, and will be a central theme across the whole project.\\n\\nThe project, as well as having a predefined agenda, must recognise the reality that this may not be sufficient to capture the complex emerging phenomenon described. Thus the need for flexibility and adaptability will be recognised and encouraged. For example, the network will work towards a new, more immanent analysis of the emerging forms of social relations, identities, political forms, discourses and activism. This should include innovative approaches to grasping collective ways of being, organising and interacting, and what these will be is likely to only emerge as part of the process of the project. Hence, instead of starting with an entirely predetermined agenda, the networking project aims to stay open to new conceptual and thematic approaches. \\n\\nOf course, we do have to start by engaging existing frameworks of thought, and will therefore draw from a broad cannon to encourage a flexibility of approach. Here thinkers such as Giorgio Agamben, Alain Badiou, Gilles Deleuze, J&uuml;rgen Habermas, Douglas Kellner and Antonio Negri, will be drawn upon. Beyond this the network will critically evaluate the existing agenda in mainstream politics and the media, and try to find blind spots, neglected issues and novel ideas for further collaboration.\\n\\nThus the guiding rationale for the network will be to draw on a broad range of expertise from different disciplines within academia. These will be primarily media and communication studies, philosophy, social theory and cultural studies, but will address the broader community to include knowledge from other sources and institutions via, for example, artists, practitioners, activists and technologists. \\n\\nAs a global phenomenon, international perspectives are imperative. As such the network will draw contributions from a wide range of economic, geographic and cultural points of view. In this context, the research expertise of Northern American scholars, with theoretically innovative interdisciplinary centres and the role of the U.S. as an economic and technological hub, are of high significance for the network. Similarly significant will be the development of links with institutes in Asia and continental Europe.","isTelecoms":1}
{"text":"Title: Many-Body\/QFT theoretical Condensed Matter Physics Abstract: Awaiting project information","isTelecoms":0}
{"text":"Title: Debt deleveraging, stagnation traps, and the optimal design of monetary, fiscal and exchange rate policy Abstract: Debt deleveraging, stagnation traps, and the optimal design of monetary, fiscal and exchange rate policy","isTelecoms":0}
{"text":"Title: ESR1 mutation profiling identifies potential drivers of metastatic breast cancer Abstract: Breast cancer is the most common cancer in the world, being responsible for 1 in 4 cancer diagnoses and 1 in 6 cancer deaths in women every year. The female hormone estrogen promotes both breast cancer development and its progression. The estrogen receptor (ER) protein mediates the cellular actions of estrogen. Estrogen binding to ER is necessary for activation of the ER. The activated estrogen-bound ER protein stimulates breast cancer development by inducing expression of the genes that work together to drive breast cancer growth. The majority (&gt;70%) of breast cancers are ER-positive and standard-of-care drug treatments for ER-positive breast cancer work by blocking ER activity. These &quot;endocrine therapies&quot; are proven, effective treatments for reducing illness and death from breast cancer. However, many patients relapse. Rates of recurrence, inevitably of endocrine therapy refractory metastatic disease, remain constant even several decades after original diagnosis and surgical removal of the tumour from the breast, necessitating the development of new treatments.\n\nRecent advances in DNA sequencing have revealed that the ER gene is mutated in up to 40% of patients whose tumours recur. These mutated ER proteins are constitutively active such that their activity is not blocked by endocrine therapies. Consequently, breast cancer patients with mutant ER cannot be controlled with endocrine therapies. \n\nEstablished breast cancer cell lines originally isolated from patient tumours provide an invaluable resource for studying mechanisms of cancer cell growth and for identifying approaches for killing cancer cells and for developing and testing new cancer drugs. We have used state-of-the-art CRISPR technology to engineer all the common ER mutations in breast cancer cell lines. These cell lines recapitulate the resistance to endocrine therapies that is observed in patients. By comparing gene expression profiles in ER mutant cells with those in endocrine therapy responsive, ER wild-type breast cancer cells, we have been able to identify a very small number of genes that are specifically activated in breast cancer cells that are making mutant ER. We have found that these mutant ER-specific genes are strongly predictive of poor likelihood of patient survival, evidencing their potential importance for endocrine therapy resistant breast cancer. The most prominent of these genes is itself a regulator of gene expression and has a well-known function in regulating cancer cell survival in other tumour types. \n\nWe hypothesise that activation of this gene plays important roles in the enhanced survival and invasive properties of ER-mutant breast cancer. By using molecular approaches to manipulate the levels of this gene in ER wild-type and ER mutant breast cancer cells, either by over-expressing it or by &quot;knocking-out&quot; the gene, we can investigate the mechanisms by which this gene drives breast cancer cell survival, metastasis and to progress to identifying new treatment opportunities in this large group of very difficult to treat breast cancer patients.","isTelecoms":0}
{"text":"Title: Optimising CNC Machine Tool Coolant Fluid condition to prolong usage and efficiency of an expensive essential resource thereby reducing cost, improving production quality and protecting operators using a unique and innovative Coolant Monitoring Analyser Abstract: The aim of the project is to create the first automated monitoring unit that will provide live data to a cloud based system including Temperature, PH, Concentration (Brix), and Bacteria \/ Fungal Growth which will enable real time and predictive reactions to changes in fluid condition allowing for less aggressive treatment to maintain optimal efficiency and extending the life span of the coolant.","isTelecoms":0}
{"text":"Title: Performing Activity Recognition on Unscripted Culinary Activities in a Living Lab Abstract: Culinary activities, including the preparation and consumption of sustenance, have the\npotential to provide valuable insights into the mental and physical health of individuals.\nBehavioural habits or variances which may become evident through monitoring of these\nprocesses can be symptomatic of conditions such as diabetes, obesity, depression and\ndementia. Therefore, autonomous monitoring and understanding of activities that take place\nin the kitchen is an important goal that if achieved could improve the lives of many people in\nthe comfort of their own homes.\nA key part of autonomous home monitoring systems is activity recognition, as this allows for\nmachine understanding of human situations and actions. This project focuses on\nknowledge-based activity recognition, since this has more flexibility for smaller data sets.\nThe sequences used to create and test our model will be recorded in the Bristol SPHERE\nhouse, which already has an assortment of cameras and sensor installed. Sequences will\nbe unscripted, allowing for a wide range of interesting and challenging behaviours.\nA Computational State Space Model will form the foundation of the recognition system, with\nmarginal filtering used to determine the most likely state at each moment in time. During the\ncourse of the project, elements of this will be enhanced or upgraded in order to improve\nmodel performance. Action recognition will be improved through the integration of visual\ndata through Convolutional Neural Networks, which will be compared to current feature\nbased approaches in terms of speed and accuracy of classification. In addition, recognition\nwill be improved to ensure that classification is invariant to different locations and system\nconfigurations. Activity recognition will be upgraded to allow the model to process activities\nperformed by multiple individuals in the same environments. Additional improvements will\nbe made to improve efficiency by reducing the overall state space through simple logical\nchanges. Data permitting, data-driven approaches to activity recognition will also be trialled\nand compared to previous methods.\nThe implications of this project are wider reaching than it's use in the kitchen. Applications to\nother environments or situations could have a wide range of different uses in many different\nsectors. Mainly, this project also builds upon and enhances the work being done by the\nSPHERE project.","isTelecoms":1}
{"text":"Title: Advanced GaAs Based Laser Fabrication (Feasibility Study) Abstract: GaAs materials research has extended the operating wavelengths of devices to those used in telecommunications and medical diagnostic applications, and offers a number of advantages over incumbent InP based devices. These revolve around the use of larger substrates leading to cost reductions, and greater band offsets allowing higher temperature (or uncooled) operation of a device through improved carrier confinement. However, GaAs based device fabrication is rather immature, with GaAs lasers typically only available as Fabry-Perot ridge structures, which exhibit highly asymmetric output, surface recombination, and broad emission spectra. Technologies such as distributed feedback (for single mode operation) and buried heterostructure lasers (symmetric output, reduced surface losses) are commonplace in commercial InP devices. The development of GaAs based buried heterostructure devices in this proposal relies upon a novel approach in circumventing deleterious regrowth upon exposed AlGaAs, allowing buried heterostructure technology for GaAs based materials. GaAs based buried heterostructure lasers will be developed and assessed in terms of electrical and optical performance, in particular the spatial profile of the optical emission using far field analysis techniques. Solid source and gaseous epitaxial overgrowth methods will be assesed and compared under various conditions. Buried gratings (distributed feedback) will be developed, initially for use in a single mode ridge laser, before ultimately incorporation in a buried heterostructure distributed feedback laser.","isTelecoms":1}
{"text":"Title: Frugl Abstract: The application is to fund the development of a piece of software that allows the user to scrape data from any website containing information about events and collate that information into a spreadsheet that can be filtered and uploaded onto a website or mobile application.","isTelecoms":0}
{"text":"Title: Unlocking Historic Landscapes in the Eastern Mediterranean Abstract: Byron's evocation of the 'Isles of Greece' in his epic poem Don Juan contrasted their plight under Ottoman oppression with the glories of an ancient Hellenic past. This perspective, partly derived from the study of the Classics, has determined how the landscapes of the Aegean and western Turkey have often been studied as the settings for historical events rather than as a source for the lives and activities of past societies. Although field survey and research overt he past thirty years have transformed our understanding of many Mediterranean landscapes, there is still a tendency to focus on the classical and earlier periods. By contrast, the lives of medieval and post-medieval people (Byzantine, Venetian and Ottoman) and the rural landscapes they created have been sadly neglected. If we are to achieve a proper understanding of the Mediterranean past we must address these periods, not least because it was during then that the vast majority of surviving monuments and landscape features were created.\\nThe frequent political tensions between Greece and Turkey over the past 70 years have not encouraged comparative archaeological studies, especially for the post-classical periods. Our research programme provides the opportunity ot foster new academic links and collaborations. More importantly, by studying these two regions we aim to focus on the experiences of a common Byzantine and Ottoman past reflected in their landscapes. We have chosen to compare two quite different landscapes, one in the hinterland of a small Byzantine and Ottoman city now in western Turkey (Silivri) and the other a rural Greek island (Naxos). Both study areas possess in rich monumental evidence including roads, fortifications, monasteries and churches. This has the potential both to help understand the patterns we identify in the landscape, and also to allow us to engage with themes such as memory and belief, further enriching our understanding of the social context.\\nOur research will adapt and use a new technique developed in Britian (Historic Landscape Characterisation - HLC) for the first time in the eastern Mediterranean. HLC is a method for mapping the landscape that reveals how and when the different elements of it were created. Using Geographical Information Systems (GIS) we will integrate data from historical, archaeological and other sources to create detailed, long-term landscape histories of our two case studies, before comparing them with one another.\\n\\nWe will investigate:\\n- How we can use cost-effective new methods to understand Mediterranean landscapes\\n on a large scale.\\n- How the rural landscapes of the Aegean have been shaped by social and economic \\n life over the last 1500 years.\\n- Whether the pace of change has been comparable in two study areas, or whether there\\n have been periods when people have changed some rural landscapes much faster \\n than others.\\n\\nUnderstanding the development of the cultural landscape is a crucial issue for historians. Its importance goes far beyond us, however. Cultural landscapes form the backdrop to our lives and provide a key element in our sense of place and identity. It is essential that we understand them so that we can manage them effectively and develop them substainably. By revealing the value in regional landscapes and the rela nature of similarities and differences between regions, this research will have implications for ordinary people, planners and policy-makers from the local to the international level. The results of our research will be accessible to all of them through publications and our website.","isTelecoms":0}
{"text":"Title: Newton Fund - Renewable energy source based on the recovery, purification and storage of hydrogen from chlor-alkali plants Abstract: Clean Fuel from Industrial Process By-Product\n\nWhere distributed industrial chemical facilities are deployed it is often difficult to fully utilise all the by-products into useful end-products, and in the case of small, distributed chlor-alkali plants the by-product hydrogen is often vented. Hydrogen can be used as a clean fuel for transport applications with the significant advantage that it burns cleanly, improving air quality. To be fully utilised as a clean transport fuel, chlor-alkali hydrogen must be pressurised and existing technology is energy inefficient and expensive. This project aims to develop an electrochemical hydrogen compressor (ECHC) that perform at least some of the stages of the compression need to make wasted hydrogen a useful resource.\n\nAn ECHC works by breaking down a hydrogen molecule into hydrogen ions and then using a low cost electrical driving force to push the hydrogen ions across a membrane where ma mechanical restriction leads to the build-up of pressure. The electricity used can be renewably generated. \n\nThe Mexican partners will take the lead to design, build and test protype ECHCs, incorporating advanced, low cost catalysts to be developed by the UK partners. By working in this way, the Mexican partners will develop technology that can be commercially exploited from Mexico for use in-country and overseas via exports, establishing new businesses in Mexico and contributing to improvements in air quality by reduced vehicle emissions. PV3 Technologies as a developer of the advanced catalyst in the UK will discuss licencing options such that the Mexican partners can develop new commercial opportunities in catalyst manufacturing, further strengthening the economic case of this project.","isTelecoms":1}
{"text":"Title: DIRECT - DIRect EnCapsulation Technology Abstract: The DIRECT project aims to bring together CPIs Atomic Layer Deposition (ALD) capabilities and Eight19's Organic Photovoltaic (OPV) platform to deliver an integrated process for barrier protection of OPV devices. The project is a 12 month feasibility study to establish the ground rules for roll to roll ALD barriers for solution processed OPV materials and resultant encapsulated photovoltaic modules. The project will initially be focussed on small area devices for testing ALD deposition on OPV materials, with a scale-up effort towards the end of the project. Test devices will be evaluated by for instance damp-heat testing to establish whether the ALD barrier has formed correctly. In addition a small wireless demonstrator will be produced to highlight the potential benefits of the technology pairing.","isTelecoms":1}
{"text":"Title: Structure and robustness of multi-agent systems operating in open world environments Abstract: Aim\nTo develop design approaches and functionality which configure the structural elements of distributed, autonomous, multi-agent systems to increase their robustness to environmental and agent variability. \n\nHigh level description\nThis project considers robustness of complex systems with autonmy operating in the real world. Example systems could be autonomous transport networks, computer data centres or the Internet of Things. It aims to contribute to a design methodoly for such systems which minimises unwanted emergent behaviours. \n\nThe intended approach is to apply multi-agent modelling and analysis to complex systems, with a particular emphasis on systems which include autonomous and intelligent functionality. The latter creates the potential to extend the intended approach to include learning techniques such as artifical evolution. Activity is intended to be split between two bodies of work. The first is investigating the effect of homogenous vs heterogenious system elements on the emergence of unwanted behaviour. The second body of work focuses on the design of a compensating function. \n\nTo investigate the effect of heterogenious system elements, a series of complex system scenarios, linked to real world problems and existing literature, will be designed and simulated. These scenarios will be designed to encourage emergent behaviour. For example, sheep herding in which a shepherd, team of dogs and flock of sheep interact during a herding trial, or a sorting exercise in which teams of robots undertake roles, receive instructions and share information through a heirachy.\n\nResearch Questions\nIn the context of this project, a structural element is the building block of a multi-agent system. For example, communications, the role of an agent or the norms which govern the interaction between agents. These structual elements can be either the same for all agents (homogeneous) or vary between agents (heterogenious). This project hyptothosises that there are combinations of these elements which achieve the same goal but are less susceptable to unwanted system behaviour occuring from real world conditions. It asks the questions:\n What is the link between the stuctual elements, heterogeniality and the robustness to environmental and agent variability?\n How can these structual elements be chosen such that the MAS is robust to a wide range of variability?\n How can behaviour at the agent level be modified such that the structual elements are reconfigured during run time to maintain positive, system level, functionality? \n\nObjectives \n1. Specify the interactions between agents in a multi-agent system using a bounded interface approach to infer where structural elements have the potential to influence unwanted behaviour. \n2. Quantify the capability of multi-agent structures (for example, roles, hierarchies or norms) to reduce system level disruption caused by variability. This will be investigated using computer based multi-agent simulations.\n3. Create dynamic, intelligent, behaviour at the agent level which reconfigures the system structure in response to negative emergent behaviour at the system level.\n\nMotivation\nEngineered autonomous multi-agent systems are becoming increasingly complex and relied upon for essential functionality. For example transport\/social\/financial networks and human-robot teams operating in warehouses or exploring unknown environments. Often in these multi-agent examples, the system evolves over time with inputs by multiple designers and engineers. There is not a single design authority and the operating conditions are not completely known at the design stage.\n\nExisting work often focuses on the correct function of a single agent. There is a lack of work which considers the problem of ensuring the system as a whole works as intended. In particular, the effect of variability and how the structal elements can be designed to cope with unknown conditions.","isTelecoms":1}
{"text":"Title: Green Bioactives: commercial acceleration of a sustainable production platform for bioactive ingredients utilising cultured plant cells Abstract: Green Bioactives, a University of Edinburgh start-up, have developed innovative strategies to produce plant-derived natural products utilising plant cell culture with full freedom to operate. These technologies can significantly improve the yields of target natural products in cultured plant cells. This technology platform can be employed to produce high quality natural product ingredients for the cosmetic, pharmaceutical, food and agricultural industries. An ICURe funding award to Green Bioactives provided invaluable market intelligence. Green Bioactives is currently engaged with leading companies to provide natural product ingredients for their respective product ranges.","isTelecoms":0}
{"text":"Title: MIREDA (Mother and Infant Research Electronic Data Analysis) Partnership Abstract: The MIREDA partnership aims to improve maternal and infant health, particularly among disadvantaged groups, by developing new resources and tools for research that uses routinely collected data. It will do so by bringing together people and datasets from existing UK research programmes that are addressing infant and maternal health.\n\nPoverty, disadvantage and associated poor health frequently start at the earliest stages of life. Poor parental health and adverse health behaviours such as drug and alcohol use affect development of the baby before and after birth, resulting in foetal growth restriction\/small-at-birth, preterm birth, or being large for gestational age. The implications of these can last a lifetime, affecting health (brain and lung development, hearing\/sight impairment), educational outcomes and subsequent life chances. This means that addressing inequalities in society starts with improving maternal and neonatal health. However, given a backdrop of rapidly-emerging and growing societal and economic challenges that include rising obesity, escalating living costs, inequality and large sections of society - including many migrants and asylum seekers - facing poverty and deprivation, it has never been more important to be able to understand how best to protect future generations from the long-term disadvantages that arise from adverse exposures before birth, including those linked to changing societal challenges. This partnership aims to facilitate such understanding, to inform evidence-based preventative interventions.\n\nMIREDA will capitalise on and add value to recent investments and developments in health-data research. Due to the expansion of big data, there are many maternal and infant datasets around the UK that could be harmonised, analysed and compared for data science in population health. But access, governance, computational capacity and the analyst skills required are all serious (but addressable) barriers. Recent years have seen rapid developments in the infrastructure and expertise needed to safely bring together diverse data for public benefit. The urgent response to the COVID-19 crisis accelerated our capabilities, and we now know it is possible to enable researchers UK-wide to access and compare datasets across the four nations.\n\nWhat the partnership will do: MIREDA will create a UK resource including harmonised maternal and infant birth-cohort health data, linked to local datasets including those in public health, neonatal health, imaging, primary care and hospitals. It will establish a multidisciplinary collaboration to provide the tools and supporting expertise for undertaking analysis in each of the cohorts without need to move the data. In addition, it will develop methods for data standardisation and common data management across datasets to ensure comparable analysis,and implement software for automating epidemiological study methods for ease of obtaining analysable datasets. It will work with others to build research capacity and networks in the field, using online and face-to-face workshops, seminars, conferences, and research development group meetings to share knowledge and skills within the UK and beyond. Finally, it will provide 'pump-priming' funding to support rising-star researchers and international collaborations in maternal and infant health, and to leverage additional funds for research to improve maternal care and infant outcomes. \n\nWhy this partnership is needed now: In the UK we have been very successful in reducing maternal and infant mortality, but this means more infants and mothers - predominantly from disadvantaged groups - living with chronic conditions. As disadvantage and deprivation become ever-more pressing societal issues, it is becoming increasingly urgent to mitigate the risks to maternal and infant health that are strongly associated with them, so as to improve life-course outcomes for successive generations and help break the cycle of poverty.","isTelecoms":1}
{"text":"Title: Energy &amp; NOx Recovery Project Abstract: To develop a product that recovers waste heat energy and reduces volatile organic compounds emissions from hydro-carbon powered boilers, coal and wood powered fireplaces and stoves.","isTelecoms":0}
{"text":"Title: MoPowered Platform - Version 2 Abstract: The MoPowered Platform Version 1.0 was launched by MoBank Limited in March 2012 and is capitalising on the rapid growth in mobile commerce (&quot;m-commerce&quot;), by providing next-generation Software-as-a-Service m-commerce payment infrastructures and services, across the full transaction cycle to merchants of any size. MoPowered is applying to the TSB for support in delivering Version 2.0 of the platform during 2013.\nMoPowered is special because it dramatically lowers the barriers to entry and costs for a merchant business that wishes to establish a mobile selling channel. MoPowered\u2019s live operations platform provides merchants with a fully hosted and managed solution on a software-as-a-service basis; and MoPowered mobile systems are fully aligned with a client\u2019s existing business systems for order management and payment.\nThere are c 100,000 online merchants in the UK of which c 75% are yet to mobilise their offering. This creates the opportunity to deliver significant growth and to demonstrate that the UK is a world leader in m-commerce. MoPowered already has a portfolio of 60 merchants ranging from enterprise retailers like Next plc and the Bestseller Fashion Group, to smaller mid-tier retailers like Proviz and Equichoice. Links to the SME solutions are:\n- http:\/\/proviz.mopowered.co.uk\/\n- http:\/\/equichoice.mopowered.co.uk\/\nMoPowered processed over 1,427,00 mobile transactions in 2012 (685,000 in 2011). The plan is to have in excess of 200 merchants on the platform by the end of 2013, with significant growth in the UK and internationally in 2014.\nThe technology has attracted channel partnerships with many of the key players in the payments and eCommerce industry which is allowing it to become increasingly attractive to slightly smaller merchants. In conjunction with their expertise in mobile technologies, this allows MoPowered to better align with the merchants, developers and payment service provider communities to be seen as the most suitable partner.\nIn 2013, MoPowered is looking to build out the capabilities of the MoPowered platform that will:\n- speed up the process for deploying m-commerce sites;\n- increase the security and speed of checkout and payments; and\n- enable MoPowered to operate across all the operating systems (i.e. iOS, Android, Windows and BlackBerry).\nMoBank Limited is a private company registered in the UK. It is backed by high-net-worths and early-stage investor groups like the Angel CoFund (a UK Government backed fund), Anthemis Investments Limited and Oxford University.","isTelecoms":1}
{"text":"Title: University of Ulster and The Odyssey Trust Company Limited Abstract: To develop and implement a Digital Integration Strategy using design thinking and agile project management methodology. To identify ways to improve customer engagement through the provision of a single view of the customer to solve company wide big data issues.","isTelecoms":1}
{"text":"Title: GplusE: Genomic selection and Environment modelling for next generation wheat breeding Abstract: Despite its importance and growing demand within the UK, and globally, the rate of increase in wheat yields on UK farms have stagnated. To meet global future demand, annual wheat yield increases must grow to at least 1.4% and increasing the rate of genetic improvement using modern approaches is one way to do this. The ability to record vast quantities of genetic and phenotypic information cheaply (e.g. genetic markers and spectral images of field trials - termed in this proposal as Genomics and Phenomics) presents a new opportunity for increasing the rate of genetic improvement.\nThe rate of genetic improvement is affected by (1) the accuracy of selection, (2) breeding cycle time, (3) selection intensity, and (4) the amount of genetic diversity to be selected upon. In the medium to long term, concerns about genetic diversity are being addressed through national and international projects to introgress traits and alleles from landraces and progenitor species. However, the major barrier to the immediate increase in the rate of genetic improvement in wheat is the length of the breeding cycle time. Even at their fastest wheat breeding programs require at least four to six seasons to complete a cycle, principally due to the time required to reduce the number of individuals for selection to a subset that can be intensively phenotyped. Genomic selection (GS) is a new breeding tool that, amongst other advantages, can dramatically reduce breeding cycle time as selection can occur without the need to record phenotypes. In wheat this means breeding cycle time could be reduced to one season, dramatically increasing the rate of genetic improvement. In the extreme, using glasshouses to complete 2 cycles of selection per year, 10 cycles could be undertaken in the 5-year time frame currently taken for a single selection cycle. \nGS uses a training population that is phenotyped and genotyped to construct a prediction equation. This equation is used to predict the breeding values of unphenotyped individuals, which, in wheat, would allow reduction of the breeding cycle to one season. GS assumes that saturating the genome of all individuals with molecular markers and estimating the effect of these markers (i.e. training the prediction equation) will allow capture of a large proportion of the genetic variation caused by the underlying quantitative trait loci. If the proportion of the captured genetic variation is large and well estimated the prediction equation will be able to make accurate predictions about breeding values. Similarly, in Phenomics the phenotype could be saturated with descriptors, which could lead to a better separation of its environmental and genetic components as well as generating more precise phenotypes.\nCreation of training populations is a required investment for GS and strategic use of resources to achieve the required size is needed to optimize the cost and benefit of GS. Use of a genotyping and imputation strategy is paramount for reducing costs. Field trials are also costly. Use of novel high-dimensional approaches for capturing extra traits and variables (Phenomics) could enhance the value of field trials generally, as well as enabling more powerful GS. \nThis proposal will use field trials and simulation to design and evaluate Genomics and Phenomics strategies for increasing rates of genetic improvement in wheat. This will include GS training population designs and low cost collection of genotype data, assessment of the properties of high-dimensional environmental descriptors and quantification of their power, assessment of the properties of trait phenotypes collected by high-dimensional data recording devices and quantification of their relationships to standard traits. Results will be generalised to other species with breeding programs similar to those of wheat as well as to other type of experiments and field trials (e.g. National List evaluations).","isTelecoms":0}
{"text":"Title: PASS - Program Analysis for Safe and Secure Software Evolution Abstract: Constant evolution is an inherent property of modern software systems. Software evolves to implement new features, adapt to new hardware and platforms, fix bugs and security vulnerabilities, or improve non-functional properties such as performance and energy consumption.\n\nWhile these changes have an overall positive impact, they are also responsible for a large number of critical bugs and security attacks. The reason is twofold: first, software changes are not vetted enough, due to the difficulty of reasoning about all possible new behaviours that they introduce. Second, even when critical errors in deployed changes are later discovered and fixed, users take a long time to update their software to the latest version, mostly because they are concerned about the potential negative impact of an update.\n\nThe PASS project aims to tackle both problems and help software evolve safely and securely. It takes a holistic approach to the challenges of safe and secure software evolution, by combining offline program analysis to verify or comprehensively test software changes, with runtime mechanisms for keeping the software updated and secure against potentially erroneous changes that make it into the deployed system.\n\nThis is an ambitious project, which requires fundamental advances at the intersection of program analysis, software engineering, and computer systems to develop practical cross-version specifications, scalable patch verification, in-production testing and analysis, and low-overhead reversible software updates.","isTelecoms":1}
{"text":"Title: Flexi-Hex Consumer Electronics Sustainable Packaging Abstract: Flexi-Hex is an innovative new sustainable packaging system for Consumer Electronics created in response to the increasing number of e-commerce direct-to-consumer sales and the demand by Consumer Electronic companies to improve their environmental credentials by going 'plastic free' in terms of packaging. Flexi-Hex is made from recycled paper and cardboard yet is surprisingly strong and durable. The unique honeycomb design gives the packaging high compression resistance and the unique cellular structure of Flexi-Hex allows flexibility to fit irregular shapes and sizes. The honeycomb geometry is unique in that it expands to create a sleeve 35 times wider than its compressed form. Flexi-hex is also lightweight and in its compressed form takes up little storage space. The system's flexibility is pragmatic for compact lightweight portability. With public awareness around single-use plastics and the devastating effect on the marine environment at an all time high, developing a sustainable plastic free packaging system for Consumer Electronics will offer a solution to reduce the considerable amount of plastic waste companies generate and so can significantly reduce their environmental footprint.\n\nFlexi-Hex has already developed a packaging solution for Bottles which is in operation today with many leading drinks suppliers and wholesalers.","isTelecoms":1}
{"text":"Title: The role of TFIIB phosphorylation in the transcriptional stress response Abstract: The genes of an organism contain the information that is necessary for life. The genes encode the products that make up the structure of cells and perform the functions for essential processes. All organisms utilise mechanisms to switch genes on and off so that the abundance of the products they encode can be regulated. The mechanisms that are deployed to regulate the turning on and off of genes are highly conserved from yeast to man, and are also similar to those see in bacteria. \n\nAll organisms need to respond to changes in their environment, i.e. stress. This requires global changes in the genes that need to be switched on so that changes in cellular structure or function can take place to deal with the new conditions. Much progress has been made in our understanding of how new genes are switched on under stress and how they help to deal with the changes. However, under stress conditions, genes that are not necessary for survival are switched off so as to conserve energy that needs to be deployed for the stress response. How the extensive silencing of these genes is achieved is not understood.\n\nWe have been studying a protein, Transcription factor IIB (TFIIB), that plays a central role in the expression of genes and is found in all organisms from yeast to man. We found that TFIIB is modified by the addition of phosphate and that this is required for the expression of most genes that are switched on under normal conditions. Intriguingly, the genes that do not require the phosphorylation of TFIIB are required for the response to stress.\n\nWhen cells are subjected to stress, the phosphate is rapidly removed from TFIIB. This leads to the temporary shut-down of non-essential genes, but allows the genes important for the stress response to be switched on. Our recent results suggest that the phosphorylation of TFIIB is an essential control point that is required for the response of an organism to stress. \n\nIn the proposed study we will;\n\n1. Determine how phosphorylation of TFIIB affects gene expression. This line of investigation will help us understand how the stress response genes are selectively switched on.\n\n2. Determine all of the genes in human cells that are switched on and off by the TFIIB phosphorylation mechanism. These results will help us to understand what makes a gene switch on or off under cell stress.\n\n3. Determine the enzymes that are responsible for adding and removing the phosphate from TFIIB. This will allow us to understand how the balance of TFIIB phosphorylation changes when cells are subjected to stress.\n\nThe completion of these studies will provide significant new insights into the gene control events that occur under stress conditions. This information will provide opportunities to potentially control an organisms response to stress, that will have important uses in agriculture and drug production in modified organisms.","isTelecoms":0}
{"text":"Title: The Implications of the protection of freedom of religion in the context of employment Abstract: The research considers how far employees should enjoy the right to freedom of religion at work. A particular focus is legalisation introduced in December 2003 prohibiting discrimination on grounds of religion. One of the aims of the research is to establish how religious discriminations interact with other equality rights such as gender and sexual orientation equality. It assesses the circumstances in which religious discrimination should be allowed, and how and clashes of rights should be resolved. In order to address these issues, the experience of other jurisdiction which has had religious discrimination protection for longer is explored.","isTelecoms":0}
{"text":"Title: Cyclic A-infinity algebras and their Koszul duals Abstract: The notion of a cyclic A-infinity algebra appears naturally in many contexts of algebra and topology, e.g. as cochain algebras of Poincare duality spaces. It is important to characterize intrinsically their Koszul duals. Such a characterization was provided in a recent work of Van den Berg but inly under rather restrictive grading assumptions that are, in particular, exclude the example mentioned above. The goal of this project is to remove these assumptions and also refine the characterization to the commutative case. A corollary would be an intrinsic characterization of homotopy Lie algebras of Poincare duality spaces.","isTelecoms":0}
{"text":"Title: Soft Power Struggles: China's State-Media in Africa Abstract: My doctorate will trace China's soft-power interactions with Africa through a study of Chinese communication via state-media organisations. Joseph Nye described soft-power, his theory concerning the use of cultural activities as a source of international power, as the 'means to success in world politics' (2005). In the Chinese context, soft-power is most actively pursued through public diplomacy: 'a country's engagement and communication with foreign publics for the sake of communicating certain narratives and images of the country' (Hartig 2016, 656). These engagements and communications takes many forms, such as state visits and the now ubiquitous Confucius Academies, but in bulk is the work of China's international state-media apparatus. China's leaders have certainly shown an enthusiasm for utilising the term ruan shili ('soft-power') in prose and rhetoric of the Communist Party of China (CPC), appearing constantly in the strategy statements of China's state-media organisations. However, the funnelling of soft-power strategies through these organisations opens them up the interpretations of very divergent structures and agents, who use these interpretations of their roles as soft-power resources to create China's African news texts. Utilising a 'bottom-up' method, my study will investigate how diversity within China's African newsrooms creates diverse content, and will seek to question how coherent China's soft-power strategy in Africa actually is in light of this divergences. To investigate this, I will examine the strategies, structures, and production of four Chinese state-media outlets in Africa. This study aims to have far-reaching implications to the study of soft-power, particularly in terms of its interface with state-owned media and the potential of non-liberal nations to exert soft-power through public diplomacy, and also to the understanding of China's international relations in terms of its increasingly contested global roles.","isTelecoms":1}
{"text":"Title: Quantum computing micro chips for high fidelity electronic quantum gate implementation Abstract: Currently developing an alternative approach for quantum information processing with trapped ions where quantum gates are executed by the application of voltages on an ion trap quantum computing microchip replacing laser beams required for quantum gate implementation.","isTelecoms":1}
{"text":"Title: Parallel Computation in Game AI Abstract: The goal of this project is to develop parallelised versions of AI techniques and to explore the potential of these techniques within interactive games in particular in the existing Jomini Engine, a historical Massively Multiplayer Online Role Playing Games (MMORPG's). We will implement parallel versions of AI search algorithms, initially based on established sequential algorithms and later exploring novel parallel algorithms particularly suited for this application domain. We will analyse and identify performance differences between each version and reasons for the variation in performance. The main metric of success will be the (absolute) speedup achieved on large-scale parallel machines, such as clusters or GPUs, and the suitability of the results in the context of a concrete game engine, such as guaranteed response time from an AI-controlled agent. In the next phase of the project we will explore different parallel programming technologies, as MPI, OpenMP and OpenCL, and different sequential host languages, such as C\/C++ &amp; C#;, to finalise the infrastructure for the main part of this research in the area of parallel programming for (interactive) games.","isTelecoms":1}
{"text":"Title: Real-time monitoring and predictive modelling of the impact of human behaviour and vaccine characteristics on COVID-19 vaccination in Scotland Abstract: While COVID-19 vaccination will likely be transformative, many uncertainties may influence how quickly and comprehensively vaccination will have an impact. Current evidence suggests high levels of protection from the available vaccines, with some evidence that it also reduces transmission. However the evaluation of the evidence is ongoing, with the potential for new variants of concern to change the overall picture. To evaluate this in real time, we shall address here two interlinked factors: the potential for vaccinated individuals to shed and transmit virus without displaying clinical symptoms, and the rate of vaccination uptake and how it may cluster in communities. We shall work with Public Health Scotland, to exploit real-time monitoring of vaccine uptake, COVID-19 testing and cases, to identify geographical localised impacts on infection rates. Wastewater surveillance data will help to identify possible shedding of vaccinated individuals by comparing detection rates before and after vaccination, with a signal either indicating potential for transmission or a signal that must be accounted for to reduce the likelihood of false alarms in future situations where wastewater surveillance is being utilised. \n\nUsing an established agent-based model fitted to cases across Scotland, we shall use these data to make short term forecasts for COVID-19 case numbers to support PHS planning. Long-term projections will consider vaccine-induced and natural immunity, clustering of low vaccine uptake, logistics, and possible loss of immunity. An online survey will build on the ongoing OPTIMUM study by correlating vaccination attitudes and ease of access to Scottish demography, mapping these geographically via the Scottish index of multiple deprivation (SIMD). We shall use models of 'vaccination games' to consider possible future scenarios where combinations of hesitancy, refusal and difficulties of access could result in lower uptake rates in some communities and therefore continued higher levels of infection or risk of outbreaks. We shall embed these scenarios into our simulation models. From this project, we shall have a more refined understanding of COVID-19 epidemiology in Scotland under vaccination, and better predictions of epidemic trajectories to aid in planning, to inform possible stresses on hospitals and ICU, and to target vaccine deployment and information strategies. Our results will more generally inform relationships amongst vaccine attitudes, accessibility, and regions of low vaccine uptake and refine approaches to surveillance and control.","isTelecoms":0}
{"text":"Title: A Consolidated Grant Proposal for Solar and Planetary Science at the University of Leicester, 2019 - 2022 Abstract: We propose a world-class programme of research that focuses on two main areas of study concerned with our solar system. The first involves study of the outer environments of the planets where the gas is in the plasma (ionized) state, such that it not only feels the gravitational pull of the planet, but also interacts strongly with its magnetic field. In the second area we seek to study the origin and development of solar system bodies, and the impact on the evolution of life, through detailed examination of the composition of samples from Mars, which will provide information on the way in which the surface of the planet has evolved, interactions with water, and interactions between surface and the atmosphere.\nPrevious work in the first area shows that the outer environments of the planets vary widely, determined by the interaction with the plasma wind that blows continuously from the Sun on the outside, and the interaction with the planet and its moons on the inside. The solar wind is prone to outbursts that can lead to magnetic storms and bright auroras at Earth, as well as varying strongly over the 11-year solar cycle, and with distance from the Sun. Its interaction with the planets then depends on whether the planet is magnetised, has an atmosphere, and has active moons orbiting close in. We will use spacecraft data to study Mercury close to the Sun that has a magnetic field but almost no atmosphere (MESSENGER mission), Mars further away that has an atmosphere but no strong magnetic field to prevent its erosion by the solar wind (Mars Express and MAVEN), and Earth at intermediate distances having both an atmosphere and a magnetic field (using data from a number of missions (Iridium satellite constellation, van Allen probes, Arase) and ground based facilities (SuperDARN and SuperMAG). We will also study the strongly magnetized giant planets Jupiter and Saturn using data from the new Juno mission at Jupiter and Cassini at Saturn, combined with observations of the auroras at ultraviolet wavelengths using the Hubble Space Telescope and at infrared wavelengths using large ground-based telescopes. Auroras are caused by large-scale electric currents flowing between the outer environments and the upper ionized atmospheres, which communicate force between these regions. Overall emphasis will be on the complex physical processes that couple the solar wind on the outside, the magnetic field surrounding the planet (if any), and the planetary atmosphere or surface on the inside. Finally, using a combination of electron microscopy and synchrotron-based X-ray spectroscopy of meteorites and experiments on analogue-fluid reactions, we will provide the most detailed mineralogical analyses and formation models of martian meteorite carbonates and co-existing clays. From this, we will address the nature of martian hydrothermal crustal fluids, and test associated current models for the ancient atmosphere. Thirdly, key processes in the formation of the martian igneous crust, in particular the formation of the main melt types, will be constrained by modelling meteorite and lander data, enabling comparisons to differentiation on other planets.","isTelecoms":0}
{"text":"Title: Aberystwyth University and TTS Pharma Limited Abstract: To develop new naturally derived treatment for inflammation of the uterus in cows, horses, camels and pigs.","isTelecoms":0}
{"text":"Title: The Synthetic Biological Engineering of Self-Assembling Micro-Hearts for Cardiac Drug Testing Abstract: Pharmaceutical drug development is increasingly more expensive and time consuming due to the lack of effective laboratory tissue\/disease models that accurately predict drug efficacy and safety. In this fellowship I will address this challenge by combining synthetic biology with tissue engineering. Focusing on cardiac drug testing, I will reprogram stem cells through synthetic biology to automatically self-assemble into small, 0.5-1 mm diameter spherical heart tissue constructs (i.e. micro-hearts). Synthetic biologically engineered micro-hearts satisfy all requirements of an effective cardiac drug testing tool, and are cheaper than currently used methodologies. As an effective and inexpensive drug testing tool it will help reduce the cost of drug development, helping the pharmaceutical industry, an &pound;8.8 billion UK sector, survive and thrive. Cheaper and more effective cardiac drugs will lessen the &pound;11 billion burden of cardiovascular diseases on the NHS, and improve the quality of life of the 7 million people living with these diseases today in the UK.","isTelecoms":0}
{"text":"Title: RaDiCal: Rapid diagnosis of Calf Pneumonia Abstract: We shall develop a rapid, sensitive, cost-effective on-farm diagnostic test capable of detecting the organisms responsible for calf pneumonia to inform herd management and reduce the unnecessary use of antibiotics. Early diagnosis of pneumonia will allow the farmer to administer treatment in a proportionate and timely way. \n\nCalf pneumonia is a complex disease caused by a variety of infectious agents. Typically, the clinical disease is caused by certain species of bacteria that may normally cause no adverse effects to the lungs but do so when the animal is compromised in some way, such as a specific viral infection in combination with other stress factors, such as weaning, changes of feed, variation in ambient temperature and humidity. The estimated lifetime economic cost of a case of pneumonia in a dairy heifer is &pound;772, highlighting the potential returns from investing in reducing the impact of this disease. Despite the substantial cost that calf pneumonia causes the UK cattle industry, most farmers prefer to reduce the likelihood of the disease occurring or rely on detecting pneumonia through non-specific means. That is not to say that diagnostic tests are not available, but the high cost of tests and the fact that the results are delayed and therefore cannot inform treatment decisions are likely reasons why these are not used routinely. We intend to understand the impediments to livestock diagnostic test use in more detail in this project through engagement with farmers, vets, and calf rearers.\n\nRecent developments in rapid molecular diagnostics (many by the project team) offer the possibility of delivering a test that is considerably cheaper, quicker and more sensitive than existing commercial tests, opening up the opportunity to use such a test for routine surveillance on-farm. This would enable early intervention and the development of specific treatment protocols, thus reducing antimicrobial resistance and improving calf welfare. Our project sits at the intersections between policy change, economic opportunity, changing practice, public perception of the industry, and even antibiotic stewardship.\n\nWe are a new and focused partnership that combines working knowledge of dairy farming, expertise in veterinary infectious disease, diagnostic test development and stakeholder engagement methods. The test will be based on simultaneous detection of any of the six most common infections associated with calf pneumonia using a simple swab of the nasal passages, not unlike the current lateral flow tests for COVID-19. The swab will be placed in a novel device developed by the project partners that gives a simple final readout of the test result using a lateral flow device. Proof of principle has been demonstrated for the technology we intend to adopt for the detection of at least some of the pathogens associated with calf pneumonia, and three of the partners have experience of the development of rapid tests using this technology for pathogens of veterinary importance, and respiratory infectious disease testing in humans (incl. COVID-19). \n\nHowever, developing a test is only half the story, and we must ensure the test is co-developed with those who will ultimately use it. One of the partners is a dairy farmer, another a livestock veterinarian, and two others have worked with calf rearers for the last five years on pneumonia management and antibiotic resistance. Using methods, such as interviews\/workshops with calf rearers and vets, we shall ask questions such as, how do you currently control pneumonia, how quick does the test need to be from start to result, how much should it cost, which sales channel is most attractive, and what will you do differently in response to the test result? This will be vital information to ensure the test we develop has the best chance of being used on farm to the benefit of animal health and welfare, the GB cattle industry, and beyond.","isTelecoms":0}
{"text":"Title: Vauxhall Pleasure [2]: Interrogating the Sonic Archaeology of Vauxhall Cross Gyratory, London - former site of the Vauxhall Pleasure Gardens. Abstract: Summary:\\n\\nVP[2] will examine the Sonic Archaeology of Vauxhall Cross. This central London gyratory is the former site of the Vauxhall Pleasure Gardens. VP[2] will investigate the ephemeral and oneiric qualities of live performance and interrogate the relationship between political protest and entertainment, traffic and pedestrians, pollution, breathing and song via two practice based outputs: a composition and a film; and a refereed journal article. VP[2] will extend the scope of the proto-discipline of Sonic Archaeology examining and testing new methodologies with a view to enabling new modes of investigation in the development of site-specific art practice. \\n\\nThe research builds on the innovative interaction of Sonic Archaeology, Live Art and Socially Engaged Practice evident in VP[1]. This pilot project featured the return of the sung voice to Vauxhall Cross on 6th August 2004. Transformations of Arcadian Songs by Thomas Arne (1710-1787) - originally written for performance at the Pleasure Gardens - met with the thunderous roar of the traffic and the systematic controls of the traffic light system. \\n\\nSonic Archaeology is the study of the former sonic profile of a specific site - the pursuit of past soundscapes. VP[2] will counterpoint this past sonic profile - the distinctive sound of mid Eighteenth Century song - with the present sonic profile of the site - the thunderous weaving counterpoint of hundreds of Internal Combustion Engines on their faltering passage through the site governed by the traffic light system. The harpsichord continuo will co-exist with the articulated truck. Alongside what could be termed the proto-discipline of Sonic Archaeology; Live Art and Socially Engaged Practice provide more familiar contexts for the research. The live performance of 6th August 2004 plotted a series of connections between the language of protest and the language of site performance - a performative Sonic Archaeology. \\n\\nThe aims and objectives of VP[2] are:\\n\\n1. To energise debate regarding the research territory and status of Sonic Archaeology - to examine the past, present and future soundscapes of urban sites. \\n\\n2. To establish a series of methodologies to expand the practice of Sonic Archaeology. \\n\\n3. To interrogate the past and present soundscapes of Vauxhall Cross, London - former site of the Vauxhall Pleasure Gardens. \\n\\n4. To scrutinise the actions of the singers who performed at Vauxhall Cross during VP[1] and so expose the relationship between the languages and behaviours of political and civil protest; and cross-disciplinary arts practice. \\n\\nThese objectives will be pursued, interrogated and fulfilled via the creation of three outputs: \\n\\na. A thirty-seven minute musical Composition for seven live instrumentalists and thirty-one loudspeakers exploring the simultaneous presentation of the sonic past and the sonic present. The work will counterpoint sonic materials of the past - The Arcadian songs of Thomas Arne - and the present - internal combustion engine; alongside the sonic control mechanisms of the past - tonality and form - and the present - a traffic-light system able to release or restrain the sonic power of the vehicles that thunder through the site. \\n\\nb. A thirty-minute broadcast quality Film that will seek to examine the impact on Vauxhall Cross of the performative mode of Sonic Archaeology - privileging and amplifying the ephemeral and oneiric qualities of the return of the sung voice to Vauxhall Cross.\\n\\nc. A refereed journal article examining the extension of existing knowledge and practices in Sonic Archaeology with reference to the interrogation of site instigated by VP[1] and the methodologies employed in the creation of outputs a. and b. \\n\\n\\n","isTelecoms":0}
{"text":"Title: MICA: Partnership for Improvement and Innovation in Dietary Assessment Technology (PIIDAT) Abstract: Studies of diet and disease relationships are difficult to carry out and often generate conflicting results. Problems occur because measuring diet in large populations is challenging. Measurement error happens in dietary studies for lots of reasons including lack of expertise, limited food choices on assessment tools, inaccurate portion sizes, incomplete food databases and cost. Health practitioners also need suitable tools for assessment of diet in patients for diagnostic purposes and monitoring treatments.\n\nThe main aim of this proposal is to improve the design, conduct, analysis and interpretation of diet studies reporting food &amp; nutrient intakes to reduce measurement error and bias. In addition, the partnership will empower researchers and clinicians through provision of valid tools to measure food and nutrient intakes. This will be of value for a range of stakeholder groups, with the potential to make important public health impacts.\n\nCurrently, unless researchers or practitioners are experts in the area of nutrition it is extremely difficult for them to include measurement of dietary behaviour in their studies. We aim to provide a resource to meet the challenges of measuring diet accurately and efficiently that incorporates new developments in technology. This will be achieved by creating a unique website containing valid, evidence based dietary assessment tools along with guidance on use linked to an analysis system generating results of foods and nutrients consumed. This resource will provide access to the best assessment tools for use in a standardised way; increasing the quality of research which is undertaken in this area.\n\nTools for inclusion on the website will be chosen by a group of experts to provide trustworthy selection of the best dietary assessment tools. These could be questionnaires; use an interview format; or on-line completion. We expect initially 10-20 tools to be included on the website. Existing paper based questionnaires included will be converted to an on-line format with downloadable pdfs. We will establish new standards for collecting, analysing and reporting studies of diet and health. The web-site hosting the validated dietary assessment tools (DAT-eLibrary) will be interactive and provide guidance for choice of the most appropriate tool for use; printable questionnaires and forms; on-line data entry and analysis functions. \n\nAt the same time, we will expand and improve existing food composition tables for the UK. The growing diversity of the UK diet with around 70,000 food items in stores has not been matched by an expansion of the standard food composition tables, with only ~7,000 items. We plan to link existing national public &amp; food industry branded food tables to expand the choice of foods available. We will use back of pack nutrient information from food producers, fast food retailers &amp; supermarkets to expand the food tables. National public and food industry branded food tables will be linked to support analysis of tools in the DAT-eLibrary. International food tables can also be incorporated.\n\nThe final element of the project will be to create an on-line interface between the dietary assessment tools and the food composition tables. The food tables will be linked to the tools in the DAT-eLibrary. The interface will allow users to access the tools and undertake analysis. Access will either be free or minimal cost to support sustainability of the resource keeping the database up-to-date.\n\nThis partnership will be a unique resource for nutrition researchers, scientists and health practitioners of value to both experts and non-experts. No other website combines in one place the resources proposed here, making this proposal the most comprehensive place to find support for research in nutrition &amp; dietary assessment. Having a central on-line resource will be a cost effective approach to improving the quality of research in the diet and health area.","isTelecoms":0}
{"text":"Title: VIPER2 - Vehicle Integrated Powertrain Energy Recovery Abstract: Jaguar Land Rover, in partnership with Ford Motor Company Ltd, European Thermodynamics Ltd and Nottingham University, will launch a 3-year program of research in which conventional concepts of engine management of thermal energy will be re-examined using state-of-the-art simulation tools and a novel test engine which will allow the heat available to be directed to the most import components such as the cylinder liner walls. Some of the heat that will inevitably escape down the exhaust will be converted into electricity using a Thermo Electric Generator.\nIn the longer term, if all the project targets are met, it is believed that a 5% improvement in fuel economy is possible through the conversion and management of heat energy. This research programme, scheduled to start in early 2014, is enabled by a &pound;2 million grant from the UK government\u2019s Technology Strategy Board (TSB), and builds on an earlier programme which was also co-funded by the TSB.","isTelecoms":1}
{"text":"Title: The Places that Speak to Us and the Publics We Talk With: Shaping Environmental Histories Abstract: Context\n\u2018The Places that Speak to Us and the Publics We Talk With\u2019 develops the work of two Networks funded under the Researching Environmental Change Network call: \u2018Local Places, Global Processes: Histories of Environmental Change\u2019 and \u2018Cultural Spaces of Climate\u2019. \u2018Local Places\u2019 revolved around three site-specific workshops on location at Wicken Fen (Cambridgeshire), Quantock Hills (Somerset), and Kielder Water and Forest Park (Northumberland). At each venue, we worked with a formal project partner - the National Trust, the AONB service and Northumbrian Water, respectively - and forged relationships with other environment management organizations, including the Forestry Commission and the Wildlife Trusts. We combined indoor pursuits such as academic papers, presentations by project partners and round table discussions involving partner representatives, with direct engagement with the locales themselves. The Cultural Spaces of Climate\u2019 Network was more orientated towards traditional academic discourse in the seminar room, and entailed innovative engagement with arts and humanities representatives, the broader research community, learned and professional societies and the public sector, to identify ways to redress the global and scientific bias in climate discourse, to explore the meaning of climate for different groups in different spatial and temporal contexts and to interrogate climate\u2019s ontological status. This joint proposal from the \u2018Local Places\u2019 Investigators and the Principal Investigator for \u2018Cultural Spaces of Climate\u2019 combines their experience and expertise in pursuit of a new round of activities that develops the original research agendas but uses them in combination to shed light on how processes of communication and the transformation of meaning in different contexts shape understanding of the environment, through the structured interaction of different research strands engaging with a variety of publics. \n\nAims and Objectives\nThe principal aims are:\n\n1. To generate innovative and productive knowledge exchanges between academics studying past environmental change from arts and humanities perspectives and professionals \u2013 our project partners \u2013 who manage environments and address environmental change. \n2. To endeavour to contribute to management decisions by applying perspectives that take account of human perceptions, community involvement and other cultural considerations. Our longer term aim is to help inform public policy.\n3. To examine, through the inter-relations of our different sub-projects embracing the broad category \u2018the environment\u2019, how different methods, contexts and publics, and processes of communication across these elements, shape environmental understanding and the translation of understanding across audiences. \n4. To pursue a range of projects, workshops and events in collaboration with partners to secure these ends. Some of these undertakings are directly related to previous workshops and Network outputs: an interview project, with professionals involved in managing the site and local community members, and a workshop to advance the book arising from \u2018Local Places\u2019. Others are spin-offs: the Quantock Orchard Project to research the role of orchards in the local landscape; Walking Militarized Landscapes to devise walks around military training estates; a public lecture series on \u2018Environmental Visions\u2019 at Wicken Fen. These projects develop existing partner relationships (National Trust, AONB service and Northumbrian Water) and formalize links with the Forestry Commission and the Royal Geographical Society (With Institute of British Geographers). We bring the two Networks\u2019 research directly together by investigating local co-production and reception of climate change adaptation strategies adopted by environmental managers. \nPotential applications and benefits\nThe potential research applications include informing decisions by professionals who manage sites and address environmental change; heightening public awareness of such issues; providing insight on practices of communication and the emergence of meaning for academic and non-academic partners; and contributing to public policy decisions. With these in mind, we also plan a Journalism Workshop convened by Erin Gill, an environmental journalist, to explore how to extract newsworthy stories from our research, convey them in appropriate language and place them to maximize the public as well as scholarly value and impact.\nWe will also hold a follow-up Forests and Woodlands Workshop with Forestry Commission and National Trust support, to bring historical, cultural and social perspectives to key concepts, such as ownership and management, community, access, and value, highlighted at our previous DEFRA meeting (September 2011).","isTelecoms":0}
{"text":"Title: Ultra-high throughput evolution of designer enzymes with extended amino acid alphabets Abstract: With increasing societal and political acknowledgment of environment and climate issues, various industrial sectors are shifting their focus towards carbon neutral and environmentally benign technologies. As thus, biocatalysis is a rapidly expanding technology in chemical industry for the production of commodity chemicals and pharmaceuticals. In biocatalysis, enzymes, which are nature's catalysts, are repurposed for synthesizing chemicals in human devised processes. Enzymes can accelerate highly complex chemical reactions with speeds and specificities that are unrivalled by conventional chemical methods. In addition, reactions can be performed at low temperatures in aqueous solutions, unlike chemical processes that typically require high temperatures, toxic chemicals and large amounts of organic solvents. However, a major limitation for broad industrial exploitation of enzymes is that not for any desired reaction a suitable enzyme is available in nature's repertoire. As thus, enzymes that meet the specifications of organic chemists are urgently required. Rather than reengineering existing natural enzymes, bottom-up design of new enzymes is now becoming a feasible alternative. In fact, highly efficient artificial enzymes for simplistic reactions were successfully created through computation and experimental optimisation. The number of chemical mechanisms that can be designed is however inherently limited to natures repertoire of functional groups and amino acids. Through genetic code expansion, it is now possible to augment nature's amino acid alphabet with additional functionalities. In particular, through integration of amino acids that are fused to small molecule catalysts, which have been extensively explored by organic chemists, it is now possible to create enzymes with a whole new reaction scope that is unprecedented in nature. In order to design better enzymes with non-natural functionalities from scratch, it is essential to gain fundamental understanding of how artificial amino acids must be placed and further complemented within enzyme active sites. This project aims to address this by experimentally improving designer enzymes with non-natural amino acids, leading to a fundamental understanding of the true potential of augmenting nature with additional building blocks. This will be achieved through directed evolution, which is a mimic of Darwinian evolution on a laboratory time scale. Directed evolution allows for the discovery of mutations that improve enzyme activity but are rationally not predictable. Through iterative rounds of mutagenesis and selection, the activity levels of enzymes can be significantly improved. This is a laborious process as many enzyme variants have to be individually analysed, to identify rare mutations with beneficial effects. To accelerate this process, an ultra-high throughput assay will be implemented that utilises picolitre-sized droplets as reaction vessels that contain the enzyme variant and its coding gene. Droplets can be manipulated at high speeds of several thousand droplets per second and most importantly they can be sorted according to enzyme activity. With this technology at hand, it is now possible for the first time to explore the evolutionary limits of these designer enzymes for different unrelated reactions, including ester hydrolysis and an unnatural carbon-carbon bond forming reaction. In depth characterisation of the best performing enzymes will highlight functional and structural features that are essential for supporting catalysis by nonnatural amino acids. Recapitulating these findings by computational enzyme design will challenge our gained molecular understanding and give rise to new generations of improved designer enzymes. Overall, this research project will open up new avenues in development of highly active enzymes for abiological reactions with implications in biotechnology, biocatalysis and synthetic biology.","isTelecoms":0}
{"text":"Title: Genetic and environmental determinants of age-acquired skewed X-inactivation and escape from X-inactivation Abstract: In humans, females carry two copies of the X chromosome and males one X and one Y chromosome. To maintain a consistent level of gene expression between the sexes, in every cell females silence or 'inactivate' one of their two X chromosomes. Most females randomly silence one X in each cell so that at a tissue level each X is silenced 50% of the time. Functionally, this means that cells in the same body are utilizing different DNA depending on which chromosome X is silenced in a given cell. \n\nHowever, as women age, one of the two X's starts to predominate; 35% of women over 60 have the same X chromosome silenced in &gt;90% of their cells (termed 'skewed X-inactivation'), and the proportion of women with preferential silencing of the same chromosome X increases with age. It is not known why this age-associated preferential silencing happens, however it is associated with biomarkers of cancer and is seen in individuals with autoimmune diseases such as systemic lupus and thyroid disease. Intriguingly, twin-studies have shown that age-associated preferential silencing is heritable, suggesting an individual's genetics interact with the ageing process to promote cells silencing one X or the other. In this study we will investigate the genetic basis of age-associated chromosome X preferential silencing in order to determine what genetic factors drive this process and whether the same genetic factors are implicated in risk of cancer and autoimmune disease. As the UK population ages, it is a public health priority to identify factors that contribute to healthy ageing and develop biomarkers that monitor healthy ageing and predict future disease. We will explore the relationship between preferential silencing and ageing phenotypes such as frailty and disease incidence to determine if preferential silencing can act as a biomarker of healthy ageing in women. \n\nSome genes on the silenced (or 'inactive') X chromosome are still turned on - they escape inactivation. Genes on the silenced X have a critical role in female biology; women with only one X chromosome (and therefore absolutely no expression of genes from a second chromosome) have Turners syndrome, which includes dysfunction of various organ systems. Genes expressed from the silenced X have a higher dosage in females than males which is thought to underlie differences in disease prevalence between men and women. For example, several of the genes known to escape X-inactivation are tumor-suppressor genes and the extra dosage from the silenced X chromosome has a protective effect - overall women develop less cancer than men. Conversely, several genes implicated in the female-biased auto-immune diseases Systemic Lupus Erythematosus and Rheumatoid Arthritis are expressed from the silenced X chromosome. In this case, it is thought that women may produce too much of these genes which pre-disposes them to developing disease. \n\nUnderstanding how genes on the silenced X are controlled, and how this varies in different contexts, is critical to understanding how these genes contribute to disease. For example, tissue-limited escape would indicate which tissue is important for mediating a gene's effect on disease. It is currently estimated that 12-20% of genes on the silenced X can be turned on and that their strength of escape varies across individuals. In this study we will perform deep sequencing of the genes on chromosome X to determine which genes escape, how the strength of escape varies across unrelated individuals, between identical twins (thereby removing variability due to genetics), and across tissues. We will focus on autoimmune disease relevant tissues as these have been linked to escape, as well as looking in existing multi-tissue datasets of blood, fat and skin. Finally, we will investigate how escape varies with age both cross-sectionally in the autoimmune tissues and longitudinally over 10 years in a whole blood dataset.","isTelecoms":0}
{"text":"Title: Experimental Equipment Call - University of Leeds Abstract: The objective of this proposal is to refresh and update key items of experimental equipment in activities aligned to proven strengths and critical mass in Medical Engineering and Advanced Materials at the University of Leeds.\nThe Institute of Medical and Biological Engineering hosts the largest and most advanced musculoskeletal simulation facility in the world. The new simulators will support three of our strategic research challenges: longer lasting joint replacements; regenerative devices and biological scaffolds for tissue repair; and, advanced simulation systems for virtual analysis and design and preclinical testing. They will deliver enhanced functionality, allowing the development and introduction of SAFER (Stratified Approaches For Enhanced Reliability) simulation methods to address the requirements of stratified and personalized medical devices, biomaterials and scaffolds. The simulators will be used for research into the tribology and wear of artificial joints, validation of novel computational methods for prediction of function, studies of wear debris and supporting biocompatibility research and studies of the tribology of biological scaffolds in natural joints, using recently developed methods.\nOur research in terahertz (THz) frequency electronics and photonics is internationally leading by any criterion. Much of this activity requires a state-of-the-art and dedicated MBE semiconductor growth system. The new MBE system will allow us to protect the UK's international reputation in this field and, in particular, in the growth and exploitation of THz frequency quantum cascade lasers (QCLs). Over the next five years we will: develop state-of-the-art THz QCLs across the 1-5 THz range, maximizing operating temperature, continuous-wave performance, output power, and gain bandwidth; develop THz QCLs engineered into robust device architectures for use as, for example, local oscillators in earth-observation and planetary science missions; develop compact bench-top QCL-based technologies producing intense, narrowband and precisely controllable pulses for non-linear THz science; and, develop self-organised quantum rod structures for cavity-QED experiments, and new optically-pumped, vertical-cavity surface-emitting room temperature THz lasers.\nThe Leeds Electron Microscopy and Spectroscopy (LEMAS) Centre is a highly successful shared electron microscopy facility. It has high visibility nationally (providing an EPSRC open access scheme for external users since 2008) and internationally (leading the consortium that formed the UK facility at SuperSTEM Daresbury). One of the next great challenges is apply high-resolution imaging and microanalytical techniques to beam sensitive materials, including advanced hybrid materials comprising organic and inorganic components. These are increasingly employed to develop new device and product functionalities. The specification of the new microscope is unique and designed to enable fast mapping of frozen specimens at high accelerating voltage to preserve their chemistry and structure whilst extracting nanostructural information.\nWe are internationally recognised in spintronics and magnetic materials, with recent appointments extending our materials expertise to include organic molecules, piezoelectrics, topological insulators and superconductors. The new deposition tool will ensure we can continue to supply top quality thin film materials to the UK and internationally, as well as underpinning a general theme of spintronic meta-materials. The functional properties of meta-materials emerge through the design and engineering of the constituent material combinations. With our broad background that includes the ability to structure materials at the nanoscale so that cooperative behaviour arises, we will apply this capability to questions in strategic areas such as quantum effects for new technology, beyond CMOS electronics, energy efficient electronics, and new tools for healthcare.","isTelecoms":0}
{"text":"Title: Determining the feasibility of provision of frequency support from wind turbines Abstract: Offshore wind will be pivotal in helping the UK meet its net-zero 2050 target but successfully increasing the proportion of offshore wind in the energy mix will require the industry to aggressively pursue measures to facilitate the smooth integration of energy generated into the grid. There are a range of technical challenges that must be overcome to achieve this, one of which is the ability of offshore wind farms to actively and competitively provide frequency and inertial support services. This presents an opportunity that Upside Energy Limited plan to take advantage of using our existing cloud based platform, the Upside Platform, that provides services to forecast, monitor, optimise, trade and analyse distributed energy resources, on a software-as-a-service basis. This project will investigate and demonstrate the feasibility of using the rotational inertia of a wind turbine in combination with the Upside Platform to allow wind farms competitive access to frequency and ancillary support markets. The feasibility will be established using the Offshore Renewable Energy Catapult's 7MW Levenmouth demonstration turbine as a reference turbine. This will involve the development of a new turbine operational mode and integration of the turbine into the Upside Platform via a data transfer interface. Phase 2 will involve a full scale demonstration of the technology using the Upside Platform and the LDT in order to demonstrate the technical merit of the solution and assess the economic and environmental benefits of deploying it.","isTelecoms":1}
{"text":"Title: Investigating the effect of lipid environment on ABC transporter structure and function Abstract: The ABC (ATP Binding Cassette) transporter superfamily is found in all organisms from bacteria to humans, and they utilise energy from ATP hydrolysis to power the transport of molecules across a membrane. The human transporters are involved in a wide range of functions including protection from toxins, metabolism, controlling drug distribution in the body, mediating inflammatory responses and transporting lipids. Several members are responsible for genetic diseases, such as cystic fibrosis and adrenoleukodystrophy, whilst others are involved in causing multi-drug resistance during cancer treatment. It is well established that the function of many membrane proteins is affected by their lipid bilayer environment. Specific lipids may interact directly with a transporter and modulate function, or simply affect the general properties (thickness, fluidity) of the bilayer. The aim of this project is to investigate this protein:lipid relationship in detail for two model ABC transporter proteins, firstly a bacterial transporter, Atm1, and secondly the human transporter MRP4\/ABCC4 (multidrug resistance protein 4). Atm1 can be easily expressed in E.coli, extracted and purified using styrene maleic acid polymer (SMA) to form SMA lipid particles (SMALPs). We have previously demonstrated Atm1 can be reconstituted from SMALPs into liposomes. In this project Atm1 will be reconstituted into liposomes of defined lipid composition\/properties and the affect on protein function monitored. This will be combined with structural studies using electron microscopy. MRP4 can be expressed in either Sf9 insect cells or Freestyle HEK mammalian cells. The effects of these different expression systems on protein yield and function will be measured, and SMA polymer will be used to extract and purify MRP4 from each expression system to enable analysis of the co-extracted lipids by mass spectrometry.","isTelecoms":0}
{"text":"Title: ELG - European Language Grid Abstract: With 24 official EU and many more additional languages, multilingualism in Europe and an inclusive Digital Single Market can only be enabled through Language Technologies (LTs). European LT business is dominated by thousands of SMEs and a few large players. Many are world-class, with technologies that outperform the global players. However, European LT business is also fragmented \u2013 by nation states, languages, verticals and sectors. Likewise, while much of European LT research is world-class, with results transferred into industry and commercial products, its full impact is held back by fragmentation. The key issue and challenge is the fragmentation of the European LT landscape. The European Language Grid (ELG) project will address this fragmentation by establishing the ELG as the primary platform for LT in Europe. The ELG will be a scalable cloud platform, providing, in an easy-to-integrate way, access to hundreds of commercial and non-commercial Language Technologies for all European languages, including running tools and services as well as data sets and resources. It will enable the commercial and non-commercial European LT community to deposit and upload their technologies and data sets into the ELG, to deploy them through the grid, and to connect with other resources. The ELG will boost the Multilingual Digital Single Market towards a thriving European LT community, creating new jobs and opportunities. Through open calls, up to 20 pilot projects will be financially supported to demonstrate the usefulness of the ELG. The proposal is rooted in the experience of a consortium with partners involved in all relevant initiatives. Based on these, 30+ national competence centres and the European LT Board will be set up for European coordination. The ELG will foster \u201clanguage technologies for Europe built in Europe\u201d, tailored to our languages and cultures and to our societal and economical demands, benefitting the European citizen, society, innovation and industry.","isTelecoms":1}
{"text":"Title: THERAPEUTIC POTENTIAL OF SPHINGOSINE KINASE BLOCKAGE IN ALLERGIC ANAPHYLAXIS Abstract: We are continuously exposed to a myriad of environmental agents some of which are harmful such as viruses, bacteria and parasites which threaten our well being and against which we must defend ourselves. This is the role of the immune system to combat ?foreign agents?. However, many other environmental agents are necessary for us, such as the food we eat, and the minerals that come in the water we drink as well as the huge number of harmless bacteria (commensals) that live normally in our intestines and help to extract nutrients from food and to generate some essential vitamins, thus, are essential for life, and other substances that are part of our surroundings but which do not cause us any harm at all. It is important that we do not attempt to make protective immune responses against these useful or innocuous agents, as this can lead to severe allergic disorders such as allergic anaphylaxis. Indeed the immune system normally becomes unresponsive (tolerant) to these agents. However, allergies are on the increase worldwide. A considerable amount is known about the cellular processes involved in allergies, for example it is now clear that a particular immunoglobulin (IgE), binds to its receptor on the cell surface of a population of leukocytes, namely the mast cells, and together binding to an allergen (the previously innocuous agent), trigger the signals that lead to the clinical symptoms of immediate allergic responses, including the some times lethal anaphylactic shock. Thus, it may possible to target some of these signals to deliberately switch off mast cell responses in allergic patients. However, progress in this area has been limited by the fact that to study these signals usually requires cells to be removed from the immune system and submitted to harsh biochemical processes. We have now developed new models that allow us to target the molecules responsible for these signals in the intact immune system with highly sensitive gene-silencing techniques. By analysing the effects of ?transient? gene-silencing in the whole immune system, we hope to precisely target molecules that might prove useful in the treatment of allergic diseases.","isTelecoms":0}
{"text":"Title: The Universe at Extreme Scales Abstract: Research in particle physics and cosmology connects the largest scales, those of the Universe as a whole, with then smallest, namely those of fundamental particles. By trying to understand how the Universe evolved after the Big Bang, we may gain insight into which particles are yet to be discovered, e.g. at the Large Hadron Collider (LHC), and vice versa.\n\nConcerning the early Universe, it is commonly understood that it underwent a period of rapid expansion, called inflation. However, many open questions remain. For instance, what is the mechanism of cosmological inflation, and, can we link\ninflation to quantum gravity, a theory that still eludes us? Interestingly, the recent observations of gravitational waves may\nprovide a guide here. Inflation predicts a gravitational-wave background with properties depending on the details of the\ninflationary model. Hence if this background is observed, it may help us to further uncover details of the inflationary epoch\nafter the Big Bang. Gravitational waves may also shed light on other puzzles, namely those related to dark energy and dark\nmatter. Again, possible alternative theories to Einstein's general theory of gravity, which are designed to solve the dark energy\/matter puzzles, may leave their imprint in gravitational waves.\n\nIn contrast to this, the LHC probes the smallest length scales, by colliding protons and nuclei at very high energies. In order to test the Standard Model (SM), our current highly successful theory of elementary particles, to the extreme, it is necessary to compute SM processes to high precision, and make predictions of physics beyond the Standard Model\n(BSM). The former can be done using advanced techniques which go beyond the usual Feynman diagrams. For the latter, one may take the viewpoint that the SM is an effective field theory (EFT), valid up to a certain energy scale only. To understand which novel BSM interactions can give rise to the SM at low energies, without conflicting with high-precision\nfrom the LHC, is an outstanding challenge. Two main classes of candidate theories are so-called near-conformal\ngauge theories and Composite Higgs models, which both give rise to electroweak symmetry breaking and a light Higgs boson. They may even provide dark matter candidates.\n\nThese theories have a commonality with the theory of quarks and gluons, Quantum Chromodynamics (QCD), namely that they are strongly interacting. This implies that they cannot be solved easily analytically, but are amenable to numerical simulations on high-performance computing facilities. The study of QCD provides a link between the physics of the early\nUniverse and elementary particles. Namely, as the Universe cooled down after the Big Bang, it underwent a series of\nphase transitions. During one of those, quarks and gluons combined into hadrons, i.e. the particles we observe today. The\nQCD phase transition is currently being explored at the LHC, by colliding heavy ions, motivating quantitative predictions on\nhow the QCD spectrum changes with temperature. In fact, even understanding the QCD spectrum in vacuum is still partly unsolved and may guide toward BSM physics.\n\nQuantum field theories (QFTs) describes physical processes across a vast range of energy scales, from fundamental interactions, as mentioned above, to low-dimensional and condensed matter systems. Many new phenomena and the detailed structure of QFTs are anticipated to lie beyond the confines of traditional perturbative methods or numerical\nsimulations. Dualities provide links between hitherto unrelated theories, making tractable questions previously considered\nto be out of reach. With new dualities being discovered, the richness of QFT is larger than naively expected. Similarly,\ndynamics out of thermal equilibrium, the process of thermalisation, or the evolution of quantum information, relevant for\nblack hole dynamics, benefits from new approaches, some of which are motivated by quantum information.","isTelecoms":0}
{"text":"Title: Mapping the Historical Growth &amp; Cultural Context of the British Fixed Line Network Abstract: Full details to be added later","isTelecoms":1}
{"text":"Title: Child Sexual Exploitation and Girls: An Interactive Training Tool for Child Protection Professionals Abstract: This project will undertake a collaborative knowledge exchange between the Centre for Child Protection (CCP) and Kent Police (KP). They will create, apply, and evaluate a pilot training tool to support police officers in applying a trauma informed approach (TIA) to work with girls who have experience of child sexual exploitation (CSE). \nTraining simulations are used to enhance the facilitation of learning and are valuable in developing practice wisdom through immersive and more readily retained 'experiences.' They allow participants a safe setting to practice complex or challenging risk-taking and decision-making experiences - such as decisions made when confronted with CSE of girls, which is a subcategory of Violence Against Women and Girls (VAWG). CSE is when a child is taken advantage of by an imbalance of power to coerce, manipulate or deceive them into sexual activity. This often involves an exchange for something the young person wants or needs or it may be for the advantage of the perpetrator. Girls who have a lived experience of CSE require a TIA from professionals. This includes an understanding of how trauma is manifested through the young person's beliefs, feelings, and behaviours - to ensure they are not retraumatised and that they feel able to engage with services to disrupt exploitation. There are indications that police are not trained in TIAs and girls who have experienced CSE may experience police as blaming and insensitive. \nThe creation of this pilot training tool will be undertaken in 3 separate work packages (WP). The first WP is being funded by the University of Kent's Impact Fund. In summary, this package will involve a literature review and professional knowledge exchange between KP and CCP. These undertakings will explore current knowledge and expertise around good practice, what works and challenges to TIA to police-support with girls who have lived experiences of CSE. \nThe second WP is the basis of this proposal to the ESRC and involves three key phases. The first phase (October 2022-January 2023) is a 'collaborative design' between CCP and KP via the facilitation of 3 workshops aimed at sharing knowledge to create a package of key developmental outputs to inform the creation of the pilot training simulation (e.g., learning outcomes, key narrative, effective interactive elements, character design &amp; sketches, a script and training strategies). The second phase (February 2023-May 2023) is the actual creation of the pilot training tool via Articulate Software as well as the creation of complementary training materials (e.g., instructions, refined learning outcomes, activities, worksheets, academic overview of essential concepts) which will continue to be developed in partnership between CCP and KP. The third phase (June 2023-September 2023) will include application of the training pilot. KP and CCP will co-facilitate 6-8 training sessions with around 10-15 KP delegates each (approximately 60-120 delegates). Evaluations following training will be collected and analysed to inform adaptations to the pilot training tool and training regime - with the aim of improving the training experience and impact of facilitating a stronger TIA by police. \nThe third WP includes dissemination of findings (e.g., journal publication, webinars, conference attendance) as well as ongoing use of the pilot training tool by KP and CCP. KP will continue to utilise the tool to train officers in TIA and CCP will integrate the tool within their multi-disciplinary postgraduate teaching programmes on 'Advanced Child Protection.' WP3 also includes visions for future funding potential to create a full-scale simulation from the pilot training tool.\nFindings will contribution to tackling VAWG by supporting police to develop a TIA to support with girls who have a lived experience of CSE. It will also contribute to developing knowledge on the facilitation of learning and application of TIA within child protection settings.","isTelecoms":0}
{"text":"Title: MISTRAL: Multi-scale Infrastructure Systems Analytics Abstract: National infrastructure provides essential services to a modern economy: energy, transport, digital communications, water supply, flood protection, and waste water \/ solid waste collection, treatment and disposal. The OECD estimates that globally US$53 trillion of infrastructure investment will be needed by 2030. The UK's National Infrastructure Plan set out over &pound;460 billion of investment in the next decade, but is not yet known what effect that investment will have on the quality and reliability of national infrastructure services, the size of the economy, the resilience of society or its impacts upon the environment. Such a gap in knowledge exists because of the sheer complexity of infrastructure networks and their interactions with people and the environment. That means that there is too much guesswork, and too many untested assumptions in the planning, appraisal and design of infrastructure, from European energy networks to local drainage systems. \n\nOur vision is for infrastructure decisions to be guided by systems analysis. When this vision is realised, decision makers will have access to, and visualisation of, information that tells them how all infrastructure systems are performing. They will have models that help to pinpoint vulnerabilities and quantify the risks of failure. They will be able to perform 'what-if' analysis of proposed investments and explore the effects of future uncertainties, such as population growth, new technologies and climate change.\n\nThe UK Infrastructure Transitions Research Consortium (ITRC) is a consortium of seven UK universities, led by the University of Oxford, which has developed unique capability in infrastructure systems analysis, modelling and decision making. Thanks to an EPSRC Programme Grant (2011-2015) the ITRC has developed and demonstrated the world's first family of national infrastructure system models (NISMOD) for analysis and long-term planning of interdependent infrastructure systems. The research is already being used by utility companies, engineering consultants, the Institution of Civil Engineers and many parts of the UK government, to analyse risks and inform billions of pounds worth of better infrastructure decisions. Infrastructure UK is now using NISMOD to analyse the National Infrastructure Plan.\n\nThe aim of MISTRAL is to develop and demonstrate a highly integrated analytics capability to inform strategic infrastructure decision making across scales, from local to global. MISTRAL will thereby radically extend infrastructure systems analysis capability:\n- Downscale: from ITRC's pioneering representation of national networks to the UK's 25.7 million households and 5.2 million businesses, representing the infrastructure services they demand and the multi-scale networks through which these services are delivered.\n- Upscale: from the national perspective to incorporate global interconnections via telecommunications, transport and energy networks.\n- Across-scale: to other national settings outside the UK, where infrastructure needs are greatest and where systems analysis represents a huge business opportunity for UK engineering firms.\nThese research challenges urgently need to be tackled because infrastructure systems are interconnected across scales and prolific technological innovation is now occurring that will exploit, or may threaten, that interconnectedness. MISTRAL will push the frontiers of system research in order to quantify these opportunities and risks, providing the evidence needed to plan, invest in and design modern, sustainable and resilient infrastructure services.\n\nFive years ago, proposing theory, methodology and network models that stretched from the household to the globe, and from the UK to different national contexts would not have been credible. Now the opportunity for multi-scale modelling is coming into sight, and ITRC, perhaps uniquely, has the capacity and ambition to take on that challenge in the MISTRAL programme.","isTelecoms":1}
{"text":"Title: Developing Artificial Intelligence Tools for the Next Generation of Medical Endoscopes Abstract: The main aim of this research is to explore Artificial Intelligence (AI) techniques to be integrated with the next generation medical endoscope. Consequently, these AI models may be extended to inform the design of the nanostructured optical fibres and aid in the decision making of clinically relevant prognostic schemes. The key objectives of the research are: 1. To develop a novel deep learning network with real-time capabilities to accelerate image reconstruction of optical fibre. The developed model must be scalable and can generalised well in different conditions e.g. temperature change, fibre deformation, etc. 2. Expand image modalities of the endoscope using deep learning techniques to implement a wide range of advanced microscopy in a cost-effective way. 3. To perform extreme data augmentation techniques or implement GAN to increase the diversity and amount of the training dataset for the project. 4. To perform real-time detection and segmentation of abnormalities in endoscopy using deep learning techniques.","isTelecoms":1}
{"text":"Title: Properties of the earliest galaxies Abstract: The gross cosmological parameters of the Universe that describe how fast it expands and how its expansion changes with time are thought to be known to a fair degree of accuracy. However, we do not have a deep understanding of the material of the Universe - the dark matter and dark energy that dominate over the ordinary ('baryonic') matter that is the familiar stuff of every-day life. We also don't understand the processes that cause this baryonic matter to form into structures such as planets, stars, galaxies, and clusters of galaxies. The purpose of the research to be funded by this grant is to gain some understanding of the largest-scale phenomena that affect the formation of structure by looking at the formation and evolution of galaxies and clusters of galaxies, and the internal substructure that they contain. Clusters of galaxies are often studied by their X-ray emission, which comes from hot gas held by the gravity field of their huge masses. At Bristol we also look at the gas in another way, by the 'shadow' that it casts against the microwave background radiation, which is a universal radiation field that was created soon after the Big Bang. Comparing the results from these ways of finding clusters tells us a lot more about the gas, and so about the mass holding the gas, than either technique alone. This trick is useful for discovering how much mass in the cluster is made up by dark matter and how much is baryonic matter, and whether these components of the mass of the cluster are distributed differently. Such a difference in distribution can occur in the cluster formation process, as it settles into a steady state, or later as the gas radiates energy away. We can also use the clusters that we find to study the expansion of the Universe itself, to find out more about the mysterious dark energy. There is a problem caused by the energy radiated by clusters - as the gas cools, it should drop inwards. But we see too little central gas - something is regulating the infall. It is thought that a major influence on the gas, and perhaps a source of all the energy needed to stop the infall, is the outflow of material from active galaxies, particularly radio galaxies, in the centres of the clusters. Active galaxies are galaxies where there seems to be a very massive black hole at their cores. These black holes themselves have the mass of a small galaxy, and are capable, somehow, of producing flows of gas at close to the speed of light away from themselves. This is a bit strange, since we normally think of black holes as being places where everything falls inwards, and the physics of how the outflows work, and how much energy they produce, is largely unknown. We need to measure that energy, and understand the physics of the process, in order to understand how black holes affect the clusters and galaxies in which they are located, and we will do much work on the radio, X-ray, infra-red properties of galaxy cores, and some theory, to try to understand what is going on. We expect to find out a lot about the black holes themselves, too. The most obvious feature of clusters of galaxies is the galaxies themselves, and we are also interested in knowing how galaxies form and change with time, why there are different types of galaxy, and how the galaxies affect the Universe as a whole. We have found that the stars in the earliest galaxies emit enough radiation to cause the entire Universe to change from being cold to being very hot, so that gas in the Universe changes from being neutral atoms to being a plasma, at a temperature like that of a star. How this happens, and what those first galaxies look like, is a focus of our research. We also want to know what happened to these early galaxies as they collided with one another, as their stars aged (and perhaps exploded), and as their central black holes kept pumping out energy, so we look also at nearby galaxies to study changes over the history of the Universe.","isTelecoms":0}
{"text":"Title: The emergence of complex structural organisation in skeletal muscle Abstract: During development, an organism goes from a single fertilised cell through to an adult with multiple organs. These organs are precisely shaped and the internal cellular structure tightly defined to ensure efficient function. For example, the lungs generate a large-scale branching network to enable rapid oxygen transport into the bloodstream. In the skeletal muscle, muscle cells form elongated, and typically multinucleated, fibres that enable the generation of significant force. How complex organ shape emerges during development has been a long standing question in biology, going back to before even D'Arcy Thompson. Yet, understanding the underlying processes has long proven challenging, partially due to the difficulty of imaging the cellular processes at appropriate spatial and temporal resolution. \n\nRecent years have seen three major advances that are helping us to tackle this challenge. First, biophysical models have proven to be very powerful in describing the structural changes in the material properties of biological materials. Developing tissues can undergo transitions, such as between fluid-like (i.e. rapid cell rearrangements) and solid-like (i.e. rigid internal structure). Second, imaging advances mean we can record with subcellular resolution the dynamics of cell morphogenesis in living embryos. Third, there have been major steps forward in our ability to segment and quantify complex biological imaging data using machine learning and more traditional approaches. Analysis of muscle fibre formation is especially challenging due to the speed with which the cell structure changes, including cell fusion. By combining these advances with the powerful genetics and optical accessibility of the zebrafish embryo, here we aim to dissect how the internal structural organisation of skeletal muscle emerges. \n\nThrough the following Aims, we explore if the developing skeletal muscle undergoes a material change in its properties and how cellular processes drive cell and tissue shaping:\n1) Provide the first dissection of the dynamics for every cell within an internal vertebrate organ as they reach their final position and morphology. \n2) Uncover the mechanisms happening within the cells that drive cell and nucleus reshaping and positioning.\n3) Use suitable mutants to perturb the cellular environment to test our models of cell and tissue shaping.\nIn Aim 1, we will develop imaging and image analysis techniques to allow us to access the cellular behaviour throughout initial skeletal muscle development. We will track the position and morphology of every cell within each selected future muscle segment as they go from round cells through to the highly elongated and tightly structured muscle. The quantitative data is a key input into our analysis of the tissue structural order, to test if there are hallmarks of transitions in the material properties.\n\nIn Aim 2, we dissect some of the subcellular mechanisms driving the changes in cell and tissue shape. We focus on microtubules due to their importance in a range of cellular processes associated with muscle formation. We will utilise lattice light-sheet microscopy - which enables very fast imaging at high spatial resolution - to record the dynamics of microtubules and their associated motor proteins during skeletal muscle formation. We will combine this with suitable drug and light-tuneable perturbations to dissect the role of microtubules in guiding muscle morphogenesis.\n\nIn Aim 3, we utilise a range of mutants to further explore the mechanisms driving tissue organisation. We focus on perturbing muscle cell fate specification and inhibiting muscle fusion. These perturbations allow us to access the role of both biochemical and biomechanical inputs in driving skeletal muscle formation.\n\nAround 40% of human body mass is skeletal muscle. Using zebrafish development. we will dissect the fundamental mechanisms ensuring this tissue is precisely structured.","isTelecoms":0}
{"text":"Title: Heat Store &amp; Processor for Emissions Reduction (HESPER) Abstract: Sunamp pioneered and patented the Heat Store and Processor (HSP) architecture which combines Phase Change Material (PCM) for thermal storage and heat upgrading. In the HESPER project (Heat Store &amp; Processor for Emissions Reduction) developed in the IDP8 framework Sunamp Ltd, Zytek Automotive Ltd and University of Edinburgh intend to demonstrate via tests of HSP at the vehicle sub-system and system levels that:\n1.CO2 emission from internal combustion engine (ICE) used in conventional, start\/stop, hybrid and plug-in hybrid vehicles can be drastically reduced by thermal pre-conditioning of the cylinder head and catalytic converter;\n2. range extension and homogeneity (specifically in variable weather conditions) for electrified vehicles (HEVs, PHEVs, BEVs) can be achieved, avoiding electric battery oversizing;\n3. fuel cells startup in cold climate can be facilitated and stresses on electrochemical components reduced;\n4. the overall system related to thermal management can be drastically simplified;\n5. materials at the core of the technology are safe in automotive environments;\n6. the technology can achieve Technology Readiness Level 5 for automotive applications.","isTelecoms":1}
{"text":"Title: The University of Reading and BP Exploration Operating Company Limited Abstract: To embed the latest research on extreme weather events to reassess the design criteria of offshore platforms.","isTelecoms":0}
{"text":"Title: Stochastic Analysis on Noncompact Manifolds Abstract: The central theme of the project is the analysis of the so called path spaces, the space of continuous paths over a curved space. The aim is to gain an understanding of its geometry and to obtain a geometric analysis for it and for its subspaces. This knowledge shall be used for the analysis of more complicated spaces such as the space of continuous loops. The main focus of the investigation will be analysis on Lp spaces. Stochastic differential equations on geometric spaces will be a primary tool and so will also be studied. The emphasis of this proposal will be path spaces over a smooth non-compact but complete Riemannian manifold.","isTelecoms":0}
{"text":"Title: LSD-CortLVPC - Applying voltage-imaging techniques to visualise the effect of lysergic acid diethylamide (LSD) on cortical layer V pyramidal cells and its adaptation during tolerance development Abstract: Serotonergic hallucinogens (sHG), such as lysergic acid diethylamide (LSD), rank among the most controversially discussed agents of modern neuropsychopharmacology. They are popular drugs of abuse, scientifically are used to study the pathophysiology of psychosis, can pose a threat to health, but most recently also re-gained attention as promotors of psychotherapy. The controversy at hand remains unresolved by modern science and politics, and the European Research Area is faced with the imminent challenge to come up with a strong and competitive scientific basis that is able to elucidate how these drugs work and how their working potentially translates into benefit and\/or detriment to European health and society. \nThe psychoactive effects of sHG are mediated by activation of serotonin 2A (5-HT2A) receptors within the cortex of the brain. In vivo, sHG disconnect cortical networks, desynchronise alpha oscillations and inhibit the metabolism of the cortex. In vitro, sHG primarily enhance the excitability of cortical layer V pyramidal cells (LVPCs), which is accounted for by 5-HT2A-glutamate interaction. The in vivo effects of sHG often are interpreted with regard to their in vitro effects. As there are virtually no LVPC specific investigations in living animals, however, the in vivo relevance of the postulated 5-HT2A-LVPC-glutamate triangle is highly speculative. \nOur project brings together Prof. Thomas Kn\u00f6pfel, who has been pioneering optogenetic electrophysiology, and the 5-HT2A-hallucinogen expertise of Dipl. Psych. Tobias Buchborn. It applies advanced techniques of voltage imaging (with the voltage-sensitive fluorescent protein Butterfly 1.2 genetically targeted to LVPCs), combines them with selective neuropharmacological challenges and 5-HT2A specific ethological observations, and reveals within the brain of waking mice whether it is indeed LVPCs and their submissiveness to 5-HT2A-glutamate interaction that represent the point pivot of the cortical action of LSD.","isTelecoms":0}
{"text":"Title: Neuroimaging and neurochemical ageing biomarkers for optimising prognosis in motor neurone disease Abstract: 1) Brief description of the context of the research including potential impact\nAmyotrophic lateral sclerosis (ALS) is a progressive neurodegenerative disease with no known cure. The time between disease onset and the end stages of disease vary widely from patient to patient. Patients with ALS endure rapid widespread brain tissue loss and this process typically progresses quicker in elder people. ALS is therefore thought to interact with the ageing process, which by itself usually causes gradual loss of brain tissue. It may be the case that individuals with larger amounts of age-related tissue loss may have a more fatal (shorter survival time) prognosis if they develop neurodegenerative diseases like ALS. To this end, machine learning algorithms in tandem with magnetic resonance imaging (MRI) data, have been used to predict disease progression in neurodegenerative diseases. This is done through the 'brain age' index, which is a measure that is informative for brain health. Additionally, neurofilaments data taken from blood samples, are informative for brain atrophy. In health, neurofilaments typically reside in the cytoplasm of neurons, and are released into the blood after neurons die. As individuals age and normal brain tissue loss occurs the levels of neurofilaments in blood also increases. Both MRI and neurofilaments data have been useful for predicting outcomes in ALS but have not previously been used together. The present research aims to combine data from both modalities in-order to develop techniques which aid ALS prognostication. This will be done through the application of computational methods, with a particular focus on machine learning. These statistical\/machine learning models will be sensitive to accelerated age-related brain tissue loss as well as increased neurofilaments in the blood. Ultimately, such models will be able to recognise the rate at which ALS will progress in an individual patient. This will increase the speed and cost effectiveness of clinical trials for ALS interventions, as well as enabling targeted treatments. \n\n2) Aims and Objectives\n -The specific objectives are to:\n- Develop multimodal (MRI and blood) machine learning and other statistical models that are sensitive to accelerated age-related changes to the brain. \n- Use these models to correctly classify whether ALS will progress quickly or slowly within an individual. \n- Apply these approaches to aid in the development of targeted treatments and more efficient clinical trials for ALS drug treatments. \n\n3) Novelty of Research Methodology\nOur research methodology is novel primarily due to the multi-modal nature of the machine learning\/statistical models that will be developed. MRI and blood samples data have independently shown promise in predicting ALS prognosis, but their combination should provide even greater power to predictive models. Also, the use of 'brain age' as well as, machine learning techniques in aiding prognostication of neurodegenerative diseases is a recent development. Therefore, this project will be able to unlock more of the potential these techniques have already shown. \n\n\n4) Alignment to EPSRC's strategies and research areas\nThis project is aligned with the EPSRC's healthcare technology strategy. Within that, the project is aligned with the medical imaging, clinical technologies and analytic science research areas. \n\n5) Any companies or collaborators involved\nN\/A","isTelecoms":0}
{"text":"Title: A new generation of insect resistant GM crops: transgenic wheat synthesising the aphid alarm signal Abstract: When aphids (greenfly) are attacked by predators they release a warning signal to alert other neighbouring aphids. This is achieved by a chemical called an alarm pheromone that other aphids can smell. This alarm pheromone is completely non-toxic, even at levels far higher than would be used in this project. As well as being produced by aphids, it is produced naturally by some non-crop plants. One such plant is peppermint and we have isolated the gene responsible for the production of pure aphid alarm pheromone in peppermint plants. By inserting this gene into other plants we can make them produce the pheromone and we have recently performed this transformation with a simple plant called thale cress which is widely used by biologists as a model. When we did this aphid pests were no longer attracted to the transformed cress. Furthermore, natural insect control was improved because a key natural enemy of aphids, called a parasitoid, searched for aphids for a longer period of time on the transformed thale cress. Following this success we now need to carry out a similar transformation with wheat, a crop plant of worldwide importance, so as eventually to exploit this system for aphid pest control and breed a new generation of environmentally friendly GM crops. Other insect pests also have pheromones and the approach developed here should lead to possibilities for replacing toxic insecticides with non-toxic insect behaviour signal chemicals in other crops too. Studies will initially be conducted under contained laboratory conditions and then extended to carefully regulated field trials. We propose to transform wheat plants with the aphid alarm pheromone gene, check that the transformed wheat plants are emitting the pheromone and then examine the effects on aphid pests and their natural enemies. Groups of aphids on leaves will be exposed to the odour of the transformed wheat and the proportion of aphids scuttling away will be recorded. Special devices called olfactometers will then be used to give aphids and their parasitoids a choice between air passing from the transformed wheat or a blank airflow. We expect that aphids will be attracted to normal wheat odour but repelled by odours of the transformed plants and that the aphid parasitoids will be more attracted to the transformed wheat. Parasitoid behaviour on the transformed plants will also be compared with behaviour on normal plants. Field simulator containers will be used to measure aphid settlement on normal and transformed wheat. Once we have identified the most promising wheat varieties under lab conditions we will test them outdoors in field plot trials. Aphid numbers will be counted in samples of 100 plants per plot every week during the growing season. We expect that aphid settlement will be reduced on the transformed wheat plants and that any aphids that do settle will be more exposed to attack by natural enemies. The combined effect of an aphid repellent odour and attraction of natural enemies will mean lower aphid infestations on the transformed wheat plants. This will provide a new option for reducing insecticide use on crops in the future.","isTelecoms":0}
{"text":"Title: Neutralizing antibody responses in HIV-2: role in disease progression and protection from subsequent HIV-1 coinfection. Abstract: Natural infection with many viruses results in the production of antibodies which help clear the virus and protect us from subsequent reinfection. Eliciting such an antibody response is the basis of many effective vaccines, but unfortunately little is understood about protective antibody responses in HIV, which has hindered HIV vaccine design. Despite sharing many similarities with HIV-1, most patients with HIV-2 do not develop AIDS (although a minority do) and the reason for this is not entirely clear. This project proposes to compare antibody responses in HIV-1 and HIV-2 infected patients and explore whether stronger antibody responses are found in HIV-2 infected patients who do not progress to AIDS, when compared to those who do, and HIV-1 infected patients; at a stage where the immune system is relatively well preserved. Early studies also suggested that HIV-2 antibodies could render HIV-1 non-functional and we also propose to compare this ability in patients who are HIV-2 infected and go on acquire HIV-1 superinfection, with those who have remained HIV-2 mono-infected despite possible exposure to HIV-1. Such information could provide vital clues to how the HIV surface interacts with antibodies and the importance of eliciting an antibody response in future HIV vaccines.","isTelecoms":0}
{"text":"Title: Harnessing the purine salvage pathway to treat ATP deficit in cerebral ischemia. Abstract: Stroke is a global health problem affecting ~14 million people per year, with ischemic stroke accounting for 85% of cases. Ischemic stroke results from disruption of blood flow in part of the brain. Without ample oxygen supply from the blood, the cells can be irreversibly damaged or die causing a number of neurological deficits.\nThe key mechanism which triggers cell death during a stroke is the loss of ATP synthesis mechanisms and the subsequent depletion of ATP. When the energy demands of the brain cannot be met and the membrane homeostasis and ionic gradient, which regulate synaptic transmission, are disrupted. This causes a metabolic crisis resulting in rapid cell death at the site of the ischemic episode. Over time, this cell death can spread to otherwise salvageable cells meaning stroke treatments must be administered as soon as possible to be effective. Currently the only method of treatment is effective in just 10% of patients due to these time constraints. \nThis project will investigate a novel method of stroke treatment which utilises metabolites of the purine salvage pathway (PSP), ribose and adenine, to generate ATP and restore energy balance in the brain. \nThe PSP is the primary route of adenine nucleotide synthesis in the brain via the production of AMP, a precursor to ATP. The addition of ribose and adenine to brain slices, which mimic the ischemic brain in terms of ATP content, has been shown to restore ATP to in vivo values. This approach has also been shown to be beneficial in a rodent model of stroke. Theoretically, this is due to the incorporation of these molecules into the PSP, increasing the production of AMP and subsequently ATP. This is a promising method of treatment as both ribose and adenine are safe for intravenous administration. Additionally, the PSP enzymes are cytosolic, eliminating any need to target organelles. This could allow for more rapid treatment and increase patient outcome should this be approved as a stroke therapeutic.","isTelecoms":0}
{"text":"Title: Adiabatic and dynamical algorithms for quantum hardware Abstract: Quantum computing - in which we use the unusual properties of very small particles or electronic circuits to process information - has the potential to revolutionise high-performance computing as applied across major industry sectors and branches of science. The computational capability of a quantum computer can grow exponentially, so that adding just one quantum bit will double the potential capacity. However, there are important challenges to realising the potential of these devices. These challenges are not only around building the hardware for quantum computing, but also how to programme a quantum computer in order to take advantage of the new opportunities it could offer for a particular calculation. \n\nIn this project, we explore new techniques for programming quantum computers, both relevant for near-term devices that require noise mitigation and hardware-specific algorithms, and future error-corrected quantum computers. We will begin by developing new techniques to build specific quantum states by changing the parameters of the system time-dependently without adding excess energy to the system (which we refer to as optimised counterdiabatic driving). In addition, we will develop quantum algorithms for specific applications, identifying opportunities for speeding up calculations in computational fluid dynamics, plasma dynamics, or quantum science, and understanding where these might exhibit an advantage over existing conventional algorithms on supercomputers. Finally, we will test implementations of these techniques on current hardware, alongside developing techniques to verify the output of the quantum computer.","isTelecoms":1}
{"text":"Title: NEw MEdical CYbersecurity assessment and design Solutions Abstract: The European health care system is moving toward personalised, distributed, and home-based services. This is made possible via new and improved connected medical devices (MDs) and in vitro diagnostic devices connected to the internet (together, CMDs), and will benefit health care providers in terms of reduced cost (fewer hospital beds) and improved service. Patients will see improved quality of life in terms of reduced travel time and reduced stress via treatment at home or where they want it. However, for these benefits to be fully realised, the cybersecurity of CMDs needs to be ensured. NEMECYS will benefit practitioners such as cybersecurity communities, MD manufacturers, CMD scenario system integrators and CMD scenario operators (e.g. health care providers), with downstream benefits to patients and the wider public, through more cost-effective and efficient care enabled via effective and streamlined cybersecurity. NEMECYS helps practitioners to (1) comply with MD regulations; (2) to be able to apply proportionate MD cybersecurity (too little security risks exposure, too much is costly and can obstruct clinical care) and (3) build in cybersecurity by design for both MDs and the connected scenarios they operate in. This is achieved by (1) providing recommendations for best practice and guidelines for MD cybersecurity by design, along with compliance assurance tooling; (2) providing a risk-benefit scheme to address cybersecurity risk balanced with clinical benefit; and (3) providing a set of specific tools to address MD cybersecurity by design and their deployment in connected scenarios. The NEMECYS team has cybersecurity risk experts, two hospitals who are already implementing IoT and remote care-based scenarios, three medical device manufacturers, major computer science research players and experienced systems integrators. This team is ideally placed to ensure that NEMECYS can enable practitioners to apply the right security at the right place, at low cost.","isTelecoms":1}
{"text":"Title: Interrogating the function of deubiquitylases Abstract: Interrogating the function of deubiquitylases","isTelecoms":0}
{"text":"Title: Catalogue of Italian Paintings in Glasgow Museums Abstract: No catalogue of the important collection of Italian paintings in Glasgow Museums has been published since 1935. The present project has resulted in a detailed scholarly catalogue of all 140 works (principally in the Kelvin Grove Museum and Art Gallery but also in the Burrell Collection and Pollok House), many of which are major works of art. All 140 have been analysed to provide basic information on dating, subject-matter, patronage and provenance. In many cases, the entries provide a balanced and up-to-date synthesis of existing research; in many others, they have involved new investigation and new assessment. As well as serving as an essential tool for professional art historians, the catalogue will provide a fundamental basis for the wider knowledge and appreciation of Glasgow's pictures, especially by way of the Museum's website.","isTelecoms":0}
{"text":"Title: ASPIRE \u2013 Aerospace Special Processes Intelligence and Re-skilling of Employees Abstract: ASPIRE project innovation focuses on responding to the sustainable productivity need of aerospace special-process houses through the integration and piloting of our MVP vision intelligence application with our AeroDNA production-control solution. The combined solution will deliver the capability to extract real-time data on human performance to:\n\n* digitise human action from skilled special-process operators to provide automated time, motion and error capture data\n* alert operators about special-process defects and non-compliance vs. standardised process routes captured in AeroDNA so they can be remedied immediately\n* extract and segment video of human actions on the special-process house shop-floor to retain best-practice through digitalised knowledge transfer.\n* remote access to visualise special-process operations in real-time by distributed process engineering teams\n* capture unprecedented business intelligence about special-process human operations which will feed into the AeroDNA scheduling solution to optimise electroplating vats and heat treatment oven utilisation which significantly impacts energy consumption and sustainability.\n\nThe approach leverages state-of-the-art AI computer vision to recognise operator actions on special processes to ensure that stringent aerospace quality standards are met. The use of convolutional neural networks offers more generalisability for pattern recognition and performs better for detecting anomalies compared to traditional automated optical inspection. A digital record of the actions that have been performed on a product can then be stored as a proof of quality management as well as be used to train new special-process operators. This record is useful for digitally connecting factories so that defects can be traced through supply-chains and used to prove quality standards.","isTelecoms":1}
{"text":"Title: Flexible Lightweight Architecture for Volume Applications (FLAVA) Abstract: The Flexible Lightweight Architecture for Volume Applications (FLAVA) project will enable the UK low\/medium \nvolume auto sector to implement &amp; integrate carbon composite multi-material flexible modular solutions \nwithin Body in White structures. Materials &amp; manufacturing process innovations resulting from the project offer substantial weight savings, enhanced flexibility in design, significant assembly &amp; logistics benefits &amp; enable adoption of a flexible powertrain strategy at an investment &amp; unit cost that can support a viable business case. These benefits will lead to reduced tail-pipe &amp; logistics CO2 emissions, on-shoring of high value manufacturing capability and development of the UK composite supply chain whilst enabling enhanced competitiveness of low\/medium luxury vehicles to maintain &amp; grow export sales.The project will demonstrate the capability of the supply chain, materials &amp; manufacturing processes to meet Automotive OEM quality &amp; production rate requirements and for the integration of significant composite structural content in standard paint and vehicle assembly lines whilst supporting the wider UK composite strategy for growth.","isTelecoms":1}
{"text":"Title: University of Edinburgh and IDEMS International Community Interest Company KTP 22_23 R4 Abstract: To substantially improve mathematics education by developing features for authoring of online materials in the STACK assessment system, especially for mathematical proof.","isTelecoms":1}
{"text":"Title: Superconducting Power Generators for Large Wind Turbines Abstract: One problem when we are trying to field super-big wind turbines is that all components involved become super heavy as well, particularly power generators. Heavier power generators require more robust foundation towers for support, which dramatically increase the cost of the entire system. The project is to investigate approaches of lightening up the next generation of utility scale turbines to generate 10 MW peak power. The major aim of this project is to develop a new compact superconductor-based generator able to work in both onshore and offshore wind turbines. Based on previous research work, it was proven that the weight when compared to conventional power generators could be reduced by at least 30% by applying superconductors. However, further work is required to analyse and improve the existing design; such as in regards to the superconducting windings and the cryogenic cooling system. The final objective is to build a 15kW prototype to prove the feasibility of the new lightweight power generator.","isTelecoms":1}
{"text":"Title: Turbulence in the Solar Corona and Near-Sun Solar Wind Abstract: Some of the central open problems in heliophysics are how the solar corona is heated and how the solar wind is accelerated. Plasma turbulence near the Sun is thought to be one of the key processes involved in answering these questions. The NASA Parker Solar Probe spacecraft is currently on its way to the solar corona making in situ measurements of the solar wind at ever closer distances. This project will make use of this new data, and related plasma theory, to understand the nature of turbulence near the Sun and the role it plays in coronal heating and solar wind acceleration.","isTelecoms":0}
{"text":"Title: Local Galois representations for higher genus curves Abstract: The aim of this research project is to describe the Galois representation attached to a hyperelliptic curve over a local field. Partial results on this problem exist: in particular, for elliptic curves it is known how to compute the inertia image and, in some cases, even the whole Galois representation. The first step of this project is to complete all the remaining cases, giving an explicit solution which can be implemented in a computer program. For higher genus curves, less is known, so the final objective is to understand the Galois representation for special families of curves, for which recent developments in the theory of models of curves can be applied, and again provide an explicit description of it.","isTelecoms":0}
{"text":"Title: SNAP-DRAGON: Subpolar North Atlantic Processes - Dynamics and pRedictability of vAriability in Gyre and OverturNing Abstract: SNAP-DRAGON will produce a step change in our understanding of the processes that link atmospheric changes to subpolar ocean variability, their implications for ocean and climate predictability in this region, and the degree to which we can trust their representation in climate models.\n\nThe subpolar North Atlantic Ocean, stretching between the UK, Greenland and Canada, plays a crucial role in local and global climate. This is the critical region where much of the warm water flowing northward in the upper North Atlantic releases its heat to the atmosphere and is converted to cold, dense water, before flowing southward again at depth in what is known as the Atlantic overturning circulation. The huge amount of heat this circulation carries northward and releases to the atmosphere impacts the storm track that determines the weather over western Europe. The overturning circulation also has profound implications for African rainfall and hurricane statistics via its effect on sea surface temperatures at lower latitudes. In addition, the sinking of water in the subpolar region ventilates the deep ocean, transferring heat and carbon away from the surface and moderating the impact of anthropogenic greenhouse gases on surface temperature. Any warm water which does not sink in the subpolar region recirculates or carries its heat further north towards the Arctic, influencing sea-ice conditions and polar marine ecosystems before it too sinks and flows south.\n\nRecently, the first ever observations of the overturning circulation in the subpolar North Atlantic have been made by the Overturning in the Subpolar North Atlantic Programme (OSNAP, www.o-snap.org). These have revealed large amplitude variations in the overturning, but raised questions about the locations and processes that give rise to this variability, and its likely impact on surface ocean conditions and climate.\n\nRepresenting this region properly in climate models is essential if we are to make useful climate predictions on seasonal, interannual, decadal and longer timescales. However, the current generation of models struggle to represent the processes we know to be important here, and disagree with the observations on the locations in which warm water is transformed into dense water. The disagreements limit our confidence in model predictions. We cannot assess model performance properly because we do not understand all the links between atmospheric conditions and ocean circulation variability.\n\nIn SNAP-DRAGON we will combine OSNAP and other observations with numerical models that can represent small-scale processes to work out what causes variations in subpolar ocean circulation. Once we know which processes are most important and how they work, we will be able to establish what climate models are getting wrong, and suggest improvements. This will improve predictions of ocean and climate variability in the subpolar North Atlantic and beyond.\n\nWe will investigate how cold, dense waters find their way into the boundary currents that export them to the south. We will establish the role that winds play, which is likely more complicated than we have assumed in the past. And we will determine the impact on overturning variability of changes in freshwater export from the Arctic and Greenland. To characterize and quantify these key processes, in addition to using ocean observations, we will perform &quot;What if?&quot; experiments in ocean models, asking questions such as: what happens to the subpolar ocean circulation if the atmospheric jet stream over the Atlantic shifts or strengthens? We will use statistical methods more common in weather forecasting to figure out how subpolar ocean properties and overturning connect to potentially predictable larger-scale atmospheric circulation patterns. And we will employ innovative ways of combining models with observations to determine a best estimate of the evolution of the subpolar North Atlantic over the OSNAP observation period.","isTelecoms":0}
{"text":"Title: Fighting Antibiotic resistance with point of care breath analysis Abstract: Due to the over prescription of antibiotics in cases where they do not help people get better, some bacteria have become resistant to them. To slow down this resistance, doctors need to prescribe less antibiotics in cases where they will not help. One way to do this is by developing a test to detect if a patient has a bacterial infection or not. This test should be quick, cheap and simple to undertake both at a GP surgery and in hospital and with no inconvenience a patient and preferably non-invasive.\n\nThere is a need for a point-of-care (POC) diagnostics device to assist clinical decision making in the administration of antibiotics. Simply being able to identify if a patient is suffering from a bacterial, viral or fungal infection could produce a significant reduction in drug administration -- the key is to provide the clinician or GP the confidence NOT to prescribe a drug\n\nIMSPEX Diagnostics Ltd will further develop their Breathspec(r) device, which has already been successfully trialled on patients with respiratory tract infections. The developments are needed to make the Breathspec(r) device compliant with legislation for medical devices. As this is a complicated process, IMSPEX will have help from leading research scientists from Warwick University, specialist design engineers and the NHS. Creating a cost-effective, quick and easy-to-use test for deciding if patient have a bacterial or viral chest infection.\n\nIMSPEX Diagnostics Ltd will bring to market a diagnostic tool that can assist in antibiotic stewardship and rule out inappropriate antibiotic use. This will give both patients and doctors confidence in the decision to prescribe antibiotics or not. This concept is so innovative that there is currently no other company actively developing an AMR test that uses breath analysis. This means that there is an opportunity for IMSPEX Diagnostics to be first to market with such as test.","isTelecoms":1}
{"text":"Title: ThioTech - sulfur containing materials to capture hazardous waste and precious metals Abstract: Environmental pollutants are one of the largest risks to human health, therefore, the release of contaminants must be controlled and prevented and, where release has already occurred, remediation methods should be used to isolate the harmful substance and make the area safe. Aimed at the highly toxic substances used and generated in industry, ThioTech, a new university spin out company, has developed a series of promising sulfur containing sorbents, which can be applied in the mining, oil &amp; gas, waste service, and power industries. Because of the high sulfur content, the high specific surface area (over two thousand square metres of surface per gram of material), and special chemical bonds, ThioTech materials have a high affinity for heavy metals and precious metals, such as mercury and gold.\n\nFirst of all, mercury pollution is an urgent global health concern. 128 countries signed a joint agreement to reduce mercury emissions (Minamata Convention), causing tightening restrictions on industry, and a need for more effective materials to adsorb mercury. Secondly, the mining of precious metals such as gold, platinum, and palladium uses chemicals to dissolve the metals in ores and pump them back to the surface as an aqueous solution. The gold is then captured onto adsorbent materials like activated carbon (porous charcoal). Mercury and cyanide are the most common gold leaching reagents in the gold mining industry, therefore, a non-toxic and environmentally friendly gold leaching agent is needed. The problem is there is no viable sorbent material to retrieve gold from the safer alternative gold leaching agents. Therefore, benefiting from the special chemical structure, ThioTech materials are anticipated as a promising approach to solve these two challenges.\n\nMarket research of the potential of ThioTech materials was investigated through the Innovation to Commercialisation of University Research (ICURe) programme, supported by Innovated UK, and showed high feasibility for establishment of a spin-out company. In the next stage, ThioTech will focus on materials scale-up development and primary commercialisation. The new company will be based in Liverpool, and collaborate with other British companies in technology development, material manufacturing, and validation study. ThioTech sorbent has potential as an import substitution in UK industry and to allow export to overseas markets, consequently, stimulating the economic growth of upstream and downstream industries. Therefore, from both economic and public health aspects, this support from Innovate UK represents the value for money for the taxpayer.","isTelecoms":0}
{"text":"Title: The microbiome of the helminth infected host: Implications for immunity and intestinal homeostasis Abstract: Worm parasites (helminthes) are capable of infecting the gastrointestinal tract of a broad range of animals including humans. Helminth infection is often associated with pronounced effects on the health of the infected individual host. An example of such a parasite is the human whipworm that infects 1 billion people worldwide. An analogous model system exists in the mouse that allows us to study the interaction between the whipworm and the host?s immune system and understand the mechanisms by which the host attempts to eradicate the worm. The site of whipworm infection in the large intestine is home to the host?s gut flora, these bacteria are important in the development and maintenance of the host?s immune response and in digesting complex dietary molecules. We have data showing that in a chronic whipworm infection in the mouse there are dramatic changes in the gut flora of the infected animal. In this research we aim to precisely define these changes in the gut flora following whipworm infection and then to understand the functional implications to the host as a result of these changes. Specifically, do the changes in gut flora provide a new ecosystem in the gut more beneficial to long term worm survival? Do they compromise the ability of the infected individual to digest complex carbohydrates thereby leading to long-term weight loss? Finally, do these changes in gut flora have implications on the way we mount immune responses e.g. to other infectious agents or in terms of immune disease such as autoimmunity or allergy.","isTelecoms":0}
{"text":"Title: Testing Plume and Plate Models of Ocean Plateau Formation at Shatsky Rise, Northwest Pacific Ocean (IODP Leg 324 - Shatsky Rise) Abstract: The Scientific Summary for IODP Leg 324 is provided in the approved IODP Scientific Prospectus (http:\/\/publications.iodp.org\/scientific_prospectus\/324\/324sp_7.htm). It is as follows: One of the most fundamental questions of modern geodynamics is the process of mantle convection and its impact on Earth's surface through volcanism. The greatest source of nonocean-ridge volcanism appears to be massive eruptive episodes that formed oceanic plateaus, volcanic passive margins, and continental flood basalts. A widely accepted hypothesis for such volcanism is that it results from the head of a starting plume, which rises from the deep mantle, spreads out beneath the lithosphere, and melts cataclysmically in a massive outpouring of volcanic activity. Despite the wide acceptance of this hypothesis, a convincing case for a plume head origin has not been made for any oceanic plateau; rather, significant complexities have been revealed by recent drilling of the Kerguelen and Ontong Java plateaus. One great difficulty with research of oceanic plateaus is that the original setting, relative to mid-ocean ridges and plate tectonics, is poorly known for most plateaus because they were formed during the mid-Cretaceous when no magnetic reversals formed ridge-parallel anomalies to record spreading ridge locations. Shatsky Rise, located ~1500 km east of Japan, is unique in being the only large oceanic plateau formed during a time of magnetic reversals, permitting its tectonic setting to be resolved. Magnetic lineations show that the plateau formed along the trace of a triple junction, intimately related to ridge tectonics. Existing data demonstrate that several aspects of Shatsky Rise's history (e.g., massive, rapid initial growth; transition from large to small magma flux; capture of ridges) fit the plume head model. On the other hand, the coincidence of volcanism with the triple junction, ridge jumps, and the lack of isotopic evidence for a hotspot-type mantle source can all be taken as favoring a plate-controlled origin. Its unique combination of features makes Shatsky Rise the best location on Earth to test plume versus plate-tectonic hypotheses of ocean plateau formation. During Integrated Ocean Drilling Program Expedition 324 we propose to core ~800 m of igneous basement at five sites on Shatsky Rise to examine the history, source(s), and evolution of this plateau. From the results of this expedition, we hope to be able to put to rest the question of whether oceanic plateaus like Shatsky Rise were formed from deep-sourced mantle plumes or interaction of plate boundaries and the lithosphere with the shallow mantle.","isTelecoms":0}
{"text":"Title: Exploring complexity and scalability of Near-term Quantum Computing algorithms for Quantum Chemistry Abstract: The study of molecular systems is heavily limited by current computing capabilities. As molecular systems grow in complexity exponentially, accurate computation of chemical properties becomes challenging even for small systems. Quantum computing offers many promises in terms of much larger modelling molecular systems than what we can currently do classically. The Variational Quantum Eigensolver (VQE) is one of the main examples of near-term quantum algorithms that are expected to find application in quantum chemistry. However, its scalability is still largely under question. Recently Zhenyu Cai (Oxford) has implemented resource estimates for VQE simulations of the 50-qubit Fermi-Hubbard Model, and discussed the requirement of multi-core NISQ processing to and better error mitigation in the context of near-term quantum hardware. The VQE, relies on classical pre-processing. In particular, we must first compute the second quantised Hamiltonian of the system, which already has a computational cost of O(N^4) for N orbitals. As such it will never replace the most widely used computational quantum chemistry method, Density Functional Theory (DFT) as its cost of solving is O(N^3) not assuming any sparsity (this would bring the cost in either case down). To be computationally relevant, the VQE must first and foremost be able to produce significantly more accurate results than DFT. At the same time, a suitable benchmarking analysis must compare the result and computational cost of VQE to a more accurate Quantum Chemistry method such as Full Configuration Interaction (FCI)\/\n\nRahko is currently leading a project aiming at studying the scalability of the VQE. The start-up is looking for a CASE PhD student to collaborate on furthering this research and conduct a formal study of the feasibility of using near-term quantum computing for quantum chemistry.In particular, the student will be researching the latest literature on Quantum algorithms for quantum chemistry (beyond VQE) and build a methodology for assessing their scalability in comparison to the best practices for the likes of DFT and FCI. As part of this project, the student will define the state-of-the-art methods to implement quantum algorithms and will identify bottlenecks and possible improvements for their scalability throughout the programme stack. The student will be given access to Rahko's quantum development platform, Hyrax , and will gain access to real quantum computers (e.g. AWS Braket, Azure Quantum, IMBQ) and supercomputers through Rahko's and UCL's partnerships.","isTelecoms":1}
{"text":"Title: HQ Project Abstract: The HQ is an interactive website designed to help girls aged 15 - 18 achieve their potential. Underpinned by the award-winning BBM approach for soft-skills development, the exciting game takes players on a journey of discovery that will lead them to a future of personal well-being and professional success.","isTelecoms":0}
{"text":"Title: Molecular epidemiology of Neoparamoeba perurans, causative agent of amoebic gill disease (AGD) in farmed salmonids Abstract: The amoeba Neoparamoeba perurans is the causative agent of Amoebic Gill Disease (AGD), one of the most significant health challenges faced by the global marine salmonid aquaculture industry. Treatments for AGD enable salmon producers to improve salmon welfare and reduce mortality, but the disease often returns in the same production cycle to the same fish. Although we are starting to understand more about N. perurans and its interaction with the host, there remains little known about the phylogeographic history and population genetics in relation to its distribution, abundance and evolutionary process that influence its epidemiology. As an important global pathogen, it is important to start understanding its transmission routes and molecular variation. Different variants of the parasite have been suggested to have emerged globally but there have been few studies that have attempted to identify the total number of variants, found within a particular locality nor have there been any attempts to assess the potential movement of such variants within and between farms. This PhD will use elements of both classic epidemiology and molecular epidemiology to assess movement and connectivity between fish farms and provide essential insights into transmission. The project will utilise both archived and contemporary samples to provide insights into the molecular population genetic structure of N. perurans in Scotland. Similarly, phylodynamic analyses will be employed to assess movement between infected sites. To achieve this, we will employ already established nuclear and mitochondrial molecular markers and will also attempt to develop new markers to assess fine scale evolutionary processes which could affect the transmission and epidemiology of the parasite. Within Scotland's salmon aquaculture, field samples will form a basis for answering epidemiological questions, such as what the prevalence of AGD is, and can we quantify and explain infection pressure. Open-source data such as environmental variables obtained from satellite data will be used to complement existing data for meta-analysis. An overall understanding of the molecular epidemiology of N. perurans will enable us to provide better recommendations for health management of AGD. Successful candidates will have the opportunity to work within internationally recognised teams at Epidemiological Research Unit of Scotland's Rural College (SRUC) and Institute of Aquaculture, University of Stirling and to receive training in cutting-edge epidemiological analysis, molecular biology, and parasitological techniques.","isTelecoms":0}
{"text":"Title: Coventry University And Daido Industrial Bearings Europe Limited Abstract: To investigate ultrasonic technology to facilitate the electrochemical deposition of innovative multifunctional coatings on bearings to enhance the sustainability of automotive, marine and industrial engines.","isTelecoms":1}
{"text":"Title: Synthetic process optimisation for production of switchable hydrophilicity disperse dyes Abstract: Polyester is the world's most used textile, with approximately 61 million tonnes produced annually (i), however the dyeing polyester process produces large volumes of chemical pollution, and high water usage with over 110 L per kg of fibre produced (ii). This means there is significant interest for a new dyeing process that eliminates polluting auxiliary chemicals and has low water usage. A new class of dyes for polyester is being developed which removes the need for polluting dispersants, reduces water and energy use, whilst providing equivalent performance within commercially used polyester dyeing machinery. This technology could be revolutionary in significantly improving the sustainability of the textile dyeing industry and contributing to the development of a circular economy.\n\nDue to these possibilities, it is critical that there is rapid scaling-up of the synthesis of the novel dyes, assisting in meeting project delivery targets and raising the commercial viability of the product. The use of a continuous flow system is being targeted to achieve this, however the current synthetic processes required optimisation with respect to the rate of reaction. In order to assess the efficacy of process changes, including use of basic catalyst and increase in reaction temperature, the reaction rate is monitored by both online and offline analytical techniques. Once optimised, the reaction will be transferred to a continuous process, to allow large scale dye production required for pilot scale studies.","isTelecoms":0}
{"text":"Title: Creating a 'Health Talk Online' web-based resource on family experiences of disorders of consciousness Abstract: Developments in medical technologies and procedures are associated with a rapid rise in the number of people surviving in prolonged disorders of consciousness (e.g. 'vegetative' and 'minimally conscious' states). However there has been relatively little research, and few resources, to help people to deal with the issues that arise when they have a loved one in\nsuch a condition. Our original research demonstrated the need for high-quality internet resources to support these families and to serve as a resource for relevant professionals. The proposed project builds on our original study of 30 people with a relative in a disordered state of consciousness who were interviewed about their experience of the care and treatment of their loved one (e.g. a partner, parent, offspring or sibling). Although the focus of this original research was 'decision making' these interviews (which lasted an average of 4-5 hours) form a rich data-base in which families talk about a wide variety of issues from the shock of the original injury and the process through which a diagnosis was reached over time, through to the long term issues facing families (emotional and practical) and the complex choices in which they may be involved (e.g. where their loved one should be cared for, how to manage their affairs, what specific medical treatments should be pursued or forgone).\n\nThe original interview study was conducted using qualitative methods based on rigorous social science research methodology and all interviews were conducted by one or other of the senior researchers submitting this bid. These data will be combined with interviews with an additional 8 interviews (videoed where possible) and the entire corpus will be re-analysed for the purpose of writing 20-25 summaries on the issues that are most important to these families in order to produce a resource to be published on 'HealthTalkOnline' http:\/\/www.healthtalkonline.org\/) - a widely used site (5 million hits \/100,000 unique visitors per month) certified under the Department of Health's Information Standard scheme and winner of severalawards for the innovative form, accuracy and quality of the information it provides (e.g. British Medical Association Patient Information Awards, Health Care IT Effectiveness Awards and Social Innovation awards - see www.healthtalkonline.org\/Overview\/Awards_healthtalkonline).\n\nThe development of the new HTO section of the website about disorders of consciousness will follow the good practice model already established through over 70 HTO projects (see attached list of HTO modules). The topic summaries will be drafted by the senior researchers who collected the original data under the guidance of Sue Ziebland, and drafts will be discussed and reviewed with her, and by a member of an expert advisory panel. The panel will include family members\/carers, social scientists and health and social care professionals. The summaries of key issues will be illustrated with clips from the interviews in video, audio or text format and the researcher will identify, in consultation with the advisory panel, a list of respected national and local organisations and websites that provide other kinds of information and support, for inclusion on the site. \n\nPrior to publication of the material on the HTO website by project partners DIPEx we will coordinate two focus groups to ensure that the new site reflects the experiences of families and that we have correctly identified the issues that are important to a broad range of people. This piloting will include participants being invited to explore the draft website and complete a brief questionnaire. After publication the site will be promoted and developed for use by a wide variety of users\/stakeholders.","isTelecoms":0}
{"text":"Title: Dynamic zoonotic disease modelling for environmental change Abstract: Human infectious diseases are a significant threat to global human health and economies (e.g., Ebola, SARS), with the majority of infectious diseases having an animal source (zoonotic) (Jones et al. 2008 Nature 451:990). Despite their public health relevance, many important diseases have not been systematically studied from a quantitative perspective, limiting our understanding of how spillovers of zoonotic infectious diseases into the human population are impacted by global and local environmental stressors (Whitmee et al. 2015 Lancet 386:1973). Furthermore, for most diseases little is known about how climate change, anthropogenic landscape alteration and changing populations will impact on future infectious disease outbreaks (Hotez &amp; Kamath 2009 PLoS Negl Trop Dis 3:e412). There is therefore an urgent need for a more interdisciplinary approach integrating computational modelling, ecology and health towards a holistic understanding of disease dynamics. \n\nComputational modelling can play a significant role in prediction of potential threats and evaluation of intervention strategies, yet effective modelling of zoonotic diseases requires an interdisciplinary breadth that is seldom achieved. In this project, we bring together leading computational, ecological and epidemiological expertise to develop a new integrated framework of disease modelling for the important endemic Lassa fever (LF) disease in West Africa. Lassa fever virus is the cause of one of the most prevalent viral haemorrhagic fevers in the region. Serology-based techniques estimate between 100,000 to 300,000 LF cases per year (compare to Ebola 30,000 total cases since 1970), with a fatality rate that ranges between 1% and 69% depending on the setting. Despite its importance, relatively few studies have tackled the problem of modelling the epidemiological dynamics of LF on a large scale (Redding et al. 2016 Methods in Ecol. &amp; Evol 7:646). As in most zoonotic diseases, much of the complexity arises from the interplay of disease dynamics in reservoir (animal) populations and the human population, as well as the spillover between the reservoir and humans. All of these processes happen concurrently in a spatially heterogeneous and dynamic environment; understanding the origin of spatially localised phenomena such as hotspots is essential to predict effects of environmental change and evaluate intervention strategies. \nOur ambition in this PhD project is to combine ecological models of animal reservoir, spillover and human disease spread in a single probabilistic modelling framework which will enable full uncertainty quantification and prediction. Importantly, our approach will leverage recent developments in the statistical computing community (Schnoerr et al. 2016 Nature Comms 7) to retain a higher level of mechanistic detail that is currently possible within epidemiological models. This will enable us to provide model-based predictions of responses to a changing environment, and to evaluate the impact of intervention strategies in plausible future scenarios. This project will work in close collaboration with the Institute of Global Health at UCL and partners at The Centre for Disease control for Nigeria and the west African hub of the African Union to embed the research into policy and priority setting within the stakeholder communities across west Africa.","isTelecoms":0}
{"text":"Title: Investigating the role of complement component 5a in ANCA-associated vasculitis Abstract: The immune system is the body's powerful response system that acts to defend us against infections. It has two main protective methods - mediated by immune cells and soluble components like 'antibodies' and 'complement' proteins which can punch holes in microbes. Unfortunately, the immune system sometimes gets wrongly activated and responds to our own tissues and organs. This causes a group of diseases called 'autoimmune' diseases. One subtype is a disease called 'vasculitis', literally meaning 'inflammation of blood vessels', which occurs as a result of immune attack by antibodies and complement. Blood vessel inflammation causes patients to get organ damage in the lungs and kidneys. Sadly, this kidney damage can be severe enough to cause kidney failure, requiring blood cleaning therapy (dialysis). The treatments that we have used for the past 20 years are variably effective, and have lots of side effects, but recently, a new drug that blocks the complement system was used in patients with vasculitis in a clinical trial. This complement blocker drug seemed to reduce kidney damage, but we don't know exactly how it does this.\n\nThis project will investigate blood, kidney tissue, and tissue taken from the back of the nose that contains immune cell collections (called the adenoids). We will take these tissue samples from patients with vasculitis who come to our clinic before and after they receive the complement blocker drug. We will use new technologies to analyse antibodies and tissue cells to produce a clearer picture of the effect of blocking complement on the human immune system and kidney. One of these technologies uses information about how the genetic code of cells is translated into action, by measuring genetic messenger molecules called 'RNA'. The Clatworthy lab are international experts in studying RNA, down to the level of individual immune or tissue cells. We can also match up this information with changes in blood immune cells and kidney function and can determine the location of immune cells in tissues affected by the complement blocking drug using a special microscope technique that can measure where RNA molecules are in tissue. \n\nThe information that our project will generate is important because it will tell us more about how complement affects the immune system in humans and how the complement-blocking drug works, both in inflamed kidneys and in immune tissues, potentially opening it up to be used to treat other autoimmune and kidney diseases.","isTelecoms":0}
{"text":"Title: Loughborough University And MacDermid Plc Abstract: To scale up and refine, for industrial operation, a recently developed process for conditioning plastics prior to metallisation, without carcinogenic and environmentally restricted chemicals.","isTelecoms":0}
{"text":"Title: Advancement of castings in the Nuclear Supply Chain Abstract: The challenge we would like to address is the advancement of nuclear castings in the nuclear supply chain. Steel castings are used for the reactor coolant pump (RCP) casings for nuclear power stations. Both the Westinghouse AP1000 and Areva EPR designs use steel castings for this application. Sheffield Forgemasters carried out a product and material qualification program in order to become a preferred supplier for the Westinghouse design and is currently involved in a similar process for the Areva EPR.","isTelecoms":0}
{"text":"Title: PALS (Predictive Analytics for Learning- Safeguarding) Abstract: The aim of the Predictive Analytics for Learning-Safeguarding (PALS) Project is to\ndemonstrate a proactive E-Safety system instead of the purely responsive functionality used in\ncurrent systems. This will be achieved by creating a new E-Safety analytics service to collect,\naggregate and analyse the relevant data from deployed E-Safety systems. The corresponding\ntrend analysis will be used to continually improve the deployed E-Safety system operation\ncapabilities. While the initial use of these new algorithms will be in systems supporting\nprimary and secondary schools, broader market sectors will also be targeted. This will enable\nthe establishment of a first-to-market solution. The innovation is based upon the creation of\nthe new data algorithms for:\na) Trend-based data analytics that can be used to improve significantly the identification of\ncyber-bullying, grooming and other e-safety abuses. These new analytics will also reduce, by\n90%, the number of \u2018false-positive\u2019 declarations;\nb) Exploitation in a wider range of market sectors. Versions of the algorithms will be \u2018tuned\u2019\nfor new systems; in Higher and Further Education, Law Enforcement, Health-care and\nCorporate Human Resource Management markets.\nA recent internal \u201cstate-of-art\u201d product evaluation has shown there is no commercial solution\nproviding the predictive-based learning safeguarding capabilities proposed by this Project.\nThe benefits that accrue to users from this new approach are:\na) More accurate identification of cyber-bullying, grooming, etc. so that administrators,\nmentors, law enforcement, etc. can make timely and better-informed interventions;\nb) Access to better Reports that allow administrators, mentors, law enforcement, etc. to put\nevents into a broader context and provide information on what future events may be expected.\nThe key objective is to produce and evaluate a \u2018demonstrator\u2019 to confirm the approach and\nensure that the required predictive functionality and performance is achieved.","isTelecoms":1}
{"text":"Title: Resolution-Enhanced Microwave Imaging Devices for medical imaging and cancer detection (REMID) Abstract: The aim of this joint TSB project is to develop a new medical imaging prototype based on microwave imaging (MWI). MWI uses low-power, non-ionizing radio frequency microwaves to obtain clinically meaningful images in a way that addresses the patient\u2019s needs for speed, safety and comfort. While there is considerable progress in medical MWI systems under development by various research groups worldwide, there is no commercial MWI system available today. The proposed prototype will be designed around the patient experience to deliver a pain free, safe and accurate system. The novel clinical prototype targeted by this project will be applied first to breast cancer screening. It will allow younger patients (aged 20 and over) to be screened as often as they wish and to be monitored for a longer period of time, thus maximizing the success rate for the early screening of cancer. This is an important benefit that is currently not available in a cost-effective and sustainable manner using today\u2019s technology.","isTelecoms":1}
{"text":"Title: ODYSSEUS - PREVENTING, COUNTERING, AND INVESTIGATING TERRORIST ATTACKS  THROUGH PROGNOSTIC, DETECTION, AND FORENSIC MECHANISMS  FOR EXPLOSIVE PRECURSORS Abstract: ODYSSEUS aims to increase the knowledge on explosive precursors and homemade explosives (HMEs), including precursors not previously studied, and develop effective and efficient prognostic, detection, and forensic tools to improve the capabilities of LEAs towards the prevention, countering, and investigation of terrorist incidents involving HMEs. ODYSSEUS will build upon relevant previous projects mainly HOMER, through the involvement ofHOMER\u2019s core partners in this consortium, and will thus continue the work already done in HOMER on some precursors and further extend it to not previously studied precursors.\nTo discover potentially hitherto unknown information, online HMEs recipes will be collected and their content will be analysed so as to extract knowledge about (possibly unknown) precursors and HMEs. Selected precursors will be then characterisedand analysed for determining their explosive properties, feasibility, and potential for becoming a threat.This knowledge will be leveraged for developing tools for(i) chemical supply chain monitoring for irregularity detection to enable prediction and localisation of potential threats; (ii) advanced sensors for detecting in (near) real-time explosive precursors through air emissions and sewerage networks; (iii) robotised tools for improved mobile detection and in-situ forensic support; and (iv) automated threat detection, localisation, and assessment; these tools will be integrated into a configurable platform that will assist LEAs\u2019 operations in diverse scenarios. \nODYSSEUS will be validated in lab and field tests and demonstrations in three operational use cases. Extensive training of LEAs' personnel, hands-on experience, joint exercises, and training material will boost the uptake of ODYSSEUS tools and technologies. With a Consortium of 4 LEAs, 9 Research\/Academic partners, and 5 industry partners, ODYSSEUS delivers a strong representation of the challenges, requirements and tools to meet its objectives.","isTelecoms":1}
{"text":"Title: University of Portsmouth and Magma Structures BP Limited Abstract: To develop a capability to diversify the innovative expertise in large composite structures from marine applications into other sectors.","isTelecoms":1}
{"text":"Title: Improved Processes and Materials for Energy Saving Glazing Abstract: Low emissivity glass, sometimes known as 'low E' or 'low energy glass', is playing an increasingly significant role in building energy efficiency. The key feature of this glass technology is a thin coating with a refractive index chosen to enhance the capture of solar energy and reduce heat loss from within the building. There is a significant opportunity to develop new improved 'low E' coatings coupled with more efficient cost effect processes to fabricate them. This project addresses both of these topics by targeting increased performance and reduced cost compared with current low energy glazing. With increasing environmental awareness, more emphasis is now being placed on ways to save energy in any building, domestic or commercial, and Glazing products can play an important role to minimise heat loss from these structures. This heat loss is normally measured by the thermal transmittance or U value and in its most basic terms, the lower the U value, the greater the thermal insulation. Insulating Glass Units incorporating low emissivity glass can significantly improve the Thermal Insulation values hence the improved performance targeted on the project will have a large impact. It is estimated that if all the existing buildings in Europe without low-E glazing were to have it installed to current regulations recently introduced relating to minimum energy efficiency standards, it would save 27-30% of building energy and 140 M Tonnes of carbon dioxide.","isTelecoms":1}
{"text":"Title: Chingford Cyber security Abstract: &quot;Chingford Electrical Supplies would like to increase the cyber security of our business by applying to take Cyber Essentials Plus. \n&quot;","isTelecoms":1}
{"text":"Title: Genetic, lipid and other risk factors in early-onset acute myocardial infarction in Malaysia. Abstract: Coronary heart disease (CHD), with myocardial infarction (MI) or &quot;heart attack&quot; as the main manifestation, is the leading cause of death worldwide, and is also the leading cause of death in Malaysia. It is estimated that in Malaysia and other South-East Asian countries, nearly a quarter of CHD events occur in people younger than 50 years, resulting in a significant loss of productive working years due to death and disability. This is why we have deigned a case-control study of acute MI in Malaysia to recruit 5000 participants (2500 MI patients or &quot;cases&quot; aged &lt;50 years and 2500 healthy participants or &quot;controls&quot;). In this study, we will initially investigate the hereditary and lipid-related risk factors of heart attack in Malaysia's population - which has distinctive features of multi-ethnicity and consanguinity (or intermarriage). \n\nThe specific objectives of our proposed study are to:\n\n(1) investigate genetic risk factors of premature heart attack in Malaysia;\n\n(2) evaluate cardiovascular risk factors of specific relevance to the Malaysian population, such as indigenous forms of tobacco consumption and local dietary patterns, with potential implications of results for public health policy; and\n\n(3) create collaborations between Malaysian and UK scientists, who will jointly manage and further harvest the dataset and bioresource of this nationally-important research platform.","isTelecoms":0}
{"text":"Title: Sustainable Oxidation Catalysts for the Production of Solar Hydrogen and Chlorine from Brine Abstract: Summary\n\nThe primary aim of this project is to produce new, sustainable oxidation catalysts that allow the creation of efficient wireless, photodiode, solar to chemical energy conversion devices for the splitting of brine\/seawater. In brine, H2, alkali and Cl2 (or H2 and sodium hypochlorite, NaOCl will be the (separated) products. Hydrogen will be stored to provide heat at a later date (by burning) or used to produce electricity (via an H2\/O2 fuel cell). \n\nThe oxidised chloride will be stored either as Cl2, or hypochlorite, to provide a route to chlorinate water, or provide a disinfectant. The programme will produce inexpensive demonstrators which can be readily scaled up for use in the household - i.e. on a 'personalised' energy and disinfectant scale. Such systems are particularly suited for use in the developing countries, although the subsequent development of substantially scaled up systems - involving solar farms - will allow the production of these valuable, storable, chemical products at a level suitable for widespread use by a town and\/or local industry. The latter scaled up systems will form the basis of a subsequent, second follow on stage, industry led, developmental program of work, whereas the first stage project described here will focus on the proof of concept and initial creation of scalable demonstrators. \n \nThe proposed novel ClOCs developed in the project will utilise inexpensive, abundant nanomaterials (such as: oxides of Mn, Ni or Co), although, in some cases, these will be doped with well-dispersed, much more active, but less abundant ones, such as Ru dioxide. These nanomaterials will also be coated onto high surface area conducting carbons, which will allow them to be partly supported and active. A novel, combinatorial approach, using High-throughput Continuous Hydrothermal flow synthesis, HiTCH and, to a lesser extent, other - electrochemical and photochemical synthetic methods, will be used to produce a wide range of oxidation catalysts. Novel, colour-based rapid screening methods will be used to provide initial assessments of their activities and a wide range of techniques will be used to assess their physical properties. \n\nThe best of the catalysts generated will be optimised in terms of performance as electrocatalysts and subjected to more detailed electro-kinetic and structural studies (e.g. XANES and XAFS) and subsequent mechanistic and structural modelling. This work will help identify key structural features associated with the most active of the electrocatalysts tested and inform on the best routes to be taken in the subsequent synthesis of related materials as oxidation catalysts of possible greater potential. Finally, the best of all the electrocatalysts tested will be used to create simple, exemplar, scalable working wireless photodiode solar energy conversion devices, which utilise inexpensive, efficient, triple-junction Si photovoltaic cells as the light-absorbing unit, for the photocleavage of water or brine (including seawater).","isTelecoms":1}
{"text":"Title: COEXIST - Coexistence on the boundary of chaos Abstract: This project is an exploration of the essence of chaos. Chaos and chaotic systems are by their very nature unpredictable. Paradoxically, the manner in which systems transition into chaotic regimes is highly structured and rigid. This contradiction can be explained mathematically through an elegant process called renormalization. Renormalization is like a microscope which can be used to observe the shape of fractals that appear on the boundary of chaos. One aspect of the structure of chaos is that such fractals on a large scale may look nothing like each other, but as the magnification factor on the microscope is increased they look more and more alike. This is expressed by saying that renormalization converges. Convergence of renormalization has been a consistent theme since the very inception of chaos theory, thus it was believed that the structure of chaos was thoroughly understood. In an unexpected twist, the applicant recently made the groundbreaking discovery that there are natural systems for which the renormalization sometimes is convergent and at other times degenerate. This reveals that the structure of chaos in fact is much more intricate than was previously imagined.\n\nBuilding on this radical discovery, the proposed project marks the start of an entirely new chapter in chaos theory. The objective is to explore this new notion of coexistence of convergent and degenerate behavior of renormalization, and to explain the consequences it has on the structure of chaos. The research will benefit the field of dynamical systems by expanding the knowledge of chaos into new and unexplored territory. It will also expand the reach of renormalization closer to systems which have relevance for the natural sciences as well as mathematics. The project hinges on the applicant joining the supervisor and members of the dynamical systems group at Imperial College, who are leading global experts, in order to learn cutting-edge techniques and spark new discussions.","isTelecoms":0}
{"text":"Title: A Molecular Touchscreen Abstract: Point-of-care testing (POCT) represents 15% of the of the in-vitro diagnostics market and is predicted to reach 38 billion USD market size by 2022. A key driver for growth is the demand for faster, portable and inexpensive testing for a high number of end users. Mobile phone diagnostics bring new potential to this field on a global scale as rapid, widespread testing requires a non-invasive reader system, calibrated quantitative outputs and the means to collate and compare data. As of 2018, there are 4.6 billion mobile phone users worldwide, rounding up to 67% by 2019 with an uptake in developing countries.\n\nThis project aims to explore how wet assays can be integrated with component technologies in the phone with a vision to create a new personal biosensor platform. For example, we will specifically investigate the potential of linking to the electrical properties and measurements made in touchscreen technologies and design a device that responds to (i) changes in ion concentration and (ii) the presence of targeted biomolecules near the screen surface to provide a measurement of personal health. It is anticipated that the approach will scale to tackle broader diagnostic challenges in developing countries where rapid, inexpensive tools with embedded computing and communication capabilities are needed to take on healthcare and agricultural challenges.\n\nThe research methodology is based on four steps: \n- Research into the full range of sensors available within the phone platform, including ability to access advanced electrode and device structures. \n- Identifying suitable physical and chemical model systems to enable a wet assay to integrate with phones. The model systems will begin as simple electrolyte sensors and move to more complex molecular label designs.\n- Study quantitative readouts to understand limits of detection and interpretation of results in the context of biosensing. \n- Prototyping of hardware links to enable the sensing platform, including a paper study into the scale-up potential to help with delivering impact after the PhD programme.\n\nThe project is carried out together with industry partners such as M-Solv Ltd. By uniting latest manufacturing technologies with the most recent advances in affinity protein engineering, DNA technology and cell proliferation analysis, the project combines a variety of academic disciplines, all represented in the EPSRC's strategic portfolio of highly relevant research areas:\n- Clinical technologies\n- Sensors and instrumentation \n- Manufacturing technologies\n\nThese areas of biosensing and microscale material manufacturing are highly relevant to the CambridgeSens strategic network, and communication of this research will enable broader impact through other fields and industries, such as water quality associations, the food industry, agriculture and air pollution detection.","isTelecoms":1}
{"text":"Title: How do Rif1 and SAF-A remodel chromatin to ensure effective DNA repair? Abstract: Our genomes are constantly damaged, each cell suffering upwards of 30,000 DNA breaks or lesions every day. Repair must occur in the context of chromatin, the nucleoprotein assembly that packages DNA within the nucleus. Regulated changes in chromatin structure are important for effective repair.\nThe protein Rif1 has emerged as critical to control DNA repair. Rif1 suppresses inappropriate homologous recombination, ensuring repair of double-stranded DNA breaks by the direct end-joining pathway. Rif1 is also implicated in organising chromatin into correctly sized loop domains. The molecular mechanism through which Rif1 controls DNA repair and chromatin organisation is however still obscure. We recently discovered that Rif1 is a 'Protein Phosphatase 1-targeting subunit', binding Protein Phosphatase 1 (PP1) to direct it to dephosphorylate specific substrates. This discovery raises the possibility that Rif1 acts in DNA repair and chromatin organisation by mediating dephosphorylation of chromatin components. In a proteomic screen for proteins showing increased phosphorylation upon Rif1-PP1 depletion we identified chromosome scaffold protein SAF-A (Scaffold Attachment Factor A; also called HNRNPU). Professor Nick Gilbert's lab in Edinburgh showed that SAF-A controls chromatin compaction and domain organisation. SAF-A is recruited to damage sites and its depletion causes DNA repair problems. \nThis PhD project will test the hypothesis that Rif1-PP1 directs DNA repair through chromosome remodelling, in particular by dephosphorylating chromosome scaffold component SAF-A to control chromatin compaction. Project addresses three specific questions:\n1. How does Rif1 affect recruitment of repair components and resolution of DNA damage? To examine effects of Rif1 on recruitment of chromatin components and subsequent repair, the endonuclease I Ppo1 will be expressed in immortalised human 293 cells to inflict controlled DNA damage (induced I-Ppo1 cuts around 20 sites in the human genome). Using flow cytometry and chromatin immunoprecipitation, we will monitor recruitment of chromatin-modulating repair components to damage sites, in control cells and cells depleted for Rif1, SAF-A, or both. DNA repair will be simultaneously monitored by PCR analysis across break sites. This section examines Rif1-mediated recruitment of chromatin modulators in relation to repair effectiveness. \n2. Does Rif1 direct repair by regulating chromatin compaction activity of SAF-A? Following DNA damage chromatin first condenses to enable checkpoint activation then is subsequently extended for DNA repair to occur. The student will test whether Rif1 dephosphorylates SAF-A after damage to mediate these changes, evaluating how chromatin compaction and conformation are affected if Rif1 and SAF-A are absent. We will test the effect of a Rif1 mutant that cannot bind PP1, and of SAF-A mutated at the phosphosites most increased by Rif1\/PP1 depletion). Mutants will be generated using CRISPR, and chromatin compaction will be monitored using sucrose density sedimentation followed by deep sequencing, and by fluorescence in situ hybridisation. \n3. Are Rif1 and SAF-A essential to establish chromosome domain organisation and chromatin compaction? We will also test whether Rif1 regulates higher-order chromatin organisation by SAF-A under undisturbed, non-DNA-damaging conditions, an intriguing question as determinants of chromatin domain structure and higher order chromosome organisation in normal cells remain elusive. Informed by Parts 1 and 2, the student will test this hypothesis by examining the effect of Rif1 and SAF-A on chromatin organisation in embryonic stem cells. \nOverall this project provides an outstanding training opportunity for an ambitious student to build on biochemical studies by understanding how DNA damage repair operates in the in vivo chromatin context, and to investigate establishment of normal chromatin organisation during development.","isTelecoms":0}
{"text":"Title: Microcavity polaritons in atomically thin semiconductors and heterostructures: many-body and nonlinear phenomena Abstract: Atomically thin materials offer a new paradigm for control of electronic excitations in the extreme two-dimensional (2D) limit in condensed matter. Recently this concept has been developed further when artificial potentials for electrons were created in heterostructures consisting of stacked 2D layers held together by van der Waals forces, and light was used to access and manipulate electronic spin and valley degrees of freedom in atomically-thin semiconducting transition metal dichalcogenides (TMDCs). A significant world-wide effort in the last 5 years has resulted in intense studies of optical properties of TMDC atomic layers in the linear regime. Here, we propose to use this new class of (2D) semiconducting crystals to demonstrate unexplored approaches to exploiting nonlinear optical phenomena on the nano-scale in regimes unattainable by other ultra-fast photonic materials. To achieve this, we will exploit robust excitonic complexes observable up to room T, which will be generated and controlled in artificially created vertical stacks of 2D atomic layers. Giant nonlinearities enabling ultra-fast control of light with light of low intensity will be realised and explored in such van der Waals heterostructures placed in optical microcavities, operating in the strong light-matter coupling regime that we demonstrated recently. In this regime part-light-part-matter polaritons are formed, with the exciton part responsible for the strong nonlinearity and the photon part providing efficient coupling to light. This work will open a new route to development of highly nonlinear nano-photonic devices such as miniature ultra-fast modulators and switches, with high potential to impact on a new generation of signal processing and quantum technology hardware.","isTelecoms":1}
{"text":"Title: Characterising cellular division and coupled DNA segregation in ASGARD Archaea Abstract: Archaea were discovered in the 1970s as a new domain of life. While their cell biology is only just beginning to be explored, it is clear that they share some aspects of their cell biology with bacteria and\/or eukaryotes, while having other unique cellular attributes. Like all cells, archaea must grow and divide to propagate. To accomplish this task a cell must copy all of its cellular components, including its genetic material, before dividing into two. During my PhD, I aim to study this process in TACK and Asgard archaea, which are the closest living known relatives of eukaryotes - sharing a common ancestor that likely lived between 1 and 2 billion years ago. Given the especially close evolutionary relationship between Asgard archaea and eukaryotes, which is reflected in their possession of machinery that was once thought to be unique to eukaryotes, my work should lead to a better understanding of archaeal cell biology, eukaryotic cell biology, and our origins. \nThe process and mechanisms by which TACK and Asgard archaea partition their DNA and divide is not understood. Genomic data has revealed that different members of the TACK and Asgard archaea possess many 'eukaryotic like' machinery involved in cell cycle control (the proteasome, E2F and a Cyclin box transcription factor), DNA organisation (Histones), DNA replication (Cdc6\/Orc, MCM, GINS) and cell division (ESCRT-III, Tubulin, Actin, SMC proteins, and Topoisomerases). In addition, they possess other machinery that appears more similar to those found in bacteria (FtsZ, SepF and ParA\/B homologues). This project will aim to understand DNA segregation and cell division is achieved by Lokiarchaeota and Hodarchaeota, members of the ASGARD phylum that Dr Fraser Macleod in the Baum lab has growing in culture, and Nitrosopumilus, a member of the Nitrososphaerota phylum grown by the Bharat lab at the LMB. To accomplish this overarching goal, this project will be split into three main aims.\nAim 1: Optimise growth conditions for the different archaeal cultures. This will involve exploring the effects of the media composition, oxygen, and temperature on growth. Note that the Asgard archaea growing in the lab were isolated from Shark bay in Australia where there are large-scale changes in environment each day. Develop a system for accurately identifying species within mixed cultures (which include Heimdallarchaeota, Hodarchaeota, Lokiarchaeota, and Thorarchaeota, and their syntropic partenrs and a host of other cells). Define the doubling time for species of interest within the culture and the cell cycle profile using flow cytometry. Image cell growth and division live (using dyes that bind DNA and mmembranes) and in fixed cells. Determine if Lokiarchaeal and Hodarchaeal cells round up before dividing. Determine their gene expression patterns using RNAseq (ideally single cell RNAseq).\nTechniques used:\n- Community microbial culturing under different conditions\n- Phylogenetic analyses\n- Genomic analyses and RNAseq.\n- Live and fixed cell imaging\n- Flow cytometry to determine normal cell cycle distribution \nAim 2: Identify key DNA segregation and division machinery in Asgard archaea and in Nitrosopumulus using a range of bioinformatics approaches. Once a panel of key proteins has been identified and refined, I will explore their localisation and cell cycle regulation. Note that the lab already has antibodies that are specific to cytoskelet proteins in Nitrosopumulus. I then aim to generate reagents (nanobodies) that can be used characterise their localisation across different stages of the archaeal cell cycle. These reagents will be used to study the localisation of different machineries via both immunofluorescence using regular and expansion microscopy. Binding partners will be identified using both computational biology (Alphafold), by crosslinking mass spectrometry (currently being optimised by the Bharat lab) and co-immunoprecipitation assays coupled with western blotting.","isTelecoms":0}
{"text":"Title: The development of 129Xe polarisation optimised MRI techniques for functional lung imaging. Abstract: Lung disease is the 4th largest cause of death worldwide and also creates a massive burden of ill health. Current methods for monitoring the extent and progression of lung disease such as chronic obstructive pulmonary disease (COPD) ans interstitial lung disease (ILD) are limited to anatomical information derived from high resolution CT scanning or functional information from pulmonary function testing. There is a major need for a method to noninvasively monitor regional variations in ventilation and gas transfer using nonradioactive techniques in order to provide a sensitive way to aid diagnosis and monitor therapy. The aim of this proposal is to utilize advances made at the University of Nottingham in the field of hyperpolarized gas technology, coupled with state of the art magnetic resonance (MR) imaging, to develop new, clinically valuable methods to monitor the extent and progress of lung disease in patients.This proposal will achieve this aim through a new collaboration between internationally recognized researchers in the Sir Peter Mansfield MR centre (Prof P Morris, Dr M Barlow and colleagues) and a clinical academic with specific expertise in lung disease (Prof IP Hall), both in the University of Nottingham, and collaborators at GE Healthcare, a major international manufacturer of clinical imaging equipment. Specifically, during this programme of research we will (i) optimize methods for the standardized production of hyperpolarized Xenon to underpin these novel imaging techniques, (ii) develop equipment, software and MR techniques to achieve high resolution functional images of ventilation and gas transfer in normal subjects, and (iii) establish an academic imaging facility embedded in the Medical School to facilitate initial physiological imaging of both in and out patients with specific lung diseases in an appropriate clinical environment using optimized MR methodology. This project therefore offers the possibility of providing novel clinical tools for the diagnosis and monitoring of pulmonary diseases.","isTelecoms":0}
{"text":"Title: Dissecting disease heterogeneity in cardiac patients using multimodal machine learning, modelling, and simulation method Abstract: Cardiac disease is a major cause of mortality, often leading to arrhythmic or mechanical death such as in heart failure, a condition which occurs when the heart stops being able to pump blood correctly. Despite lifestyle adjustments and life-long treatment to manage symptoms, the condition typically worsens over time and can lead to death or an urgent heart transplant. New methods are required to account for the variability of cardiac disease across a diverse patient population and to correctly evaluate severity and risks. New biomarkers derived from multimodal data could provide a stronger prognosis than current techniques by increasing diagnostic sensitivity, providing more details on the pathophysiology, predicting disease progression, and identifying the therapy option that best mitigates each individual's condition.The objective of this project is to develop novel computational methods that exploit the synergy between AI approaches and mechanistic modelling and simulation for the realisation of precision cardiology. Specific goals include identifying new multimodal biomarkers to define cardiac disease subgroups, investigating the underlying mechanisms of disease that explain these subgroups, and identifying therapeutic targets and treatments that best improve the outcomes of each subgroup. These studies will be carried out by using data-driven methods to leverage the wealth of information contained in the UK Biobank and Clinical Practice Research Datalink electronic health records, and by augmenting this information through digital twinning and simulations. Representative groups of patients will be identified by using machine learning strategies to integrate clinical data, such as cardiac magnetic resonance imaging and electrocardiogram, with patient demographics (e.g. age, sex, co-morbidities) and genetics. Unsupervised clustering strategies could provide preliminary patient subgroups. These subgroups could be compared to, or enhanced by, subgroups obtained from novel data representation strategies based on generative models (Beetz et al., 2022). This would help explain the phenotypical variability of cardiac disease in the human population and help automatically identify the biomarkers that define subgroups. Mechanistic differences between these subgroups can be explained using cardiac digital twins, which are built using an existing electromechanical pipeline that simulates cardiac activity based on the centroids of patient clusters obtained (Camps et al., 2021, Banerjee et al., 2021). In order to improve target identification in the clinic, we will investigate the efficacy of therapeutic options and their link to the new biomarkers by using simulation testing on each group's representative digital twin.\nIn summary, the project will deliver novel strategies combining AI and simulation methods, helping to uncover new data-driven trends in cardiac biomarkers and perform cardiac simulations on a per-patient basis level to unravel mechanisms of disease. The work aims to improve current diagnosis methods and enable the discovery of more tailored treatment regimens for cardiac patients, helping to alleviate the global burden of fatal cardiac diseases.\nThis project falls within the EPSRC research area of Healthcare Technologies, more specifically at the intersection of Clinical Technologies and Analytical Science, and addresses the Grand Challenge of optimising disease prediction, diagnosis and intervention.","isTelecoms":0}
{"text":"Title: Modelling of glasses as nuclear waste forms Abstract: This proposal addresses the pressing need to find suitable methods to safely encapsulate nuclear waste. This is required in order to make the nuclear industry sustainable and is also necessary for the environmental reasons due to large amount of legacy waste already accumulated. We model new types of glasses as encapsulation matrices and perform state-of-the-art molecular dynamics simulations to understand the stability of glasses and their suitability for long-term encapsulation of nuclear waste. \n\nWe calculate several important properties of novel glass compositions including the activation energy for crystallization and phase separation as well as structure. We compare our results with the structural and thermodynamic experiments performed by our US partners. This will enable us to gain atomistic understanding of what governs stability of glasses at the microscopic level and predict their long-term performance.","isTelecoms":0}
{"text":"Title: METIS-II - Mobile and wireless communications Enablers for Twenty-twenty (2020) Information Society-II Abstract: Key objectives of METIS-II are to develop the overall 5G radio access network design and to provide the technical enablers needed for an efficient integration and use of the various 5G technologies and components currently developed. The innovation pillars that will allow METIS-II to achieve this goal are \n\u2022 a holistic spectrum management architecture addressing the spectrum crunch, \n\u2022 an air interface harmonisation framework enabling an efficient integration of new and legacy air interfaces, \n\u2022 an agile Resource Management (RM) framework providing the dynamics required to efficiently adapt the integrated 5G air interfaces and radio concepts to the varying traffic demand and service requirements,  \n\u2022 a cross-layer and cross-air-interface system access and mobility framework ensuring an ubiquitous access continuum,\n\u2022 and a common control and user plane framework providing the means for an efficient support of the broad versatility of services expected for 5G as well as a future-proof and cost-efficient implementation of the 5G integration.\nOn the strategic level, METIS-II will provide the 5G collaboration framework within 5G-PPP for a common evaluation of 5G radio access network concepts and prepare concerted action towards regulatory and standardisation bodies. \nBased on its very strong and international consortium with partners from all regions with strong 5G R&D initiatives (EU, US, China, Japan, Korea) with most of the major international vendors, major operators, and key researchers, METIS-II will have the unique capability to drive consensus building globally, to consolidate a full picture of the needs of mobile as well as vertical industries, and to disseminate the results towards the relevant bodies, forums, and standardisation groups in all regions.\nThe METIS-II proposal addresses the Strand \u201cRadio network architecture and technologies\u201d in the ICT14-2014 call in the H2020 program. METIS-II is committed to actively drive the collaboration with the 5G-PPP.","isTelecoms":1}
{"text":"Title: Oxford Brookes University and Prospectsoft Limited KTP 21_22 R3 Abstract: To develop additional functionality for its stock-aware CRM system which will provide significantly greater value for its clients, and allow the business to differentiate itself within its markets.","isTelecoms":0}
{"text":"Title: Satellite detection of volcanic eruption impacts on forests Abstract: Volcanic eruptions have significant impacts on any surrounding forests. During major eruptions trees may be scorched or flattened by lateral blasts &amp; pyroclastic flows, buried by volcanic mudflows or damaged by ashfall. Even during low level activity sustained gas emissions alter the density and character of vegetation. Volcanic damage to forests can be detected in reflectance and scattering properties extracted from satellite imagery. The rates and processes of recovery following volcanic eruptions have not yet been well-quantified, but have potential as a tool for identifying and assessing the date of past eruptions, independent from geological methods. This project will exploit multi-platform satellite datasets to map extensive and spatially variable changes in forests after volcanic eruptions, with a particular focus on the period of recovery. \n\n \n\nThis studentship will address the following questions:\n\n- How do major volcanic eruptions affect selected tropical and temperate forest ecosystems? This will be addressed through case studies of major eruptions, for example, the impact of the 2011 eruption of Chaiten, Chile. Significant volcanic impacts to investigate could include the flattening or burial of trees, leaf damage from ashfall, the effect of volcanic gases on vegetation and alteration of drainage\/water supply due to topographic change.\n\n- Can the footprint of past eruptions be detected in forests surrounding active volcanoes?\n\n- What factors affect the rate or recovery of temperate and tropical forests after an eruption?\n\n \n\nTime series of vegetation change will be mapped in the first instance using indexes derived from optical imagery (e.g., LANDSAT, Sentinel-2), with more quantitative analysis over critical periods using Synthetic Aperture Radar imagery (e.g., Sentinel-1 and higher resolution commercial datasets TSX and CSK where available). \n\nThis work will build a new understanding of the characteristics of volcanic impacts on vegetation, and of recovery rates related to different types of volcanic activity. We will test if the spatial extent, nature and intensity of impacts can be interpreted to provide information about past eruption. To do this we will draw on recent events for which pre- and post-eruption satellite imagery are available, as well as looking for longer-term imprints of major eruptions on forest structure.","isTelecoms":1}
{"text":"Title: Manchester Metropolitan University and Social Communications Group Limited Abstract: To develop technology-based approaches for supporting ongoing, meaningful conversation with end users.","isTelecoms":1}
{"text":"Title: Enhanced Homogeneous Iridium Complexes for Extensive Application in Isotope Labelling Processes and as New Catalysts in Wider Organic Synthetic Proced Abstract: Transition metal-mediated hydrogen isotope exchange (HIE) is a technique of increasing importance, with a range of applications spanning all aspects of organic synthesis. Importantly for medicinal chemists, such direct and flexible labelling processes now represent a central tool for the fast and efficient incorporation of a tracer into drug candidates, enabling various metabolic, stability, and toxicity studies to be performed earlier in the drug design process. In this regard, recently established iridium species from the Kerr laboratories have emerged to become some of the most active species in isotopic labelling chemistry. Having applied our developed catalysts to enable the highly efficient labelling of a broad range of both aromatic and non-aromatic unsaturated systems, we have also initiated preliminary investigations into the labelling of more challenging substrate classes as well as probed the use of our catalysts for C-H activation in a wider sense.\n\nThe overarching aims of this programme of work relate to the continued exploration of direct, flexible, and selective means of C-H activation under extremely mild reaction conditions, using specifically developed organotransition metal catalysts. As part of this project, a series of new iridium catalyst will be designed and prepared with their steric and electronic parameters tuned for application within C-H activation and exchange processes. The design of these complexes will be based on the demands of new, challenging substrates for labelling processes as well as emerging wider applications for this family of catalysts. The general substrate structural classes and directing functional groups will be chosen and guided based on their relevance within the drug design and synthesis setting.\n\nIn relation to the EPSRC Portfolio, the main objectives of this programme align with and will address the Research Areas of Catalysis, Chemical Reaction Dynamics and Mechanism, and Synthetic Organic Chemistry and as of importance within the Themes of Healthcare Technologies, Physical Sciences, and Manufacturing the Future.","isTelecoms":1}
{"text":"Title: GCRF Decent Work: Decent Work in Regional Value Chains: Promoting Public-Private Governance in Sub-Saharan Africa Abstract: The growth of South-South trade involving Southern lead firms and end markets presents critical challenges for the governance of decent work. However, we have limited information on whether the commercial dynamics of domestic and regional value chains (RVCs) coordinated by Southern lead firms undermine decent work. Or do they provide new channels for promoting labour standards through multi-stakeholder public-private alliances based in the global South? Can governance of RVCs in Southern markets become more ethical leading to labour outcomes that support sustainable development? This study aims to address this critical gap by asking: What are the implications of regional and domestic value chains in the global South for public-private governance and regulation of decent work in global production? This has key policy implications for the potential development of Southern-based multi-stakeholder public-private 'ethical trade platforms' to support Sustainable Development Goal 8 (SDG8) on decent work. The research addresses this question on three fronts. \n\nFirst, empirically it examines South African and Kenyan retailers that coordinate value chains domestically and across the sub-Saharan Africa (SSA) region. African producers have long supplied multi-national companies (MNCs) through global value chains (GVCs). MNCs apply private governance of social standards (codes of labour practice and fair trade) as a result of civil society campaigns to hold them to account for decent work deficits in GVCs. However, commercial pressures on suppliers to reduce costs and meet delivery criteria often undermine social standards. Production can shift to suppliers with weak labour rights and intensify use of precarious workers. Private social standards have been largely ineffective in securing decent work for precarious workers, many of whom are women. There are now calls for public governance (national labour regulation and social clauses in trade agreements) to play a greater role. Increasingly SSA suppliers also sell into RVCs coordinated by South African and some Kenyan retailers. This research focuses on sourcing by South African and Kenyan retailers of horticulture and garments from South Africa, Lesotho and Kenya. It assesses the implications for attaining decent work, especially for precarious female workers. It examines whether the spread of RVCs imply greater commercial challenges for labour, or could provide a channel for enhancing public-private governance of decent work. \n\nSecond, analytically the research advances global value chain and global production network (GPN) approaches to governance combined with gender analysis of decent work for precarious labour. It adapts polycentric analysis of public and private governance of RVCs to incorporate 'joint and several' accountability for decent work. This extends beyond direct employers, involving wider commercial actors that can influence working conditions, including buyers, suppliers and labour contractors across different value chain tiers. It provides an analytical framework for examining governance of decent work in RVCs that overlap with GVCs. This has important implications for analysis of how linkages between public and private governance can be enhanced to support attainment of SDG8. \n\nThird, policy wise the research combines an inter-disciplinary team working in close collaboration with the UK Ethical Trading Initiative (ETI). ETI has strong connections in sub-Saharan Africa through its company, NGO and trade union members, and with MSIs in South African and Kenya. We aim to provide a research informed contribution to examining how Southern-based multi-stakeholder alliances involving government, commercial and civil society actors could be tailored to South African and Kenyan RVCs. The research will inform ETI's 2020 vision of promoting new 'ethical trade platforms' in Africa as a new model of sustainable development in support of SDG8 on decent work","isTelecoms":1}
{"text":"Title: Paintbox: Development of Printable Direct-gloss Paint Material Abstract: Paintbox is a specialist Tier 1 painting provider to UK based Original Equipment Manufacturers (OEMs). Paintbox's clients include the likes of Bentley, Rolls Royce, Aston Martin, Jaguar Land Rover, and McLaren as well as Hitachi and Alstom in the rail sector. They are currently advancing a proprietary inkjet system, capable of 'printing' paint onto components in the automotive industry. This would enable 100% transfer efficiency of paint onto parts, eliminating overspray and the significant quantities of associated waste and emissions excess overspray produces. The process also removes various energy intensive curing steps, to drive further environmental and cost efficiencies.\n\nThis project is a Feasibility Study whose focus is materials (paint) compatibility, specifically looking at highly-viscous materials. The Paintbox team will be understanding the constraints in developing, testing and designing baseline recipes for printable paints. The paints must be printable and compatible with a variety of substrates (e.g. composites, aluminium and various thermoplastics) and meet OEM performance capability standards to ensure coating longevity. The project will inform system constraints and follow-on R&amp;D required to ensure materials compatibility and scale-up.","isTelecoms":1}
{"text":"Title: Capital Award for Core Equipment at Durham University Abstract: This grant provides support for underpinning equipment for research in chemistry, physics and materials science. By increasing throughput of samples, decreasing downtime due to equipment failure and benefitting from improvements in performance of modern instruments, the new equipment will lead to greater efficiency, higher performance and lower costs. Four pieces of instrumentation will be acquired.\n\nMass spectrometry is a core technique underpinning research in synthetic chemistry. The requested instrument replaces a current spectrometer at the end of its life and provides automated spectra of samples initially separated by high pressure liquid chromatography. UV absorption spectra are provided alongside the mass distribution of the samples. This system allows rapid assessment of samples with enhanced results being available due to the new system.\n\n'Energy dispersive analysis of X-rays' (EDX) enables the chemical composition of a sample within an electron microscope to be determined. This detector will be added to the current focused ion beam instrument which as well as being able to image samples can also &quot;machine&quot; the sample with micron precision. With this attachment as the machining is taking place the user will be able to analyse the material being ablated. In certain structured samples this will enable more precise machining as well as mapping information on the local composition of samples.\n\nMicrowave ovens are a familiar gadget in every kitchen and microwaves can also be used to heat up chemical reactions. Microwave reactors will soon be as common in a chemistry laboratory as in the kitchen. This grant will enable the purchase of a microwave reactor to support a range of projects in synthetic chemistry and materials science and be of particular benefit to early-career researchers.\n\nNMR is a standard method that is used by synthetic chemists to ensure that they have produced the correct chemical and to determine its purity at the end of chemical synthesis. In an active research department such analysis is provided as a service with samples being left for analysis. The purchase here is for a robotic handling system which will take the sample and then run a spectrum minimising the sample handling time and maximising the throughput of the instrument. The autosampler will enable the NMR spectrometer to run up to 60,000 spectra per year.","isTelecoms":0}
{"text":"Title: Realising the UK Value-chain in Graphene Composite Battery Materials (GRAVITY) Abstract: Climate change is one of the greatest threats facing humanity, and transitioning to sustainable energy is paramount to the survival of our species. Transport is Europe's single largest source of CO2, responsible for 25% of the continent's greenhouse gases emissions. \n\nA transition from internal combustion engines to electric vehicles (EVs), along with a grid powered by sustainable energy, can help mitigate climate change. This transition can be accelerated if customers choose to purchase EVs over cars with internal combustion engines. However, there are multiple barriers to widespread EV adoption, including long battery-charging times, uncertainties over battery lifetimes. \n\nThis project seeks to address these barriers by developing graphene-composite electrodes via an inherently scalable and inexpensive process that is compatible with existing industry. Electrons are more mobile in graphene than almost any other known material, travelling thousands of times faster than in metals. Because of this, graphene has outstanding electrical properties, and these can be used to enhance Li-ion batteries (LIBs). \n\nThe cathodes of most LIBs are formed of small particles of metal-oxides, such as nickel manganese cobalt oxide (NMC). These are good at storing Li+ ions, but poor electrical conductors. To enhance electrical conductivity, these particles are coated in carbon black (essentially high-grade soot); however, graphene has far superior electrical properties, and therefore can significantly increase the electrical conductivity of electrodes in the battery. \n\nIt is extremely challenging to create a high-quality graphene-metal-oxide composite. This is because the graphene nano-sheets have a tendency to stick to other graphene nanosheets in preference to the metal-oxide particles. Multiple approaches have been applied to address this problem; however, to-date these have not succeeded, largely because the process results in poor quality graphene (e.g., using reduced graphene oxide), or uses surfactants, resulting in undesirable residues in the materials. \n\nAnaphite has developed a low-cost scalable process to form graphene-metal-oxide composites, which is compatible with the rapidly scaling LIB manufacturing infrastructure. Anaphite's composite materials are suitable for creating batteries with faster charging times. Batteries formed using this technology will also last longer due to the improved electrical performance of the electrodes","isTelecoms":1}
{"text":"Title: QuadWave - Renewable Wave Power Abstract: Aqua Power Technologies designs and develops wave energy converters. QuadWave is our latest wave energy converter and is a design response to the recent industry activity within the wave energy sector. QuadWave is a small, compact and efficient device designed to be deployed in a wave array configuration. QuadWave possesses the unique advantages of utilizing mainstream manufacturing processes, off the shelf comportment selections and ease of transportation and deployment. A careful and considered approach to all aspects of the design have culminated in a device with a realistic commercial case.","isTelecoms":1}
{"text":"Title: BIMERR - BIM-based holistic tools for Energy-driven Renovation of existing Residences Abstract: Building Information Modelling is a critical element in the digitalization of the construction industry, which is necessary in order to unleash huge efficiency and productivity improvements.  BIMERR will design and develop a Renovation 4.0 toolkit which will comprise tools to support renovation stakeholders throughout the renovation process of existing buildings, from project conception to delivery. It comprises tools for the automated creation of enhanced building information models, a renovation decision support system to aid the designer in exploring available renovation options through an the accurate estimation of renovation impact on building performance as well as a process management tool that will optimize the design and on-site construction process toward optimal coordination and minimization of renovation time and cost.  At the heart of the BIMERR toolkit lies an interoperability framework, which will enforce semantic interoperability among BIMERR tools as well as with third-party legacy ICT tools to enable seamless BIM creation and information exchange among AEC stakeholders in an effort to enhance the rapid adoption of BIM in renovation of the existing EU building stock.  The BIMERR toolkit will be validated and demonstrated in 4 buildings in 3 European Member States. Two buildings will be used for pre-validation and implementation refinement and the refined BIMERR toolkit will support the actual renovation design and works in one residential building in Poland and a second one in Spain. The assessment and evaluation of the BIMERR toolkit after these real-life activities will feed material into two supporting horizontal project activities: i) dissemination and exploitation of project outcomes through the creation of best practice examples of BIMERR use that will guide further replication effort, and ii) promotion of BIMERR outcome to the most relevant standardization bodies.","isTelecoms":1}
{"text":"Title: Stopping bone metastasis in its tracks: Abstract: Targeting glycan sugar groups to improve early diagnosis and prevent\/inhibit the spread of prostate cancer to bone.","isTelecoms":0}
{"text":"Title: Acropolis (Advanced Collaborative Research for Oncology Platform for Improved Outcomes, Learnings, Insight and Science) Abstract: Growing healthcare costs and poor patient outcomes is driving increased interest in collaboration to support stratified medicines as a means to deliver targeted, safe and cost effective treatments. Research into stratified medicines is severely curtailed by poor access to high quality patient data and the deluge in associated genetic, molecular and image information.\nThe innovative Acropolis platform will provide the essential informatics infrastructure to support secure stratified medicine research and collaboration, including data handling, storage, retrieval and analysis services that will acquire, pseudonymise and integrate data from a wide variety of diverse sources. Acropolis has a strong consortium led by R&amp;D data management firm IDBS, supported by hosting firm Quantix and leading cancer institutes at Manchester and King\u2019s Health Partners.\nThe Acropolis consortium has all the components to successfully support translational research activities and will ultimately help deliver improved treatment of cancer and other diseases across global healthcare systems.","isTelecoms":1}
{"text":"Title: An innovative eco-friendly concrete water tank to increase water storage capacity in rural areas that could reduce the cost of firefighting by 25% Abstract: Deploy Tech Ltd (Deploy) is a UK-based concrete product manufacturing SME with a core project team of Paul Mendieta, project and commercial lead, and Beren Kayali, technical lead. Deploy is solving a significant unmet need with its concrete water tank designed to help reduce the impact of wildfires in rural areas. The Deploy tank has many unique features. It has a built-in concrete base, can be flat-packed and is easily transportable, even by air. It can be assembled by two people and ready to use in 24 hours. The Deploy tank enables land\/property owners to protect their property by wetting and provides a water source for firefighters.","isTelecoms":0}
{"text":"Title: Vectors to Accessible Critical Raw Material Resources in Sedimentary Basins Abstract: The EU imports 80% of its industrial raw materials making European supply chains highly vulnerable to disruption and threatening the EU's ability to manufacture raw material-intensive technologies, such as electric cars, wind turbines, and ICT hardware, that are essential to the green and digital transformations. Europe possesses significant mineral potential but development is limited by the lack of sustainable, low-impact exploration methods and by social opposition to mineral projects. With VECTOR we will generate new knowledge to overcome these technical and social barriers, unlocking Europe's raw material potential and improving the resilience of EU raw materials supply chains. Overcoming issues will require major changes of the business models in the extractives industry and\nto integrate a more human-centred approach. The VECTOR project is based on the premise that a prerequisite to any sustainable human activity is to minimize the environmental and social costs and include all the stakeholders in the decision making processes around this. VECTOR's overall objective is to deliver evidence-based and accessible knowledge that integrates the scientific and social pathways to successful mineral exploration and mining. The first pillar of our approach is a geological prospectivity toolkit based on an entirely new workflow using machine learning-based integration of less invasive geological, geochemical and geophysical measurements. The\nworkflow will be validated in three European sedimentary basins and will be transferable worldwide. The second pillar is a social acceptance procedure that identifies, for the first time, the values that the European public invokes when deciding about mineral development. This will result in a Social Acceptance index and a new body of knowledge that reflects diverse values-based perspectives. The third pillar is an integrated toolkit consisting of a unique, distributed, multimodal, self-learning, and interactive platform that will consider both geological exploration potential and socio-economic factors to yield a data-driven, quantitative and integrative assessment\nof regions more suitable for exploration and, eventually, mining. The results will be freely available via an engaging, web-based interface designed to support evidence-based decision making and the UNFC and UNRMS.","isTelecoms":1}
{"text":"Title: Novel high-accuracy impedance tomography enabled by time-of-flight EIT via CHIRP current excitation (CHIRP-EIT) Abstract: MRes Student - TBA","isTelecoms":1}
{"text":"Title: Development of new ligation systems for the preparation of peptide-drug conjugates Abstract: the research questions the project is trying to address\/the objectives of the project\n\nAntibody-drug or peptide-drug conjugates (ADCs) are three-component therapeutics frequently used in oncology medicine which consist of a protein recognition motif, a linker, and a payload - typically a cytotoxic drug. Optimisation of each component to achieve biological activity is a major research question and requires design and analysis of targeting, uptake, release and pharmacological activities. \nThis research project aims to target active compounds to a subset of immune cells known as monocytes. These conjugates have high activity\/specificity and are active in cancer models, but the current preparation methods rely on use of synthetic proteins that are not sufficiently scalable for us to develop them further. The Butterworth group (University of Manchester) have developed peptide-drug conjugates that utilise a specific cytokine-receptor interaction to specifically target active compounds, and the Greaney group (University of Manchester) have developed metal-free ligation chemistry on simple small molecule systems that demonstrate exciting chemoselectivity and compatibility with aqueous conditions. This PhD project sets out an ambitious plan to unite the two approaches and define a new toolset for the construction of potent, selective ADCs on scale, and is supported by the biotechnology company LifeArc. ADCs are at the forefront of pharmaceutical industry research and are a key focus of many pharmaceutical companies in the UK.\n\nthe approach that will be taken to answer these questions (what the student will actually be doing)\n\nWe will develop two approaches to realise the synthesis of novel peptide-drug conjugates:\n\n1) Apply medicinal chemistry principles to the optimisation of amine donors for transglutaminase (an enzyme that facilitates conjugation), thus reducing the equivalents of this component required to achieve selective conjugation. Chemoenzymatic conjugation methods can proceed with high efficiency under biocompatible conditions, but typically require laborious syntheses of appropriately tagged linker-warhead combinations, limiting optimisation of the linker-payload component. \n\n2) Examine novel ligation chemistries to broaden scope beyond alkyne\/azide chemistry. The Smiles arylation chemistry developed in the Greaney lab works in water, and is efficient and reliable. Further, the components of the reaction are very bio-compatible, with sulfonamides being mainstays of medicinal chemistry prized for their metabolic stability, and alkynes being the archetypal click component having proven application in numerous chemical biology studies. The chemistry has the powerful feature of generating a fluorescent linkage, creating a functional readout for successful ligation and tracking of cellular uptake and distribution.\n\nthe novel engineering and\/or physical sciences content of the research (the science that places it within EPSRC's remit).\n\nThe studentship will create an ambitious, cross-disciplinary research environment which sits within both the EPSRC remits of physical sciences and healthcare technologies, addressing the following areas: Catalysis, Chemical biology and biological chemistry, and synthetic chemistry.","isTelecoms":0}
{"text":"Title: Trustworthy Ambient Systems (TRAMS) Abstract: Advances in communications and networking technology are making it possible to devise 'ambient' systems in which mobile computing devices and software agents form ad hoc groupings, sharing data and services. The Dependability Research Group at Newcastle University has an outstanding international profile and a history of significant contributions to the trustworthiness of computer-based systems. The proposed platform grant would enable the group to continue its extremely successful research on formal methods for developing fault-tolerant computing systems and to extend this to cover ambient systems. It would do so by providing continuity of research staff, supporting preliminary investigation of new research directions, and supporting travel and visitors to maintain and develop existing and new collaborations. Our focus is on the trustworthiness of ambient systems. We refer to 'trustworthiness' because we wish to encompass both dependability and the evidence that a system is dependable. We are therefore interested in the technology of fault-tolerance, but also highly rigorous techniques for developing and analysing fault-tolerant systems, and the human dimension of the acceptability of ambient systems. Ambient systems pose huge new dependability challenges partly because they cannot be designed as a coherent whole. Mobility means they will be open to new malicious interference and accidental failure modes that are difficult to predict at design time. Their decentralised character means that recovery is potentially difficult. Separate ownership of components means that we can not design for central control over evolution and upgrades. Together, these factors mean that traditional approaches to the engineering of fault-tolerant, dependable systems, which rely on firm design-time knowledge of run-time structure, will be challenged. The very acceptance of ambient systems will depend on socio-technical factors such as how users view the risks and benefits.The project sets out to address a number of specific technical challenges in the five domains:- Formal Foundation, Calculi and Logic- Integrated Verification Tools- Design of Trustworthy Ambient Systems- Fault Tolerance Technologies for Ambient Systems- Socio-technical issues This grant will allow us to conduct investigatory work in these technical areas, to retain key staff and expand the group expertise in these areas, to identify the promising topics which need further researching and to prepare new proposals.","isTelecoms":1}
{"text":"Title: Probing the structure and function of a super-rogue photosystem II complex involved in chlorophyll f synthesis Abstract: There is an urgent need to develop new strategies to improve crop yield to feed the ever-growing global population. Crop plants grow because they use the energy of sunlight to drive the conversion of atmospheric carbon dioxide into biomass. This process of photosynthesis is relatively inefficient with much less than 1% of the incident solar energy converted into stored chemical energy. One straightforward way to improve photosynthetic efficiency is to capture more of the sunlight in the first place. Plants rely on chlorophyll pigments (as well as some accessory pigments) to absorb light to drive photosynthesis. The chemical nature of the chlorophyll pigments found in plants necessarily means that photosynthesis is restricted to the visible region of the solar spectrum. In recent years, however, several strains of cyanobacteria, which perform plant-like photosynthesis, have been discovered that make modified forms of chlorophyll that absorb light in the far-red region of the spectrum. If these far-red chlorophylls could be made in plants and assembled correctly in the photosynthetic apparatus, the number of photons of light that could be used to drive photosynthesis could be increased by up to 19%, a considerable increase in efficiency. One of the far-red absorbing chlorophylls is chlorophyll f (Chl f). In order to make Chl f in plants, an important first step is to identify and characterise the cyanobacterial enzyme that synthesises Chl f. In a recent breakthrough, Don Bryant and colleagues in the USA showed that Chl f synthesis was dependent on the ChlF protein subunit which, somewhat surprisingly, was found to be related to one of the proteins present in the well-studied photosystem II complex which catalyses the light-driven oxidation of water to oxygen characteristic of plant photosynthesis. In follow-up work, we have discovered that ChlF does not act alone, as was originally thought, but is part of a new type of PSII complex, which we term the super-rogue PSII complex. The super-rogue PSII complex shows clear similarities to regular PSII but has evolved to make Chl f rather than split water into oxygen. Chl f is made from the Chl a pigment through an oxidation reaction involving molecular oxygen; but the chemistry involved in this process is currently unknown. In this application, we propose to study the structure and mechanism of the newly identified super-rogue PSII complex in unprecedented detail. We aim to investigate whether the super-rogue complex is photochemically active and will test the hypothesis that the super-rogue PSII complex activates molecular oxygen into a reactive form that oxidises a Chl a molecule bound to a specific site in the super-rogue PSII complex. The project involves a team of scientists with skills in microbiology, molecular biology, biochemistry and spectroscopy. Our experimental approaches are diverse and involve working on biochemically pure protein complexes as well studying cyanobacterial mutants expressing Chl f. Ultimately our studies will provide important new knowledge on a new type of photosystem II complex that will underpin future work producing Chl f in crop plants.","isTelecoms":0}
{"text":"Title: A Biomimetic Flexible Soft Tissue Probe for Computer Assisted Minimally Invasive Intervention Abstract: The proposed research involves the design and proof of concept of a biomimetic soft tissue probe, inspired by the ovipositor of a wood-boring wasp, with an application to computer assisted brain biopsy. The probe will be able to be steered along curved paths within the body, but in contrast to the wood wasp's ovipositor, will displace the tissue (e.g. syringe needle) rather than removing it (e.g. drilling). In essence, the biomimetic probe will enable a hollow tube to be inserted deep into soft tissue accurately, without the need to exploit a natural orifice, for use in any number of minimally invasive procedures. This feasibility study will focus on three aspects: probe design, actuation, and control. It will also lay the foundation for the further development of an intelligent probe where the insertion process is guided interactively by pre-operative image data, allowing deep lesions of the brain and other regions of the human body to be accessed with greater accuracy and repeatability. Operative complications due to non-diagnosis and post-operative haemorrhaging could also be reduced through precise pre-operative planning of the probe's insertion and target points i.e. through the planning of a suitable trajectory that would minimise the distance between the two, whilst avoiding major veins, arteries, nerves and other vital structures. The planned procedure would be executed in the operating theatre by the flexible probe under computer assistance.The proposed project will comprise three main components:1) The design of a flexible probe capable of smooth three-dimensional motion through soft tissue.2) The design of an actuation mechanism and control strategy to drive the probe.3) The integration of the probe and the actuation mechanism into a fully functional system suitable for in vitro experimentation on synthetic soft tissue specimen.The probe design will essentially be composed of a two-part thin biopsy probe (1mm-3mm diameter, approximately 40cm in length), with the reciprocating motion of the two halves driving the head into the tissue without the need for any external force applied at the base; the drive unit, composed of three actuators, plus control software and hardware; a graphical interface for progress monitoring and user interaction; and, optionally, a tracking device (e.g. the magnetic tracker) to monitor the position of the probe head in real-time. This will require an investigation into suitable materials, surface coatings and surface topographies to minimise the impact that inserting the probe would have on the surrounding tissue. Further research will also be needed on the development of suitable probe actuation methods, in order to avoid any tissue damage, and control strategies, for automatic targeting and obstacle avoidance.","isTelecoms":0}
{"text":"Title: SmartAgriHubs - Connecting the dots to unleash the innovation potential for digital transformation of the European agri-food sector Abstract: SmartAgriHubs is dedicated to accelerate the digital transformation of the European agri-food sector. It will consolidate, activate and extend the current ecosystem by building a network of Digital Innovation Hubs (DIHs) that will boost the uptake of digital solutions by the farming sector. This will be achieved by integrating technology and business support in a local one-stop-shop approach involving all regions and all relevant players in Europe. The heart of the project is formed by 28 flagship innovation experiments demonstrating digital innovations in agriculture, facilitated by DIHs from 9 Regional Clusters including all European member states. Concurrently, SmartAgriHubs will improve the maturity of innovation services of DIHs so that digital innovations will be replicated across Europe and widely adopted by European farmers. A lean multi-actor approach focusing on user acceptability, stakeholder engagement and sustainable business models will boost technology and market readiness levels and bring user adoption to the next level. This will be enhanced by synergetic effects between SmartAgriHubs and RIS3, since SmartAgriHubs will work in lock step with European regions to maximize the return of European investments, including regional structural funds and private capital. Open Calls with a total budget of \u00b16 M\u20ac will expand the network and ensure that technological developments and emerging challenges of the agri-food sector are incorporated in the DIH service portfolio. SmartAgriHubs\u2019 inclusive structure and ambitious targets will bring the entire European ecosystem together, connecting the dots to ensure global leadership for Europe in the AgTech market. The consortium, led by Wageningen Research and other partners of previous key projects such as IoF2020, FIWARE, S3P Agri-Food and I4MS, will leverage the existing ecosystem and guarantee a maximum ROI for European taxpayers and a vital agri-food sector producing adequate and safe food for future generations.","isTelecoms":1}
{"text":"Title: Suffering and Sentiment on Romantic Military Art Abstract: Suffering and Sentiment in Romantic Military Art' takes as its focus the image of the dead and wounded soldier in British culture, from the Seven Years War to the close of the Crimean War. Following in the wake of pioneering work by Simon Bainbridge, John Bonehill, Mary Favret and Yuval Harari it presents the first detailed discussion of how suffering and sentiment on and off the battlefield was depicted in a range of visual and verbal media: from paintings and sketches to political prose and anti-war poetry, and from writings on culture and aesthetics to graphic satires and early photographs. The project will result in the publication of a book (Ashgate 2012), a one-day conference and a 'Late at Tate' event, both open to the public, to be held at Tate Britain in 2011.\\n \\nIn a significant departure from previous studies, the particular concern of my research is with the way in which images of death and wounding are used to qualify as well as consolidate ideas of individual and national unanimity. By taking account of the full range of media in this period, the study seeks to redress the notion that suffering was depicted solely as noble or heroic. Whilst classical portraiture and history painting undoubtedly conspired with official ideologies to deflect attention from the true costs of war, such portrayals must be set against works of art, literary as well as visual, which focus on the lot of the common soldier. In bringing this neglected figure to light, the book uncovers a history of changing attitudes to suffering, from mid eighteenth-century ambivalence, through late eighteenth- and early nineteenth-century concepts of moral sentiment, to mid-Victorian notions of sympathy. As such, 'Suffering and Sentiment' tells the story of how images of death and wounding both facilitated and queried a shift in the perception of war: from autocratic visions of noble sacrifice to democratic notions of endurance and common cause.\\n\\nFollowing an introductory discussion of eighteenth-century attitudes to the military and to the portrayal of war, the first chapter focuses on the depiction of the wounded soldier in Laurence Sterne's 'The Life and Opinions of Tristram Shandy, Gentleman' (1759-67). It pays particular attention to contemporary illustrations of the novel, which foreground the uneasy connections between military manners, conceptions of masculinity and the links between sexuality and injury. The following chapter discusses the work of the graphic artist Henry Bunbury, described by Walpole as 'a second Hogarth'. Bunbury's 'Affliction' (1783), a print depicting a dead soldier and his grieving wife and child, is examined in the context of English, American and Scottish responses to the wars against America and in terms of debates about charitable relief for the victims of war. In chapter three, attention turns to Joseph Wright's painting 'The Dead Soldier' (1789), a work presenting a provocative conflation of the military and domestic spheres. Drawing on previously unpublished correspondence by Wright and his circle, as well as on poems, prose writings and graphic satires, the chapter locates the painting at the centre of a complex network of liberal, radical and conservative anti-war sentiment. Chapter four pays close attention to artistic and literary responses to the war against revolutionary France. It considers how works by Joseph Wright, James Gillray, Robert Brown and William Hodges responded to a culture of 'military spectacle', offering melancholic uncertainty in place of sublime triumphalism. The final chapters turn to considerations of the changing status of the soldier's body: chapter five addresses the representation of military discipline in a range of prints, paintings and literary works, while chapter six focuses on the depiction of the dead and wounded soldier in medical discourse and imagery. The study's conclusion accounts for the emergence of new forms of sympathy in the literature and art of the Crimea.","isTelecoms":0}
{"text":"Title: Can the Plasmodium falciparum Nedd8 pathway provide new targets for malaria control? Abstract: Ubiquitin and Nedd8 are involved in fundamental cellular processes and are essential to all eukaryotes. As such, enzymes mediating their dynamic attachment and removal from substrates present attractive targets for therapeutic intervention for both chronic and communicable diseases. Despite being evolutionarily conserved, differences in how these pathways are controlled in higher and lower eukaryotes do exist and could potentially be exploited to generate pathogen-specific inhibitors. It is, therefore, necessary to understand the cell biological mechanisms behind how these pathways are regulated. We have evidence to support that removal of Nedd8 from target proteins in the malaria parasite, Plasmodium falciparum, is mediated by different enzymes than those of the human host. We now aim to characterize enzymes involved in Nedd8 attachment. We also aim to assess whether these enzymes are essential to P. falciparum survival and if they can be selectively disrupted in the parasite through peptide inhibitors. Overall, we hope to gain a better understanding of how the Nedd8 pathway has evolved across eukaryotes and identify patterns to predict its function in other parasites more widely.","isTelecoms":0}
{"text":"Title: Skeletal Dysplasia: establishing metabolic &amp; nutritional requirements to manage health risks Abstract: Some people are born with a condition that prevents their bones from growing in the usual way. The medical term for \nthis is skeletal dysplasia but it is often known as dwarfism. Most people notice that this results in short arms and legs \nbut are unaware of the many other health problems that can limit quality of life (e.g. breathing difficulties due to \nchanges in the skull, neck and back operations due to changes in the spine, joint pain where bones do not fit together \nwell and so extra difficulties moving around in a world designed for taller people). \nAll the above problems can be made worse if a person becomes overweight or obese. This is important because people \nwith skeletal dysplasia are more likely to gain weight than those who are average height. People with skeletal dysplasia \nare also then more likely to become ill with life-threatening diseases like type 2 diabetes and heart disease. Nobody \nknows why being extremely short would cause these problems. It is likely that metabolic rate might explain the links \nbetween body fat levels and health markers - but no scientific research has ever made these measurements in this \nunique group of people. \nThe reason there is no research in this area is that scientists with the necessary skills have not had access to a large \ngroup of people with skeletal dysplasia. Our research team has linked with several major charities to do just that, so \nwe can measure metabolic rate and the metabolic response to a meal very accurately from a large number of people. \nWe will also then use cutting-edge wearable technology to monitor diet and physical activity levels once people return \nto their normal lifestyles, so we can understand completely how much energy they take in and use on a daily basis. \nOne benefit of these measurements is that they will reveal the range of body fat that is metabolically healthy for a \nperson with skeletal dysplasia. This is important because the usual ways to do this by simply checking the healthy \nrange for body weight or body mass index (i.e. the right weight for your height) does not work well unless all parts of \nthe body are the usual size and shape. Individuals with skeletal dysplasia therefore currently have no way to know \nwhether they should lose weight and, if so, what would be an appropriate diet and physical activity for them.","isTelecoms":0}
{"text":"Title: Welsh Election Survey 2019 Abstract: The proposed research seeks to extend the 2016 Welsh Election Study (WES) and, in so doing, provide the first-ever study in Wales where substantial individual-level data on voting behaviour and political attitudes for elections to different levels of government is available. This would add crucial information that would help substantially in fulfilling one of the major research goals of WES: understanding why vote choices can differ between different electoral arenas. This extension of WES would also offer the only opportunity to gain detailed insight into the potential realignment in Welsh politics that the 2019 election could deliver.\n\nThe British Election Study (BES) cannot be expected to explore in detail this potential historic re-alignment in Welsh politics; they have a wider remit to explore the election across Britain, which they are having to fulfil at very short notice. It will not include sufficient Welsh-specific questions to explore the historic shifts occurring in Welsh politics.\n\nThe research would comprise an online survey of voting age adults in Wales (with a sample of approximately 2000; fieldwork to be conducted by YouGov). With these data the project aims:\n1. To make possible a detailed and focused account of voting behaviour in Wales - one of the key battlegrounds in the 2019 General Election; \n2. To understand how Welsh voters interact with UK-level politics after two decades of devolution;\n3. To add to the substantial time-series of questions collected in Wales as part of the Welsh Election Study.","isTelecoms":0}
{"text":"Title: Visualising neuronal activity in cerebellar Purkinje cells Abstract: The term synapse refers to the specialised structures that allow excitable cells within the central nervous system to communicate with one another. The properties of synapses differ between cells and between parts of the brain and they can adapt over short or longer terms to modulate the strength and pattern of information transmission. Longer term changes in the strength of transmission are thought to provide a storage mechanism for learning and the process of learning may, in turn, help to sculpt patterns of information flow between networks of cells and between different structures in the brain. Understanding how synapses work, and how they can be modified, is fundamental to our understanding how the brain works and this, in turn, is an essential starting point for repairing brain function when it is damaged through injury or disease. In this proposal, we aim to generate strains of mice that have been genetically modified to express proteins that are fluorescent. These fluorescent proteins can be visualised microscopically and they alter their properties under different pH environments. By attaching these artificial proteins to natural protein structures that are involved in cell signalling and plasticity, we intend to develop methods that allow the real time visualisation of aspects of synaptic transmission, plasticity and communication in living brain cells. In the cerebellum, part of the brain necessary for the execution of skilled movement, information is transmitted from granule cells to Purkinje cells. Purkinje cells provide the sole output from this part of the brain and they are largely responsible for processing the information that enters the cerebellum. Activity within Purkinje cells triggers substantial increases in intracellular calcium, a chemical essential for cell signalling and plasticity. Calcium increases are accompanied by an acidification of the cell. By incorporating a fluorescent protein based pH sensor selectively into Purkinje cells, we aim to generate mice in which the activity of Purkinje cells can be directly visualised. We will then use brain slices prepared from these mice to evaluate how different patterns of neuronal input to the cerebellum are processed and passed on within this model network. Communication at a synapse requires the release of a chemical transmitter that diffuses across the synaptic space between the two cells and acts on a receptor present in the post-synaptic membrane to produce a response. Long-term changes in the strength of signalling between cells are thought to arise, in many cases, by either an increase or a decrease in the number of receptors present in the post-synaptic membrane. The movement of a receptor from the synaptic cleft to the inside of the cell (down-regulation) or vice verse (up-regulation), is accompanied by a sharp change in pH from the alkaline extracellular surface to the acidic inside of a transport vesicle. By tagging specific receptors expressed by Purkinje cells with a fluorescent protein pH sensor, we aim to develop mice in which we can directly visualise the movement of receptors to and from the membrane under conditions thought to produce learning. Brain slices derived from these mice will be used to examine the input conditions that produce changes in the number of receptors at a synapse and hence the strength of synaptic transmission within this part of the central nervous system. These mice will provide valuable tools to the research community and if successful, provide proof of concept for the development of other probes with uses in other parts of the brain.","isTelecoms":0}
{"text":"Title: Eco-evolutionary virus-host relationships in mammals: a phylogenomic study of endogenous viral elements Abstract: Retroviruses have been infecting mammals for at least 100 million years, leaving descendants in host genomes known as endogenous retroviruses (ERVs). Additionally, although most endogenous viral elements (EVEs) found in host genomes are inactive 'viral fossils', an open reading frame is occasionally maintained in these sequences. This has lead to examples, such as the placentation gene syncitin, in which EVEs become co-opted by the host as virus-derived, functional genes (often with immune related functions). The increase in genomic and transcriptomic data for mammalian species allows for broader study of ERV features across this well-studied clade. This project will focus in particular on bats (order Chiroptera) which are the natural hosts of multiple zoonotic viruses of public health concern, including Ebola, Nipah, Hendra and SARS.\n\nThe order Chiroptera (bats), comprises &gt;1200 species and encompasses some of the most extensive ecological and phenotypic radiation known among mammals, having adapted to a diverse multitude of ecological niches. This unique evolutionary history, combined with their ecological role as carriers of zoonotic viruses provides an ideal system in which to study the evolutionary relationship between mammals and their viruses through comparative genomic\/transcriptomic approaches.\n\nThe project aims to create a computational pipeline for identifying endogenous viral elements (EVEs) in mammalian genomes\/transcriptomes and to apply this to genome-scale sequence data obtained from tens of species of bats. Characterisation of EVEs across multiple species will allow a comparative analyses (e.g. phylogenomic selection analysis) to identify eco-evolutionary patterns in the relationship between viral and host lineages. Tissue specific transcriptome data will also be employed during the project in order to identify potentially functional EVEs by looking for EVE containing transcripts upregulated in immune tissues. These comparative analyses will hope to provide insight on, for example: the relative importance of co-evolution between host and virus compared with host ecology in determining the virus pathogen landscape; the roles of co-opted viral genes in host biology; and eco-evolutionary patterns of these co-opted viral genes.","isTelecoms":0}
{"text":"Title: Modulatory Capacity: Biomarkers for pain sensitization and response to psychological treatment for pain Abstract: A recent UK study demonstrated that making treatment choices based on individual differences in sensory and psychological aspects of pain resulted in improved patient outcomes and lower medical costs. The proposed research also aims to direct patients to the best treatments, but aims for bigger improvements by precise measurement of mechanisms that make some individuals prone to chronic pain. Based on previous research, I hypothesize that individual differences in how the brain modulates information about injury from the body (&quot;modulatory capacity&quot;) might tell us who is at risk of developing chronic pain and how we might best treat these high-risk individuals. A reliable measure of these individual differences could help clinicians steer patients towards the best treatments. This research aims to develop a modulatory capacity assessment battery (MCAB) using measures of negative emotion, pain responses and patterns of brain activation.\n\nPrevious studies have shown that measures of central pain modulation can predict who will develop chronic pain after surgery. These studies have used single measures and their rates of prediction are not optimized for clinical use. This project will collect a wide range of measures of brain function, pain responses and unhelpful attitudes about pain. This carefully chosen set of measures can will help us understand why some individuals are more susceptible to chronic pain and help us direct them towards treatments that are more likely to help them.\n\nIn order to test the utility of the MCAB in predicting who becomes sensitized to pain, we have developed an experimental model where participants are exposed to a series of painful stimuli over eight separate days. We will use the MCAB to identify individuals whose brains enhance pain responses over time. This experiment will help us understand the mechanisms that make some people more likely to develop persistent pain. Our eventual goal is to use this measure in clinical settings, to identify individuals at risk of developing chronic pain after surgery. This study will provide an important first step towards a future grant to examine the use of the MCAB in a clinical setting.\n\nThe ability to identify individuals at risk of developing chronic pain provides little advantage if we are unable to provide treatments. A low-risk and low-cost option for early intervention for individuals at risk of developing chronic pain is cognitive behavioural therapy (CBT). CBT has been shown to reduce suffering and disability related to pain. In the same experiment mentioned above, we showed that it reduced central enhancement of the pain response. We will use this same experiment to find out whether individuals identified by the MCAB as &quot;high risk&quot; (those showing increased sensitisation in response to prolonged pain) will be responsive to CBT. One potential use of these findings would be to identify individuals that might benefit from early intervention with CBT immediately after a painful surgery.","isTelecoms":1}
{"text":"Title: Anti-Biofilm Materials Using Multifunctional MOFs Abstract: Biofilm infections are a major source of nosocomial (hospital-acquired) infections, accounting for ~65% of all those treated in the Western world (according to an estimate in 1999 ). Almost a defining feature of biofilms is their increased resistance to both antimicrobial drugs and to the host animal's own defences. This makes them particularly difficult targets, and even strains of microbe that are effectively treated when in their non-biofilm (planktonic) form are often untreatable when formed in biofilms. There is therefore a great incentive to develop new methods of combating such infections. In this project we will look to develop the commercial and technical aspects of a technology that we originally developed during an EPSRC-funded research projects (GR\/T09705\/01 Designing Porous Metal-Organic Frameworks to Store and Deliver Large Amounts of Nitric Oxide). We have proven that nitric oxide delivered from metal organic frameworks, a type of highly porous inorganic organic hybrid material, is extremely potent at killing bacteria, even when the bacteria have formed biofilm communities. We have also shown that, because of the very highly porous nature of the metal organic frameworks, we can load drugs or other small molecules simultaneously with the NO. In this project we aim to develop the commercial potential of these materials with a goal of developing a product for the anti-biofilm market. In particular our previous results have shown that we can formulate these materials into polymers suitable for coating medical devices. Over the course of this project we will coat commercial devices with MOF-containing polymers and prove their anti-biofilm activity under industry standard conditions. We will also develop a commercialisation for this technology in the anti-biofilm area as well as improving the strength of our intellectual property and identifying important potential commercial partners.","isTelecoms":1}
{"text":"Title: Towards more Effective Working Memory Training for Older Adults Abstract: As working memory decline affects most people during aging, effective training to maintain cognitive functioning is beneficial for both the individual and the health system. Due to their motivational appeal and customizable nature, serious games have the potential to achieve meaningful changes in several areas of functioning. Yet, existing gamified training mostly fails to provide significant improvements. This might be due to the limited use of effective gamification elements, as well as the uninformed selection of a reliable adaptivity component, which is rarely based on current cognitive theories. The aim of the proposed project is it therefore to develop and evaluate a working memory game for older adults, with an improved adaptivity mechanism and adequate gamification elements. The successful completion of this project will provide important insights into the design of gamified training as well as inform cognitive theories and contribute to the well-being of many individuals.","isTelecoms":1}
{"text":"Title: University of Leeds AFM Facility Abstract: This funding provides a dedicated facility manager for the atomic force microscope (AFM) facility situated within the School of Physics and Astronomy at the University of Leeds. The two year grant will enable us to recruit a technical specialist in the applications of AFM after which this experimental officer post will be sustainably funded through consolidation of existing research projects and pump priming of new collaborations. The high quality science that this facility generates across a wide range of different research fields will allow us to recover the true costs of operating the facility via a combination of grant funding and industrial collaboration. The role of the facility manager will be to oversee the efficient day-to-day running of the suite of seven state-of-the-art AFMs.\n\nAFM is a versatile high resolution surface scanning microscopy that can produce topographical and mechanical maps for a wide range of hard and soft materials. It uses a sharp probe, nanometres in radius, to scan across surfaces to produce images with resolution down to the atomic scale. The probe is mounted on a force sensing flexible cantilever spring that can measure the mechanics of materials and molecules to sub-piconewton accuracy. AFM can operate in vacuum, liquid and air environments making it highly suited as an analytical technique for studying a wide range of materials under different conditions. The facility contains instruments that are optimised for high resolution imaging, sensitive and accurate force measurement, high throughput and high speed imaging and a new combined instrument platform integrating AFM with advanced optical microscopy techniques.\n\nThe versatility of AFM means it is a critical instrument to enable high quality nanoscience, nanotechnology, soft condensed matter, advanced and functional materials research. Examples of collaborative interdisciplinary research carried out in the facility include: magnetic nanostructures, magnetic spin-ice, skyrmions, crystallisation, synthetic polymers, biomembranes, food nanomechanics, single biomolecule mechanics, therapeutic microbubbles, DNA origami nanostructures, nanoparticles, anti-cancer peptides and biomaterials. These topics relate to research and development of applications within: data storage, data integrity, green energy generation, energy storage, oil recovery, drug delivery, drug formulation, catalysis, biomineralization, anti-cancer agents, hydrogels, tissue engineering, food science and textile development.\nWe expect the new post to augment impact of UK science within Physics, Chemistry, Mechanical Engineering, Chemical Engineering, Electronic Engineering, Biomedical Engineering, Biomedicine, Biological Sciences, Earth and Environment, Food Sciences and Dentistry.\nCurrent research from the facility falls within the EPSRC themes of Physical Science, Engineering, Manufacturing the Future and Healthcare Technologies. Specific research areas include: Biophysics and soft matter, biomaterials and tissue engineering, magnetism and magnetic materials, spintronics, polymer materials, particle technology, surface science and synthetic biology. The multi-disciplinary research relates to Grand Challenges in: Physics of Life, Physics far from Equilibrium, Nanoscale design of functional materials and Healthcare technologies - developing future therapies. The activities that the facility supports align with the EPSRC Balancing Capabilities strategy since it covers such abroad range of research within the Physical Sciences and Engineering, producing high impact research of societal importance.\n\nTwenty-first century society will be built on understanding and controlling material down to the nanometre scale. AFM is a key tool for characterising and manipulating materials at the nanoscale, be they natural, bioinspired or synthesised. The Leeds AFM facility can make a significant impact across a wide range of important scientific challenges.","isTelecoms":1}
{"text":"Title: A Hybrid PV-Battery Unit Optimised for LV Grids Using GaN Transistors Abstract: Under their &quot;Gone Green&quot; deployment scenario, National Grid forecast that energy generated from photovoltaics (PV) in the UK is expected to rise from 2 GW to 15 GW over the next 20 years. This is being driven by the UK's legal obligations\naround the installation of renewables and cutting greenhouse gases, the rising cost of energy and concerns around the security of supply - the so-called energy &quot;trilemma&quot;. Power Electronic converters are a key enabling technology for PV and a range of other low-carbon technologies (LCTs). However the use of LCTs has resulted in problems for the Distribution Network Operators (DNOs) in terms of supply voltage distortion and over-voltages, which threatens to limit or delay the uptake of these technologies. The aim of this project is to mitigate this threat by exploiting the benefits of new Gallium\nNitride (GaN) power module, which will initially be developed for use in a hybrid PV-battery unit for residential applications, but will have much broader application in LV grid-connected equipment (e.g. electric vehicle, charging &amp; micro-CHP). It is anticipated that the deployment of these units would lead to an increase in the maximum allowable installed capacity on the network and will be much smaller, lighter and have lower cost than existing Silicon based units.","isTelecoms":1}
{"text":"Title: Syphilis self-testing to expand test uptake among men who have sex with men (SST) Abstract: Across a wide range of resource-constrained settings, syphilis infection causes substantial morbidity. Syphilis increases the risk of acquiring and transmitting HIV infection, but is frequently asymptomatic. Many men who have sex with men (MSM) with high risk sexual behaviours are unable to receive syphilis testing because of centralized testing sites and stigma associated with testing sites. \n\nOne way to increase syphilis test uptake among MSM is syphilis self-testing. Syphilis self-testing has a person use a test kit and interpret their own test result. HIV self-testing programs have already introduced the concept of self-testing to MSM and created an infrastructure to distribute and measure uptake of self-testing. Sensitive and specific syphilis self-test kits are available and can be used to detect syphilis infection, similar to treponemal serologies commonly used in clinical practice. Syphilis self-testing could decentralize testing and decrease stigma associated with testing. Our nationwide study found that 174\/699 (24.9%) of a Chinese MSM sample already use syphilis self-test kits. We have organized five randomized controlled trials focused on increasing HIV test uptake among MSM.\n\nTo date, there have been no studies evaluating the efficacy of MSM syphilis self-testing compared to facility-based testing. Our long-term goal is to organize a large two-country study to evaluate if self-testing can improve syphilis diagnosis and treatment. As a first step, we will finalise and pilot an intervention to promote syphilis self-testing and linkage to clinical services. This will establish a strong foundation for a randomized controlled trial if the pilot is deemed effective.\n\nThe study will take place in Guangzhou (China) and Harare (Zimbabwe), two settings with a high burden of syphilis infection, strong linkages to MSM community organizations and health services, and ongoing HIV self-testing programs. Many research tools and methods developed to measure HIV self-testing can be directly applied in this study. We expect that our China-Africa project would facilitate adoption of the intervention in both other Chinese provinces as well as other less-developed African countries. This project will synergize with and benefit from ongoing China-Africa STI collaboration.","isTelecoms":0}
{"text":"Title: Regulation of plateau potentials by dendritically targeted inhibitory synaptic transmission. Abstract: Experience-dependent memory is the foundation on which we make all our decisions. Reliable memory encoding is therefore essential for good decision making and our mental health. But what determines the durability of memories and how are they protected from interference by subsequent events? Our brains are not like computers which reliably transcribe all information faithfully and equally - we have a much greater capacity for flexibility. But how do we balance the needs for flexibility and adaptation with reliability and stability?\n\nMemory representations in the brain are thought to be encoded in the strength of connections (synapses) between neurons creating assemblies where each neuron represents a distinct aspect of the memory. An excellent example of this are place cells of the hippocampus which each represent one specific location but can group together by strengthening their synaptic connections into assemblies that provide a representation or memory of the whole environment. When we experience a new environment the place cell assemblies must reorganise to form a new representation where each place cell may now &quot;re-map&quot; to a different location. The hippocampus is therefore an excellent system to study the flexibility and stability of memory representations.\n\nThe biological substrate for memory formation is therefore modifications in the strength of synaptic connections. This plasticity enables the reorganisation of cell assemblies. Synaptic plasticity is triggered by the influx of calcium ions across the synaptic membrane through proteins called NMDA receptors. If multiple excitatory synaptic inputs are activated simultaneous, a plateau potential is generated which is a long-lasting activation of NMDA receptors and calcium influx. These plateau potentials are known to be important in triggering synaptic plasticity to encode new aspects of our environment into place cells. \n\nWe propose that plateau potentials are controlled by inhibition provided by a specialised subtype of inhibitory neuron termed an OLM interneuron. These inhibitory cells can counteract excitatory synaptic input and are therefore perfectly positioned to regulate plateau potentials and the resulting synaptic plasticity and memory formation. Furthermore, we propose that OLM adaptation is important for creating stable memory representations.\n\nIn this BBSRC project, we will test the hypothesis that OLM interneurons can control when new place cells can incorporate new information by regulating plateau potentials and synaptic plasticity. To do this we will fill neurons with dyes that fluoresce when calcium ions are present and measure whether a synapse has strengthened or weakened by recording electrical activity from the neurons. We will do this while activating OLM interneurons to test how these cells regulate neuronal calcium and synapse strength. We will then record place cells in the hippocampus and investigate if OLM inputs can keep a place cell stable and prevent new information from destabilising previously encoded representations of the world. \n\nThis work is important because it will lead to a wealth of new information about place cells and synaptic plasticity. Dysfunctional synaptic plasticity is thought to underlie the altered neuronal activity in several brain diseases, such as Alzheimer's disease and schizophrenia. Therefore, the mechanisms that we will study in this research will add to our knowledge about these debilitating diseases and may contribute to developing novel therapies.","isTelecoms":0}
{"text":"Title: Urban-Air Port | &quot;Air-One&quot; [Rapidly Deployable Vertiport For Drone-Delivery, Air-Taxi, Disaster Management] Abstract: Urban-Air Port Ltd is designing &amp; developing the 'worlds smallest airport', an infrastructure solution to support future Electric Vertical Take off and Landing \\[EVTOL\\] aircraft. This innovative programme is called &quot;Air-One&quot;.\n\nThis project employs sophisticated design, Intelligent-Autonomous-Systems technology, sustainable renewable energy input &amp; fabrication processes to create rapidly deployable, small foot-print infrastructure with minimal impact on the environment. Creating a new business model for an emerging era of personal &amp; logistics air-mobility.\n\nThis pop-up 'urban-airport' innovation is particularly relevant post-Covid 19, offering flexible, autonomous &amp; safer transportation solutions. For Coventry City of Culture 2021, Air-One will demonstrate a vision of future Urban Air Mobility \\[UAM\\], including its capacity to support Disaster Emergency Management &amp; Security \\[DEMS\\] in areas exposed to climate change, pandemics or with diminishing resources, a just-in-time, safe &amp; resilient rescue hub.\n\nAir-One, as a global first will accelerate public trust &amp; readiness for this new technology by promoting an exciting, green alternative by demonstrating;\n\n1\\. Technical proficiency &amp; operational feasibilit_y_ of dynamic EVTOL logistics, air_-_taxi-services &amp; DEMS scenarios;\n\n2\\. The portability, flexibility, sustainability, capacity capabilities &amp; decarbonisation contributions of Air-One;\n\n3\\. A holistic, ultra compact, vehicle agnostic transport infrastructure solution with modular areas covering passenger\/cargo terminal &amp; DEMS needs, with in built EVTOL maintenance, recharging command &amp; control requirements - an all in one solution - 'Air One.'\n\nAir-One is part of the Innovate UK Future Flight Challenge, led by leading British architects, designers &amp; engineers in Partnership with; Coventry City Council, Malloy Aeronautics, National Transport Design Centre, Coventry University, Tritium, Hyundai Air Mobility &amp; Ove Arup presenting a giant step towards greener mobility enabled by game changing new &amp; much needed infrastructure.\n\nThe programme has already attracted potential customers from abroad highlighting Air-Ones credibility &amp; UKs UAM export potential &amp; has received investment from globally recognised Partners, Hyundai Motor-Group through their Urban Air Mobility business led by Dr Jaiwon Shin former NASA as Head of the Aeronautics Research Mission Directorate for over a decade.\n\nAir-One gives hope to the UK's aviation &amp; manufacturing sectors post COVID-19 &amp; addresses key targets of the UK's Industrial Strategy boosting the economy with new jobs, empowering the UK's ambitious environmental pledges &amp; advancing UK STEM capabilities.\n\n&quot;As part of the West Midlands Combined Authority, Coventry City Council is 100% supportive of this innovative &amp; ground-breaking Air-One programme, demonstrating how revolutionary new, greener modes of travel will increase mobility, reduce road congestion, improve connectivity &amp; increase UK manufacturing opportunities.&quot; Coventry City Council, Transport Innovation Manager, Sunil Budhdeo.\n\n&quot;Air-One could be the foundation of a UK UAM &quot;Centre of Excellence&quot; where industry can converge to collaboratively test ideas, technologies, new vehicles, operational concepts on an on-going basis presenting immense value for money for the UK taxpayer, improving connectivity, boosting productivity - ultimately transforming cities &amp; helping to build back better.&quot;\n\nUrban-Air Port Ltd, CEO &amp; Founder, Ricky Sandhu.","isTelecoms":1}
{"text":"Title: CHILDREN'S PLAYGROUND GAMES AND SONGS IN THE NEW MEDIA AGE Abstract: This project will update, analyse and re-present three important collections of children's playground songs and rhymes: the Opie Collection of Children's Games and Songs, and selections from collections at the National Centre for English Cultural Tradition (NATCECT) and the Leeds Archive of Vernacular Culture (LAVC). The project aims to preserve this important aspect of our national culture; but also to explore how it continues to be a part of the lives of children living in the age of computer games and the internet. What does this oral tradition borrow from the media; and how might it connect with the entertainment and information technologies of the age of new media?\\n\\nThe project will work in three ways. Firstly, it will digitise material from the collections as a new digital archive at the British Library, and design an interactive website available to educators, researchers, children, parents, and the wider public. The website will break new ground in the exhibition of children's culture, and will involve children from our partner primary schools in the design and duration of the website. The transformation of the Opie archive has the full support of Iona Opie.\\n\\nSecondly, it will carry out a two-year study of playground culture in two primary schools, one in London, one in Sheffield. This will explore how these games, songs and rhymes are used by children today as part of a living tradition; and, again, how they relate to children's experiences of popular media such as comics, TV, film, and computer games. It will also conduct an analysis of selected material, both from the playground studies and from the archive, focusing on how this oral culture relates to media cultures, which has never been systematically done before.\\n\\nThirdly, it will consider how traditional games like this are making their way into forms of new media. It will explore this by developing a suite of games for the Nintendo Wii. This will involve an innovative adaptation of the Wii's technology, to capture playground games and make them playable as computer games, without losing their traditional character. This innovation, supported by Nintendo UK, who are partners in the project, will be developed by researchers at the London Knowledge Lab, informed by ideas from panels of children from the two partner primary schools in the project.\\n\\nThe project also draws on the expertise of the British Library, NATCECT and LAVC. It is directed by researchers expert in children's literacies and media cultures, and in game theory and game design, at the Centre for the Study of Children, Youth and Media at the Institute of Education, University of London; the Centre for the Study of Childhood and Youth at the University of Sheffield; and the School of Social Sciences, Media and Cultural Studies at the University of East London. The project is based in the London Knowledge Lab, a research institution shared by the Institute of Education and Birkbeck College.\\n\\nThe project will culminate in a series of high-profile events: a children's conference in Sheffield, a conference for researchers, educators and policy-makers at the British Library, a demonstration of the Wii prototype at the BETT show, and a book presenting the research.\\n\\nFinally, the project will be supported by an authoritative expert advisory panel of academics, game industry representatives and specialists in children's oral culture. We are delighted that the Children's Laureate, Michael Rosen, has agreed to be a member of the panel.","isTelecoms":0}
{"text":"Title: Open source robotic surgery Abstract: The project aims at improving the level of autonomy in robotic surgery and is carried on with the DaVinci Research Kit. Intuitive Surgical, worldwide market leader in robotic surgery, has kindly donated this kit to the University of Leeds and will constantly monitor our research outcomes. Research topic include design and integration of new robotic end-effectors, automation of robotic tasks in surgery, improvement of the human machine interface design, surgical skills analysis and training, and platform validation in collaboration with our clinical partners. Other activities include pre-clinical assessment of developed systems in animal and\/or cadaveric models in collaboration with our clinical partners, analyse and summarize research results into high-quality peer-reviewed scientific publications, travel for research meetings with our collaborators and for presenting research results at conferences worldwide, participating in outreach activities to engage the broader community into science and engineering.","isTelecoms":0}
{"text":"Title: For Love or Money? Collaboration between Amateur and Professional Theatre Abstract: Professional theatre-makers often view their amateur counterparts with suspicion or even derision. Frequently assumed to be artistically conservative, the creative output of amateur dramatics companies is often stereotyped, with the consequence that there appears to be very little formal contact between the two artistic communities. In practice, however, the twenty-first century is redefining what is meant by amateur participation and the boundaries between amateur and professional theatre are rather more blurred than is popularly believed. This research both responds to the contemporary 'amateur turn' in the arts, and recognises that amateur theatre is a form of cultural participation that has sustained the interest of many people over decades. It will test the assumption there is little contact between professional and amateur theatre-makers and will analyse why, how and when amateur dramatic companies and professional theatre-makers work together. \n\nFor Love or Money? Collaboration between Amateur and Professional Theatre analyses three contexts in which different sectors work together. With the Royal Shakespeare Company as a leading partner, the research will investigate the RSC's Open Stages Programme, the first large-scale project that seeks to establish formal artistic partnerships between a major professional theatre company and amateur theatres. Amateur companies who are selected for the Open Stages Programme are often highly organised, bringing a professional attitude to their productions and producing work that RSC professionals identify as high quality. We will analyse the impact of the RSC's intervention on the artistic practices and creative processes of their amateur theatre partners and, reciprocally, we will examine how engagement with amateurs is influencing policy and practice at the RSC. This raises questions about how artistic quality and cultural value are understood within these two artistic communities, and considers how this form of professional-amateur collaboration might be developed in the future. \n\nSecond, the research will investigate the work of professional theatre-makers employed by amateur theatre companies. Amateur theatre companies often hire professional musicians, musical directors and choreographers to work with them on their productions. Some playwrights are sustained by selling rights for amateur productions and professionalised adjudicators' accept lucrative bookings to judge competitive festivals. The research will analyse how the work of trained and professional theatre-makers shapes and defines the repertoire, influences production values and impacts on the culture of amateur theatre in national festivals and local productions. \n\nThird, we will investigate the social and economic impact of amateur theatre on professional theatres. This strand of the research will investigate how audiences for amateur theatre contribute to the economic viability of regional theatres, many of whom have struggled to survive in an area of low funding. It will analyse what, if anything, can be learnt from the successful operations of building-based amateur theatres. The research will investigate the opportunities, contradictions, tensions and mutual dependency between the two sectors, and how this speaks to wider (and neoliberal) political agendas. \n\nThese three research contexts will illuminate distinctions between professional and amateur knowledge, investigating where and how boundaries between amateurism and professionalism are drawn. This research raises pressing questions about artistic quality, cultural value and the contribution amateurs make to the cultural economies of different of forms of professional theatre, whether it is commercial, subsidised, or the work of freelance theatre-makers. The study has far-reaching implications, with the potential to shape cultural policy and creative practice in ways that recognise the opportunities that cross-sector collaboration invites.","isTelecoms":0}
{"text":"Title: IGNITE - High performance generation channel Integration and Testing Abstract: Conventional aircraft currently use three-stage synchronous generators to provide 115Vrms 400Hz AC power to downstream electrical loads. The recent introduction of variable frequency generators has permitted simplification of the mechanical drive train, offering greater power capability than traditional constant frequency generator technologies. The IGNITE project will take a step further and move away from AC power to the DC power to achieve further efficiency improvement and mass reduction. \n\nThe IGNITE Consortium will bring together their world-leading expertise in the field of machines, electrical drive integration and testing including test rig design, supervisory control and data acquisition (SCADA), test rig integration of high-performance electrical generation systems, test rig commissioning, test planning and test management, to develop a high-performance test rig for high-voltage direct current (HVDC) power generation channel testing and demonstration. IGNITE will also integrate the power electronic conversion and quick disconnect system developed in two other topics with the IGNITE test bench and SCADA system.\n\nThe high performance HVDC power generation channel to be developed by IGNITE will embrace multiple advancements including:\n\u2022 Robust and reliable test equipment for HVDC power generation systems \n\u2022 High-efficiency, high-speed permanent magnet machine drives \n\u2022 Advanced test rig combining environmental effects and degradation of the system under test\n\u2022 Advanced control for high-speed electrical generators\n\u2022 Fast data acquisition system which is capable of capturing rapid change system variables and parameters\nThe integrated HVDC power generation system developed within IGNITE will demonstrate an innovative high-efficiency and robust power generation technology for future LPA applications. It will also open doors for power sharing between different HVDC power sources to further improve the efficiency of aircraft under different operating conditions.","isTelecoms":1}
{"text":"Title: Applying -omics methods to map the circadian matrisome Abstract: Circadian rhythm regulates and synchronises biological processes through a daily cycle. Molecular clocks in cells throughout the human body are entrained to a 'master clock' located in the hypothalamus, and cells in almost all tissues have been found to contain rhythmic genes. Circadian rhythm ensures the correct sequence and regulation of a broad range of cellular and organ functions. Consequently, disruption to the cycle - for example, in shift-workers - has been linked to risk in many diseases, including hypertension, inflammatory, metabolic and neurological disorders. \n \nRecent work, for example in mouse liver, has shown circadian rhythm in transcriptional regulation to be propagated through to protein levels and post-translational modifications of proteins. Remarkably, a study by the project management team has demonstrated that the secretory system for extracellular matrix proteins - the proteins that provide persistent, life-long structure to the body - also falls under circadian regulation in tendon tissue. The purpose of this project is to discover the extent to which circadian oscillations occur in extracellular matrix proteins throughout the body (the 'matrisome'), and how these and other rhythmic processes can contribute to the healthy maintenance of tissues subjected to daily activity. \n \nAn initial task will be to mine existing transcriptional datasets to identify characteristic circadian regulation of secretory-pathway and matrix proteins, informed by our earlier work on tendon, cartilage and intervertebral disc. Candidate tissues, such as skin, will be isolated from mice at defined time-points and subjected to proteomic analysis. There will be opportunity here to learn and develop methods for sample preparation, data processing and interpretation. Unbiased -omics approaches will inform on multiple pathways, including secretion, autophagy, stress response and regulation of cell structure. This will enable us to build an integrated, holistic picture of the fundamental intracellular signalling and secretion pathways that maintain extracellular matrix homeostasis. The importance of key pathways will be tested through manipulation of cell and mouse model systems. Finally, we would like the project to establish an internet-based database of the &quot;circadian matrisome&quot;, thus providing benefit to the broader matrix and chronobiology communities. \n \nThis is a 'Underpinning Biosciences' project that will encompass aspects of chronobiology, cell biology, matrix biology, bioinformatics and biophysics. The multidisciplinary nature of the work, and its close integration of quantitative and -omics methodologies, make it an ideal fit to the BBSRC's ENWW remit. The work will be performed in partnership with SCIEX (Cheshire, UK) - a leading developer of instruments for mass spectrometry. This collaboration will give access to training, technical expertise and the latest proteomics technology.","isTelecoms":0}
{"text":"Title: Quantification of vascular and neuronal pathology in dementia using PET and MRI Abstract: The increasing occurrence of dementia within our ageing population is one of the pressing challenges facing society. Successful management of patients with dementia is significantly aided by early and accurate diagnosis. Imaging methods such as magnetic resonance imaging (MRI) and positron emission tomography (PET) are already used in the diagnostic process; we believe that there is substantial scope for both methods to be improved to provide more precise and sensitive diagnostic information, and to do so in a way that is easily tolerated by patients. If we are correct in this belief, then the methods we develop within this project will not only help in early diagnosis, but may also help in the discovery of new therapies and in the longer term with helping doctors select the best therapeutic strategies for patients with different forms of dementia.\n\nImaging methods such as MRI and PET can tell us a lot more about brains than simply providing a picture of brain shape and size. We will focus on improving MRI and PET to be sensitive to two important microscopic aspects of dementia. Firstly, we will develop and validate new methods for measuring the loss of brain cells due to the condition; this loss is the cause of many of the symptoms of dementia, such as memory problems, and we hope to be able to detect these changes earlier than has previously been possible. Secondly we will develop and validate new methods for measuring changes in blood delivery to the brain and how this can affect oxygen delivery. These changes are thought to be part of one of the important processes involved in causing cell death and tissue loss, and are likely to be particularly relevant to vascular dementia.\n\nWe will also spend considerable time checking that the measurements we develop are both accurate and practical for application in dementia patients in the future. We will optimise the way in which the scanning processes take place so that the time required for patients to lie in the scanner(s) is minimised. This will be important for future adoption of these methods in the clinical environment.","isTelecoms":0}
{"text":"Title: EconCell - Aligned one-dimensional nanostructure electrodes from Electrically Conductive pOrous coordiNation polymer for proton exChange mEmbrane fueL celLs Abstract: To address environmental hazardous impact of fossil fuel energy technologies and the high dependency on them, clean energy systems have been developed for future energy fulfilment. Among them, the proton exchange membrane fuel cell (PEMFC) is considered as a highly potential electrochemical energy conversion technology because of its low operation temperature, quick start-up and shutdown, high energy efficiency and power flexibility. However, the sluggish cathodic oxygen reduction reaction (ORR) undermines the overall performance. Up to now, the commonly used catalysts are still carbon supported Pt-based nanoparticles, with which the high cost of Pt undesirably increases the overall cost of the system. In EconCell, we will develop a new generation of low-cost, active site enriched and durable PEMFC electrodes from three-dimensional (3D) nanostructures of non-platinum group metal (non-PGM) electrocatalysts. It consists of protic hydrophobic ionic liquid (IL) encapsulated nanowire arrays (NWAs) of electronically conductive porous coordination polymer (E-PCP) selectively assembled on N-doped aligned carbon nanotubes (N-CNTs). The ambitious aim will be achieved with the complementary skills of Experienced Researcher (E-PCPs and nanowires) and supervisors (fuel cells and ionic liquids), based on the unique porosity, conductivity and stability of E-PCPs, the excellent catalytic activities of nitrogen-containing (N) transition metal complexes (MCs), and oxyphilicity and hydrophobicity of ILs. EconCell will extend significantly the existing knowledge of coordinated N active sites, transition metals, ILs and 1D nanostructure electrodes, making available for predicting the catalytic performance of new non-PGM catalyst systems for PEMFCs. The advancement will improve the development level of related fields, bringing about both fundamental and practical impact on various electrochemical energy conversion systems, e.g. electrolyzers, batteries, supercapacitors, etc.","isTelecoms":1}
{"text":"Title: Fluorescence imaging flow cytometry in non-straight microfluidic channels Abstract: Cells can be manipulated using forces generated by flow, either to probe their mechanical properties or to deliver cargo (e.g. drugs) into the cells. This can be performed in special microfluidic devices. A limitation of these devices, due to the high flow rates and complex geometry, is that it is currently impossible to take fluorescence images of the cells as they flow through. These images are essential for understanding cell behaviour under these extreme conditions, as fluorescence can report on the response of various cellular components (cytoskeleton, membrane, mitochondria) to stress. \nThe aim of this project is to implement a high-speed fluorescence light sheet microscope to view cells under high shear stress in a non-straight microfluidic platform. This will be used to improve our understanding of cellular responses to shear deformation, which has potential application of identifying cancerous cells as well as delivering probes and drugs into cells. \nIn order to create a shear stress, a flow cytometer will be manufactured in a cross-flow junction geometry, where fluid flows in and exits through two separate channels and the cells experience large shear stresses at a stationary central point. This geometry however makes implementing a fluorescence microscope challenging. Oblique plane microscopy will be used, as this technology is able to apply light sheet microscopy in an inverted geometry (viewing the microfluidic device from the bottom). Meanwhile the light-sheet is essential to minimise out-of-focus fluorescence to generate high-contrast images at high speeds. With this setup the aim is to achieve imaging at 200,000 frames-per-second, using an intensified high-speed camera. This will in turn allow measurements of 100,000 cells\/min with the cells flowing at speeds of up to 1 m\/s in the flow cytometer. \nWhen cells experience high shear stresses they respond by undergoing substantial stretching. This stretching has been shown to depend on the type of cell, such that cross-flow cytometry can be used to identify cancerous cells. However, little is known about which cellular components are responsible for deformation under these conditions and this is where the new cytometer will be applied to study how various cell component control the deformation. \nFurthermore, as cells are stretched pores are formed in the cell membrane to account for the increased surface area. This offers potential opportunities for drug delivery or the transport of small molecules into cells due to these pores being created during deformation. With the addition of fluorescence microscopy, our understanding of the cellular mechanisms responsible for the creation of these pores will be improved. With an increased understanding of pore formation (e.g. pore size distribution, lifetime, stability), there is a possibility to model and describe their capability of acting as transport vehicles for intracellular delivery.","isTelecoms":1}
{"text":"Title: Dynamic Reaction Monitoring as Enabling Technology for Developing New Selective Catalytic Syntheses in the Fine Chemical Industry Abstract: In this project, we will use advanced FlowNMR spectroscopy coupled with other complementary techniques such as UV-vis spectroscopy, mass spectrometry and high-performance liquid chromatography for real-time investigations of molecular solution phase transformations, catalysis with transition metal complexes in particular, with the aim of deriving kinetic and mechanistic information that will allow us to improve existing processes and bring about new reactivity of relevance to industrial fine chemical synthesis.\nExample work packages include:\n1) Ru- and V-catalysed Meyer-Schuster rearrangement reactions of alkinols. Building on preliminary joint work, establish monitoring of these air-sensitive transformations in flow, utilising selective excitation pulse sequences, hetero-nuclear NMR and two-dimensional techniques to quantify catalyst intermediates. Main focus besides establishing reliable methods for quantitative real-time monitoring of this reaction is understanding and preventing catalyst deactivation to improve productivities.\n2) Ru\/Rh\/Ir-catalysed selective hydrogenation reactions. Extend setup to work under pressures of dihydrogen as reductant, and establish para-hydrogen and deuteration techniques with the aim of increased mechanistic understanding allowing to improve selectivities.\n3) Acid-catalysed carbon chain elongation reactions. Develop advanced 13C FlowNMR methods and reaction engineering solutions including mass spectrometry sampling to allow tracking C3 and C4 extension reactions at high temperature and pressure with the aim of understanding the reaction pathway.\n4) Cu-catalysed aerobic oxidations of phenols to quinones. Explore the possibility of utilizing paramagnetic NMR spectroscopy in flow with the aim of establishing a method for investigating oxidation reactions proceeding through open-shell species.\nThe work will be carried out in Bath's Dynamic Reaction Monitoring Facility, supervised by Dr Ulrich Hintermair. DSM offer strategic advice and project support in form of access to R&amp;D materials and foreground IP as well as placement opportunities. Project updates by email or telephone were agreed to occur every 3 months, project meetings in person or via Skype every 6 months, and written reports every 12 months.","isTelecoms":0}
{"text":"Title: Advanced random field models and practical Bayesian estimation Abstract: Bayesian methods involving Gaussian processes and random fields are commonly used when modelling spatial and spatiotemporal phenomena in a wide range of problems in ecology, geoscience, medical imaging, and epidemiology. However, realistic models can require non-stationary, non-Gaussian and non-linear behaviour that current methods are not equipped\nto handle efficiently. In this project, current models and methods based on Gaussian stochastic partial differential equations, numerical optimisation and integration, and currently implemented in the R-INLA software (http:\/\/r-inla.org and http:\/\/inlabru.org) will be extended to non-stationary and non-Gaussian models. An important aspect of computationally\nefficient methods is to assess how close the numerical results are to the theoretically exact values, as well as to assess how well the estimated models mimic the real observed phenomena. This aspect will involve developing practical diagnostic measures for the approximations, and for assessing probabilistic spatial and temporal predictions.","isTelecoms":1}
{"text":"Title: The discernment of metals by a set of DNA-binding transcriptional regulators Abstract: It has recently been estimated that 47% of all enzymes require metals such as copper, zinc, nickel, cobalt, iron, manganese, calcium and magnesium. On average, almost half of all attempts to manipulate the activities of cells (for example in metabolic engineering) will involve an enzyme which must somehow acquire the correct metal. Selection of the correct metals by enzymes is substantially governed by metal-availability at the site of protein folding, and metal-availability in cells is, in turn, substantially governed by sensors that detect excess or deficiency of each metal. Crucially, these sensors somehow discern the different inorganic elements, one from another. A zinc-sensor called MTF1 is currently the only DNA-binding, metal-binding, metal-sensor known in humans. However, over the last two decades we, and many others, have discovered an expanding repertoire of bacterial DNA-binding metal-sensing proteins. These sensors turn genes on or off; each sensor acting in response to specific metals. The genes that some of the sensors regulate have been found and the metals they respond to identified. Among the regulated genes are ones encoding importers that acquire more of those metals which are needed and exporters that pump out metals that are surplus to requirements and\/or solely toxic. The sensors work in several different ways. Some bind to DNA and, in effect, switch a gene off. When the sensor binds to the metal its structure changes such that it no longer binds tightly to the DNA and the gene becomes active. Other metal-sensors do the reverse. Their structure changes upon binding a metal such that only under these conditions do they bind tightly to DNA and switch a gene off. Finally, some sensors bind to DNA both with and without a metal but a change in protein structure caused by binding the metal distorts the DNA to activate gene expression. The characterisation of these assorted metal sensors has provided an opportunity to explore how metals are discerned. A na&iuml;ve expectation was that each sensor would tightly bind the metal it detected and bind all other metals weakly or not at all. But this turns out not to be the case and indeed fundamental rules of bioinorganic chemistry imply that for flexible proteins it could rarely be the case. Thus the question becomes, regardless of the mechanism of gene regulation, how does each metal trigger the correct sensor protein? To answer this question we need to consider a set of sensors from a single bacterium. We need to consider their affinities for different metals, not in isolation, but in the context of the metal-affinities of all of the other metal-sensors in the same cell. A simple explanation could be that the sensors give the correct integrated response as a function of their 'relative' metal affinities rather than their 'absolute' metal affinities: the cobalt sensor being the tightest cobalt-binder of the set, the zinc-sensor being the tightest zinc-binder of the set, and so on. The organism chosen for this work, a cyanobacterium, has a set of metal-sensors with properties that are peculiarly well suited to comparing their metal-affinities, one against the other, using a method that we exploited and published in 2007. In this program we will also characterize at least one new metal-sensor. This is fundamental research. Discerning metals is, literally, elemental to life. Nonetheless, it has implications and applications across the biosciences and biotechnology and for this reason we, and the rest of the 'Metals in Cells' group at Newcastle, actively collaborate with the biotechnology industrial sector. Industrial links related to this programme are described in the impact plan.","isTelecoms":0}
{"text":"Title: An Integrated Approach to Assessing Catchment Resilience: Combining GIS and Field Data in Relation To Climate Change Projections in the River Derwen Abstract: Changing conditions such as land-use and climate change in the UK has affected catchment behaviour, one of the key challenges is related to the removal, redistribution and deposition of sediment within a catchment. The increased deposition of sediment within catchments is causing problems such as increased water quality treatment costs. This is clearly seen within the River Derwent study area. One way to reduce costs associated with water quality treatment is to include the whole supply chain, from land owners to water companies. \n\nThe source of fine grained sediment within a catchment can be mapped using software such as geographic information systems (GIS). This research aims to produce a GIS model and framework to assessing sensitive reaches and areas within a catchment in relation to fine grained sediment including source areas, sediment pathways and sediment deposition within the catchment. The model will integrate high resolution satellite imagery to inform seasonal changes in land-use and vegetation and climate change projections. Once sensitive reaches have been identified, field work will be undertaken to assess the validity of the output. Field work data collection will include sediment grain size analysis and sediment fingerprinting to identify source areas. The model will identify areas within the catchment where management or intervention is required to reduce the impacts of fine grained sediment. \n\nThe model will directly benefit Yorkshire Water as creating a GIS model will reduce the costs of fieldwork associated with highlighting these areas. By including the whole supply chain and land-users, costs will be reduced in relation to soil erosion and the removal of valuable top soil. Further reducing the input of fine grained sediment into rivers will reduce flood risk. Water is an integral part of the economy, and by reducing costs associated with water treatment, the water supply will become more resilient. This will help keep a resilient economy, a key challenge with regards to the Industrial Strategy.","isTelecoms":0}
{"text":"Title: Keeping Vital Commercial Online Systems Up and Running With Reduced IT Personnel Abstract: This project proposes an efficient, automated, and online software system that continually probes a companies online systems to determine if they are vulnerable to new cybersecurity attacks. This software system will use open source and custom probes to determine if a system is vulnerable, and alert the companies relevant team.\n\nThis system is designed to be efficient, only alerting for exploitable vulnerabilities, so as not to swamp teams, and have its interface and operations designed to be easy-to-use for any SME. This system will be a cost-effective early warning system for companies who do not have an IT team available to perform this monitoring and wish to only be alerted to vulnerabilities or patches that are absolutely necessary.","isTelecoms":1}
{"text":"Title: Study of hypothalamic amino acid sensing pathways implicated in the regulation of energy balance Abstract: Obesity and its associated conditions, such as type 2 diabetes and cardiovascular disease, are major health threats worldwide. The brain plays a huge role in the regulation of energy balance. Specialized brain cells process information about ingested food and fat stores and directly regulate food intake, energy expenditure or storage. Among other signals of energy availability, the brain monitors circulating levels of nutrients such as glucose and amino acids. In this project we want to characterize the mechanisms implicated in brain amino acid detection in the regulation of energy balance. This research will improve our understanding of the pathways implicated in the regulation of body weight and potentially identify novel therapeutic targets for the treatment of obesity.","isTelecoms":0}
{"text":"Title: Improving maternal-neonatal outcomes through implementing Quality Midwifery Services in India: a case study of facilitators and barriers Abstract: Approximately 45,000 women die of pregnancy-related causes each year in India, and global evidence shows that 83% of these death can be prevented if competent midwives provide skilled birth attendance. India does not have independent midwives. Indian nurses, who have studied midwifery as part of their nursing studies work as the nurse-midwives in most of the health facilities in public and private sectors. Since India is striving to bring the maternal deaths down from 130 to 70 per 100,000 live births by 2030; the Government of India has acknowledged that introducing and strengthening midwifery in line with the international standards could be an effective strategy to achieve the target.\nThe Government of India has supported additional training of some nurse-midwives to prepare them as Nurse Practitioners in Midwifery in the states of Gujarat and Telangana. These Nurse Practitioners in Midwifery have been posted in public health facilities serving remote\/rural\/difficult-to-access geographical areas. In Gujarat, some Nurse Practitioners in Midwifery have been posted in Urban Family Welfare Centers too.\nAn Indo-UK consortium of researchers have developed this research proposal titled &quot;Improving quality of care through implementing quality midwifery services in India: a case study of facilitators and barriers&quot;. This project will be implemented over a period of 12 months. The aim of this study is to document the perceptions and experiences of women, families, community influencers; the Nurse Practitioners in Midwifery, other nurse-midwives, and obstetricians about midwifery; and the facilitators and barriers for establishing independent midwifery in India. The study will also highlight gaps in the quality of care and identify important outcomes that could be used assess whether midwifery is effective.\nOur research work will involve qualitative in-depth interviews\/focus group discussions\/group interviews with women, and community influencers (40 in total) and also with Nurse Practitioners in Midwifery, other nurse-midwives, and obstetricians (40 in total). Reviews of Indian and international literature will be carried out to identify the key maternal-neonatal outcome indicators; and 5 maternal and neonatal deaths from each state will be reviewed to see if reviews of death are a good way to identify gaps in care.\nThis study will pave the way to do further research to evaluate the impact of midwifery care on maternal and neonatal outcomes in the coming years; and lay the foundation to develop interventions to strengthen rolling-out midwifery care in India. The project will also train early-stage Indian researchers in research skills.","isTelecoms":0}
{"text":"Title: Probing presynaptic regulators of dopamine to identify new opportunities for therapy in Parkinson's disease Abstract: Parkinson's disease is a neurodegenerative condition caused by the death of neurones in the brain that release the neurotransmitter dopamine. Dopamine is essential for regulating motor function, and thus the loss of dopamine as a result of these neurones dying manifests as motor dysfunction in patients with Parkinson's disease. This typically presents with tremor, rigidity, and bradykinesia in patients. However, current therapies for restoring dopamine release from these neurones are limited, both in terms of their efficacy and the side-effects produced. My research will aim to identify novel mechanisms of enhancing dopamine release from these neurones, which may then have the potential for clinical translation into new therapies. \n\nThis studentship will provide me with the opportunity to develop various skills. Firstly, I will learn new practical techniques that will be crucial to my future research, such as fast-scan cyclic voltammetry (allowing real-time detection of dopamine levels in tissue) and electrophysiology. I will also develop my skills as a scientist, to assimilate the existing research in the scientific literature to formulate my own hypotheses, and then design the experiments (in collaboration with my supervisors) to test them. \nAs an iCASE student with an industrial partner and supervisors, I will develop my understanding of the collaboration that takes place between academia and industry. I will also have the opportunity to exploit their insight into potential research targets for treating Parkinson's disease, in addition to learning new techniques in their facilities.","isTelecoms":0}
{"text":"Title: 20-BBSRC\/NSF-BIO: The amphibian skin microbial-immune interface and its impact on infection outcome Abstract: The immune system is one of the primary ways animals fight pathogenic microorganisms. Animals also live with millions of non-pathogenic microorganisms (their microbiomes) which cause them no harm. Accumulating evidence indicates that immune systems establish intimate relationships with these microbiomes, which may make the difference between life and death for an animal exposed to a pathogen. Amphibians exemplify the importance of studying interactions among microbiomes, immune systems and pathogens. Amphibians across the globe are dying from infection by the chytrid fungus Batrachochytrium dendrobatidis (Bd). Bd infects the skin of amphibians and causes death by disruption of essential skin function. Amphibian skin microbiome and immune system components have been shown to independently relate to Bd infection outcomes. Yet, the interactions among host microbiomes, host immune systems and the pathogen Bd remain poorly understood. This microbial-immune interface is likely critical to determining Bd infection outcomes. The proposed research is unique and innovative because the investigators will combine laboratory experiments using three amphibian species that differ in Bd susceptibility with state-of-the-art molecular and analytical approaches. Together, they aim to define the mechanisms controlling the microbial-immune interface and its effect on Bd susceptibility. They expect to demonstrate that amphibian skin microbiomes and host immune responses are interconnected, multi-facetted systems rather than discrete host and microbial entities. \n\nThe central hypothesis guiding the proposed studies is that the interdependence of amphibian skin microbiomes and resident immune cell populations critically define Bd infection outcomes. The interdisciplinary research team will integrate microbial ecology, comparative immunology, meta-transcriptomics and proteomics at multiple experimental scales. They will combine these comprehensive system-level datasets with network analyses and structural equation modeling to examine the amphibian skin microbial-immune interface and its effect on amphibian susceptibility to the disease chytridiomycosis, caused by Bd infection. They will address their hypothesis by: 1) determining how skin microbiomes affect skin immune cell populations, 2) defining how skin-resident immune cells affect skin microbiomes, 3) resolving the contribution of the microbial-immune interface in Bd infection outcomes. They predict that key microbial-immune interactions strongly impact Bd susceptibility. Their findings will garner the much-needed understanding of the microbial-immune interface and how these interactions impact disease outcomes. Theirs will be the first study to simultaneously evaluate the relative contribution of the microbiome and immune system to chytridiomycosis in a causal framework. Vertebrate animals, including humans, are host to symbiotic microbes and complex immune system components. The resulting insight from these investigations will have broad applicability to a variety of other animal systems.","isTelecoms":0}
{"text":"Title: Exploring quantum enhancements from indefinite causality and time-reversing gates Abstract: The notion that events happen in defined causal orders, where one event temporally follows another, is innate to our understanding of the classical world we live in. However, the laws of quantum mechanics allow the strict assumption of a definite causal order to be relaxed, giving rise to events with indefinite causal orders arising from quantum superpositions of causally ordered processes [1]. Indefinite causality can be exploited to achieve advantages in quantum computation [2], quantum communication [3,4], quantum metrology [5], and other information processing tasks [6]. It also has implications for the foundations of quantum theory and concepts in quantum gravity. The aim of this project is to investigate the fundamental concepts underlying indefinite causality and explore potential new quantum advantages that can be harnessed, both on theoretical and experimental fronts. In this hybrid project, I will first work on (i) the theoretical aspect of formulating physical processes able to violate so called &quot;causal inequalities&quot; [7] (bounds on the correlations between events which hold whenever these take place in a well-defined causal order), and (ii) theoretical advantages that can be achieved from indefinite causality, before moving onto experimental work using integrated photonics. On the experimental side, I will perform experiments to illustrate the advantage of \nindefinite causality in quantum metrology, using a silicon photonic chip that has already been fabricated and is now ready for characterisation. Based on the results obtained in the first (theoretical) phase of this project, this project may also include first prototype experiments demonstrating the violation of causal inequalities, or indefinite causal order processes involving 4 parties. Alongside the work on indefinite causality, I will also study a conceptually related concept, namely, the possibility of temporally reversing unknown unitary operations [8,9] and its applications for quantum technologies. I will extend the theoretical work I started in Project A for a protocol to perform quantum key distribution (QKD) noiselessly along a channel that applies unitary noise. I will also design an on-chip experiment to demonstrate the protocols in Ref. [8,9].","isTelecoms":1}
{"text":"Title: Examining the volcanism-extinction link: an end-Guadalupian case study Abstract: Is volcanism capable of causing species to go extinct? We don't know the answer to this question but evidence from rocks provides some intriguing clues. Thus, it has been recognised that all the extinction events of the past 300 million years coincide with major volcanic eruptions. These eruptions consisted of huge flows of basalt, involving 100s or 1000s of cubic kilometres of lava, that quietly oozed from the ground, plus some much more violent eruptions that scattered volcanic ash over great distances. Working out which of these styles of eruption are most closely associated, in time, with the extinctions has proved very difficult because the fossil evidence is usually found far away from where the volcanism occurred. This project will address this problem by studying a unique example of the volcanism-extinction link from 260 million years ago when lavas and ashes were repeatedly erupted into shallow seas in present-day China. The limestones that formed in these seas contain abundant fossils and evidence of a catastrophic extinction. By studying these Chinese rocks it will be possible, for the first time, to study directly both the volcanism and extinction story in the same place. The work will be supplemented with studies of carbon and sulphur isotopes from the limestones which will allow the scientists to determine changes in the state of the oceans during this interval.","isTelecoms":0}
{"text":"Title: OPTOMICS - Combining optoacoustic imaging phenotypes and multi-omics to advance diabetes healthcare Abstract: Diabetes has emerged as a global pandemic affecting more than 420 million people worldwide, a number expected to further rise in the next decades. The disease has very heterogeneous outcomes and accurate patient staging or prediction of subsets of individuals likely to develop disease and\/or progress to disease complications are currently unmet clinical challenges in need of urgent attention. OPTOMICS aims to research methodology that can deliver a paradigm shift in type 2 diabetes healthcare, by integrating 1) molecular phenotyping, 2) a new generation of phenotypic measurements in humans, representative of diabetes onset and progression, allowed by novel portable and non-invasive optoacoustic technology and 3) cutting-edge computational approaches leveraging progress in Artificial Intelligence. This research will develop and validate a digital twin model that catalyses a step change in shortening the path to translation, enabling applications in the entire spectrum from target identification & prevention\/prognosis to patient stratification for type 2 diabetes and its complications. In addition to the research and technology goals, OPTOMICS places special attention to the ethical needs and implications of the work performed and further aims at exemplary project management, human measurements, dissemination and communication activities and updating an adept exploitation plan for the digital twin developed.","isTelecoms":0}
{"text":"Title: Coupled Evolution of Ice Shelf and Ocean in the Amundsen Sea Sector of Antarctica Abstract: As our planet warms the ice cover shrinks, a process that transfers water from land to ocean and thereby raises sea level. The result, which could ultimately raise global sea level by 10s of metres, seems intuitively obvious. However, in the case of the Antarctic Ice Sheet, the processes at work are less than obvious. The atmosphere over the ice sheet is too cold to drive significant melting, so all the snow that falls in the interior is returned to the ocean as ice that only melts once it is afloat. The cold atmosphere creates cold surface waters, so most of the heat that melts the ice comes from deep within the ocean's interior. As it melts the floating ice from underneath, the thinning of the so-called ice shelves allows ice to flow off the land more rapidly, hence raising sea level.\n\nSo, the underlying process is clear, but why should it drive a loss of ice from Antarctica as the climate warms? The waters that melt the ice are too deep in the ocean to feel atmospheric warming. However, as the atmosphere warms the circulation patterns change, influencing the winds that drive the ocean currents, and that delivers more of the deep warm water to the ice. Understanding how the processes work has been challenging. It is not immediately obvious why a change in the winds should deliver more, rather than less, warm water to the ice. Nevertheless, observation and modelling give us a consistent answer and our understanding of the processes grows as we focus our research on key unknowns.\n\nHowever, there is another puzzle that has received much less attention to date. More warm water leads to more rapid melting of the ice shelves, they thin and the flow of ice off the land accelerates. That acceleration of the flow delivers more ice to the ice shelves, and they should therefore start to grow, or at least thin less rapidly, unless the ocean heat delivery continues to grow. Until recently it was assumed that that is exactly what was happening, but as our record of ocean observations has lengthened, we have seen decadal cycles of warming and cooling. Why then should the ice shelves continue to thin?\n\nThe answer must lie in the way in which the thinning of the ice shelves themselves affects the melt rate. Again, it is not immediately clear why the change in the ice should increase rather than decrease the melt. However, in this case observation of the key processes is exceptionally difficult because they take place beneath 100s or even 1000s of metres of ice.\n\nThat is the challenge we will address with this project, by sending an autonomous submarine beneath the ice to make the critical measurements of the ocean, including the temperature of the water and the currents. Those direct observations of the ocean beneath the ice will allow us to verify that the ocean models we use to simulate the processes are correct, or to improve them if they are not.\n\nThis will not be the first time such measurements have been made, but the new observations will differ in two important respects from the very few that have been made in the past. Some will be repeats of earlier measurements, so we will have observations from before and after a significant change in the extent of the ice shelf. Thus, we can directly answer the question of what change in the ocean circulation accompanied the change in shape of the ice cover. Other observations will target regions where the ice was grounded until recently. Because radar signals penetrate ice, but not seawater, we are able to map the topography only when the ice rests on the land and not when it is afloat. Thus, we paradoxically know the geometry of newly formed ocean cavities with much greater accuracy than we do the cavities that have been there since humans first explored the south polar regions. Our ability to understand the links between cavity geometry and ocean circulation is therefore enhanced in the newly opened cavities that are among the targets of our field campaign.","isTelecoms":0}
{"text":"Title: 'Strange Magic': A Creative and Critical Exploration of Bisexual Representation in Young Adult Fantasy Literature Abstract: My critical-creative project explores depictions of bisexuality in a selection of post-2009 young adult fantasy novels. My primary critical research question is: how, why and to what ends do these texts employ magic to support their construction of bisexual characters?\n\nMy first critical chapter investigates the parallels between the experience of &quot;growing up magic&quot; and growing up queer, while the second discusses the magical bisexual body. The final chapter discusses how the indeterminate nature of the borders and boundaries demarcating the magical worlds in these texts reflects the liminal existence of the bisexual teenager.\n\nMy findings will inform my YA fantasy novel, a fully realised portrayal of bisexuality in which a girl discovers her magic and her sexuality against the backdrop of a mysterious magical market.","isTelecoms":0}
{"text":"Title: Structure, function and resilience of avian communities in tropical ecosystems Abstract: The study of biodiversity and its role in natural ecosystems is an urgent priority because the Earth is facing unprecedentedly rapid changes in climate and land-use. These changes will be felt most acutely in tropical regions, not only because they are set to experience the biggest increase in human population, habitat loss and economic development, but also because they support the vast majority of species (&gt;80%), many with small ranges and narrow climatic limits, making them vulnerable to extinction. However, partly because of a research bias towards temperate systems, we have a very incomplete understanding of how range shifts and extinctions will affect ecosystem structure and resilience in tropical regions.\n\nOf all tropical biodiversity, vertebrates are the iconic figureheads for conservation. They are central to a range of key ecosystem processes, such as seed dispersal, pollination and predation. The importance of understanding the forces underpinning the structure, function and resilience of their communities is clear, yet the answers remain elusive because of the difficulty of surveying vertebrates. In addition, the coverage of molecular data for vertebrates has until very recently been incomplete.\n\nIn this project, we will capitalise on new high-resolution datasets for the best-known group of tropical vertebrates - birds - to test ecological theory at contrasting spatial scales using community phylogenetic approaches. We will use site-based faunal lists gathered throughout the Neotropics in recent decades. We will also use plot-based community and abundance data collected through fieldwork across an elevational gradient in the tropical Andes. These datasets will be coupled with information about ecological niches and functional traits for each species. In all cases analyses will be framed by newly available species-level phylogenies, which have the power to reveal the structure of evolutionary relationships between community members, and uncover the way niches and traits have evolved through time. This will help us to compare communities from sites with differing levels of habitat degradation and fragmentation.\n\nTo manage ecosystems effectively we need to understand the mechanisms governing responses to change, and how these changes are likely to influence the ecological function and resilience of communities over time. The main goals of this research are to understand (1) how species from a regional pool are assembled into local communities, (2) how the phylogenetic structure and ecological function of communities varies in relation to climate and human impacts, and (3) how we can apply insights from (1) and (2) to improve methods for ecological forecasting under various global change scenarios. The results will provide a more complete understanding of the forces shaping and regulating biological communities worldwide, and enhance our ability to predict the consequences of environmental change, particularly in tropical systems.","isTelecoms":0}
{"text":"Title: Greenhouse Gas Removal Plus (GGR+): Sustainable Treescapes Demonstrator &amp; Decision Tools Abstract: Due to the need for climate change action, UK Government has committed to the ambitious task of achieving 'net zero' greenhouse gas emissions by 2050. However, some emissions from farming, aviation and other activities are very difficult to eliminate. So to reach net zero the UK must also directly remove greenhouse gases from the atmosphere amounting to the equivalent of 100 million tonnes of carbon dioxide\/year. \n\nOf the Greenhouse Gas Removal (GGR) options available, increasing the carbon stored in the UK's 'treescapes' (forests, hedgerows etc.) has the greatest potential, the lowest cost, and can be started immediately. Planting woodlands can store carbon in standing trees, in forest soils and in timber products. For these reasons, the UK is committed to a huge increase in forest cover. However, our understanding of all these processes and how they vary across locations and over time is incomplete. This major programme will gather evidence, address knowledge gaps and allow decision makers to understand the GGR consequences of different planting options. Woodlands can also deliver many other benefits, creating habitats to conserve wild species, enhancing water quality, regulating rainfall and reducing flood risk, and providing recreation (hence the &quot;GGR+&quot; title). \n\nGGR+ will examine all the diverse aspects of forestry to identify &quot;The Right Tree in the Right Place&quot;. However, it is equally possible to plant the wrong tree in the wrong place. This can result in damage to biodiversity, and even cause some soils to release huge amounts of carbon into the atmosphere. Also, if certain types of agriculture are displaced, there could be higher imports of food from countries that destroy rainforests to increase farm yields. On top of this, climate change means that many risks (forest fires, extreme weather, disease) are changing faster than ever. \n&quot;The Right Tree in the Right Place&quot; is not a simple proposition - if we are not careful, and don't consider the complexities properly, the UK's net zero tree planting strategy will be poorly designed, and at worst could result in forests that actually increase climate change. \n\nHowever, even understanding the consequences of planting in different locations is not enough to plan the future of the UK's forests. Land is typically privately owned and Government cannot dictate its use. Rather they need to create the conditions and incentives needed for owners to decide to plant trees. Consequently, GGR+ will also undertake the economic research needed to turn science advice into practice. \n\nThis challenge cannot be addressed by scientists alone, and the GGR+ partners include UK land use policy makers, including all of the Forestry authorities, the Defra teams responsible for forestry, climate and agriculture (who will use GGR+ to plant 30,000ha\/year), as well as the Ministry of Defence (which has huge land holdings). From the private and NGO sectors our partners include massive land owners such as Network Rail and the National Trust (who together will fund over 74,000ha of planting based on GGR+ advice), as well as a network of over 1,400 farmers, the timber and building sector and many other stakeholders. \n\nTogether with our partners, GGR+ will design innovative &quot;decision support tools&quot;; bespoke software allowing users to examine the effects of a tree planting investment or policy in terms of greenhouse gas storage, food production, incomes of those involved, effects on biodiversity, water quality, flooding, recreation etc. Perhaps most revolutionary, this tool will allow users to specify what outcomes they want and then see what planting, policy or investments they need to get those outcomes. \n\nThis is an exciting, highly interdisciplinary approach to answering the surprisingly challenging question of finding &quot;The Right Tree in the Right Place&quot; and setting the UK on the path to delivering net zero emissions by 2050.","isTelecoms":0}
{"text":"Title: Interrogating the (re)construction and (re)negotiation of black Caribbean cultural identities in the wake of Windrush scandal and white Britain. Abstract: This study endeavours to understand the construction of Caribbean cultural identity amongst black British millennials - those aged between 22 and 37 years old - and how much past histories and contact with whiteness in contemporary society influences their identity. The demographic in question has been chosen because of the proliferation of &quot;black&quot; culture and race-related discourses, discussions and content on social media which has opened questions of &quot;race&quot; and racism in contemporary society.Using semi-structured interviews and discourse analysis, the study will capture aspects of Black Caribbean identity often hidden from view through the sharing of participants personal narratives, experiences and constructions of their identity. Such methodologies are useful and relevant in the attempt to interrogate how we understand (re)construction and (re)negotiation of black Caribbean identities within contemporary society.\n\nTherefore, the aim of this research is firstly to understand what underpins constructions of Caribbean identity and what it means to be black in contemporary discourse and is this construction in relation to whiteness - consciously or subconsciously. Secondly, the research aims to explore the construction and negotiation of black Caribbean identity through the act of narration itself in the interview space. And lastly, the research aims to utilise reflexive methodologies to address the complexities of identity construction of those of African Caribbean descent who exist in a &quot;white space&quot;. \n\nThe research question can be framed as:\nTo what extent are contemporary constructions of Caribbean cultural identities, by black British millennials, underpinned by histories of empire, trauma and racism. And how are these identities then negotiated within the context of whiteness in Britain?","isTelecoms":0}
{"text":"Title: Building understanding of climate variability into planning of groundwater supplies from low storage aquifers in Africa (BRAVE) Abstract: Africa's population is growing rapidly and is expected to increase by over 150% between 2000 and 2050. This will result in an increased demand for water. Groundwater has been identified as having the potential to meet much of the growing water requirements for domestic use, food production and other productive uses, especially as it is seen as being more resilient to climate variability than surface water resources. However, it is recognised that in large regions of Africa where the groundwater store is relatively small there may be occasions when extended periods of low groundwater recharge result in water shortages. \n\nAs groundwater is being promoted as a means to address Africa's future water supply needs, further research is crucial to study the potential vulnerability of communities that become more reliant on these low storage aquifers. This will allow better decisions to be made when planning groundwater development. The BRAVE project (Building understanding of climate variability into planning of groundwater supplies from low storage aquifers in Africa) aims to take advantage of recent developments in models of climate, the land surface and groundwater to improve the understanding of how these groundwater resources are affected by climate variability, under present and future climate, and by changes in land use and water demand. A key element of the project is to ensure that the output from the model is in a form that addresses the questions being asked by those making decisions on water resource development.\n\nThe BRAVE project will use the River Volta Basin (RVB) in West Africa as a case study area, working in Burkina Faso and Ghana. It brings together a strong team of internationally-recognised meteorologists, hydrogeologists, land surface modellers and knowledge exchange experts, with extensive experience of working in Africa, and builds on recent NERC-funded research.","isTelecoms":0}
{"text":"Title: Antarctic ice mass fluxes from satellite observations Abstract: The Antarctic ice sheet is the largest freshwater store on Earth by an order of magnitude and contains enough ice to increase global sea level by ~65 m. Changes in the input and output of ice (the mass balance) have profound implications for sea level, ocean circulation and inferences concerning the stability of the ice mass. The mass balance of the ice sheet is controlled by both short term and long term processes related to changes in snowfall and ice dynamics. To understand how the ice sheet is behaving now and to be able to predict how it will behave in the future we need to be able to quantify and separate the processes responsible for the trends in mass balance. Some recent research using satellite measurements of elevation change suggests that increased snowfall may be contributing to a positive mass balance for large sectors of the East Antarctic ice sheet (EAIS). This conclusion, however, is not universally accepted and the results do not account for processes related to ice dynamics close to the margins of the ice sheet. Other recent studies, using different satellite data, suggest that overall, the ice sheet is losing a large amount of mass and that the EAIS is roughly in balance. To solve the open and crucial question of whether the EAIS is losing or gaining mass and to better understand the mass balance trends for the whole ice sheet, we will obtain accurate, regional-scale mass balance measurements with well constrained error budgets. In this project, in collaboration with US and Dutch partners, we will determine the mass balance of individual drainage basins covering ~85% of the ice sheet and the larger floating ice shelves using a combination of new and existing satellite observations and atmospheric modelling. In particular, we aim to determine conclusively whether the East Antarctic Ice Sheet is a net source or sink of ocean mass. We also aim to investigate the relative importance of trends in snowfall and ice dynamics in the mass budget of the ice sheet.","isTelecoms":0}
{"text":"Title: 2-Dimensional Magnetoresistance Imager Abstract: The discovery of Giant Magnetoresistance (GMR) in magnetic multilayers in 1988, which increased typical values of magnetoresistance (MR) from 1-2% to 10-100%, stimulated extensive research leading to the field of spintronics. Such was the demand for highly sensitive MR sensors, that within 15 years, GMR sensors had been introduced into the read head of magnetic hard disks. Their performance has been so successful that the technology is now being transferred to other sectors such as motion, position, rotation and field sensing; for example in automotive and biological systems. The nanoscale nature of these sensors makes them highly compatible with nanotechnology. Although the ability to manufacture such complex sensors has been proven by the magnetic recording industry, these materials operate on the nanoscale, and layer thicknesses are typically a nanometre. Quality control is crucial. Ideally, the functional property of the device should be tested, in this case, its MR. Electrical measurements of MR require an electric current to be passed through the sample via contacts, resulting in surface damage and contamination. More importantly, electrical measurements offer no spatial resolution, providing no information about variations across the wafer. Furthermore, it is impractical to test the performance of the wafer following lithographic patterning and so sensor characteristics cannot be determined until after subsequent costly intricate stages. There is therefore a clear requirement for a contactless, non-destructive method for characterising MR. Using electromagnetic radiation in the infrared provides all these advantages. We have pioneered the use of reflection and transmission of infrared as a probe of MR. Based on this experience, we recently proposed an alternative using thermal emissivity. This presents a larger and more direct relationship with MR than reflection, and additionally lends itself readily to spatial resolution on the scale of tens of microns. The technique relies on the connection between electrical resistance and emissivity, the efficiency with which a material emits radiation according to its temperature. Emissivity depends on the surface properties of a material and at long infrared wavelengths (&gt; 5 microns) is directly proportional to the square root of resistance. We detect the change in the intensity of the emitted radiation due to a change in resistance. The radiation is measured using an infrared detector and converted into an apparent temperature. When a magnetic field is applied to a GMR thin film, its resistance and consequently its emissivity reduces. The lower emissivity results in less radiation being emitted and this is interpreted by the detector as a reduction in temperature. The GMR therefore manifests itself as an apparent change in temperature in an applied magnetic field. The power of this technique is realised when the detector is replaced by a CCD camera generating a 2D image of the apparent temperature. By subtracting temperature images in different magnetic fields, an image is produced of the change in temperature resulting from the change in resistance, uniquely providing a spatially resolved image of the magnetoresistance.We propose the development of an instrument capable of 2D imaging of MR designed to carry out the quality control of GMR wafers. Successful development will lead the way for insitu measurement of wafers whilst still inside a growth chamber, the evaluation of material at different stages of the lithographic patterning process and open up new applications such as the deliberate introduction of spatial variations in MR for use in of pattern recognition.","isTelecoms":1}
{"text":"Title: MEDUSA Multi Environment Deployable Universal Software Application Abstract: A key factor in reducing potential gun crime is to detect someone carrying a gun before they can commit a criminal act. This detection can be achieved by the existing, and widespread, CCTV camera network in the UK. However, the performance of operators in interpreting CCTV imagery is variable as they are trying to detect essentially a very rare threat event. Additionally, current automated systems for detecting possible anomalous behaviour have been found to have varying success. We propose the development of a new machine learning system for the detection of individuals carrying guns which will combine both human and machine-based factors. Using selected CCTV footage which depicts people carrying concealed guns, and other control individuals, the proposal will establish what overt and covert cues (essentially conscious and subconscious cues) experienced CCTV operators actually attend to when identifying potential gun-carrying individuals from such CCTV imagery. In parallel, a machine learning approach will establish the machine recognised cues for such individuals. The separate human and machine cues will then be combined to form a new machine learning approach which will be fully tested. The system will be capable of learning and reacting to local gun crime factors which will aid its usefulness and deployment capability.","isTelecoms":1}
{"text":"Title: University of Portsmouth and InTandem System Ltd Abstract: To embed new capability and processes to optimise the modelling, design and control of BEMS for energy saving opportunities and to create a new branch to capitalise on this by developing new markets and saving energy for the UK.","isTelecoms":0}
{"text":"Title: University of Kent AHRC Impact Acceleration Account Abstract: The aim of the AHRC IAA is to significantly advance the extent of our reach (scaling 'up'); the diversity of our beneficiaries (scaling 'out'), and the depth of the change (sustaining the impact). This will result in an immediate step-change in impact and knowledge exchange across our research portfolio and will see us achieving our strategic goal of positively impacting on the world around us through driving economic, environmental and social change - both nationally and across our region.\n\nArts and Humanities research at Kent is focussed around three priority themes. These are: History and Heritage, Society and Environment, and Health and Wellbeing. These themes are multidisciplinary and reflect research strengths across and beyond the Arts and Humanities at Kent as well as being aligned to both AHRC and UoK research priorities.\n\nThe IAA has four objectives and related work packages through which we will accelerate impact across our priority themes: \n\n1. Implementing a programme of 'quick response' funding (WP1), enabling rapid response to new opportunities\n2. Developing, testing and implementing new models of social enterprise start-up and licensing (WP2)\n3. Establishing multi-sector strategic partnership networks (WP3) for each theme\n4. Providing targetted impact development training and a toolkit (WP4) to strengthen our knowledge, capacity and capability. \n\nOverall, through the IAA we will have succeeded in increasing creativity, innovation and ambition across AH knowledge transfer and impact.","isTelecoms":0}
{"text":"Title: Manchester Metropolitan University and Instil Bio (UK) Limited Abstract: To investigate the generation of a type of stem cell from cancer specific immune cells, to isolate rarer cell populations from cancers and develop a treatment with enhanced activity and potentially develop this as a treatment that can be used to treat many patients.","isTelecoms":0}
{"text":"Title: Chemical ecological protection of tomato by synergising plant priming and pest deterrence Abstract: When tomato plants, Lycopersicum esculentum, are infested with whitefly, Trialeurodes vaporariorum, they emit herbivore-induced plant volatiles (HIPVs). These volatiles are able to induce an elevated herbivore defence in nearby tomatoes, a concept termed 'priming'. My project aims to develop a non-toxic ecological whitefly pest management system for tomato plants based on the exploitation of this natural plant signalling mechanism. I aim to identify the specific herbivore induced plant volatiles (HIPVs), emitted by whitefly infested tomato plants, which can prime the defence of un-infested tomato plants against future herbivore challenge and allow them to mount a stronger and faster defence. In order to determine the chemicals responsible for priming, air entrainment and GCMS will be used to collect and analyse volatiles from whitefly infested and control tomato plants. Since priming is time-dependent, a comparison of HIPVs collected before, during and after whitefly infestation by a time-series of air entrainments will facilitate identification of chemical signals by GCMS. The priming response will be determined by subsequent infestation and whitefly performance data, as well as by post-colonisation induced volatile defence chemistry (analysed by air entrainment and GCMS). Candidate chemicals will be trialled individually for their ability to reproduce the priming response and efficacy in pest control. \n\nAs well as using HIPVs from tomato, I will identify non-host volatile chemical cues from unrelated plant taxonomy to deter initial whitefly infestation. Literature searches of T. vaporariorum non-hosts will be used to select several separate plant families, and the volatile chemistry of these families tested for behavioural activity with whitefly. Following this, three non-host plant volatiles will be used for further analysis. Candidate non-host and priming volatiles will be tested in a commercial glasshouse setting at Stockbridge, where the compounds will be applied in a standard spray medium onto un-infested tomato plants. This will allow confirmation that laboratory results are applicable to a commercial setting for growing. Settling and egg lay of whiteflies in glasshouse mixed culture will be used as measures of efficacy for the priming compounds identified from HIPVs. The most deterrent non-host compounds will also be determined, as well as the concentrations at which they work most effectively.\n\nFinally, the blending of priming and deterrent material will be trialled. By combining these two chemical ecological mechanisms I aim to prevent successful whitefly colonisation through a novel pest management strategy. The strategy will not rely on stress-induced chemistry, which could have adverse effects on the performance of tomato crops, and will employ cheap, non-toxic chemistry, consequently eliminating biochemical resistance. Using a multi-component strategy will also reduce the development of behavioural resistance in T. vaporariorum and maximise the effectiveness of this pest control strategy.","isTelecoms":0}
{"text":"Title: Randomised controlled trial of habit-based advice for weight control in general practice (The 10TT Trial) Abstract: Most weight-loss programmes aim to encourage people to adopt healthy diet and activity habits. However, changes to lifestyle are known to be difficult to keep up, and tend to slip over time. Psychological research shows that repeating a behaviour in a consistent context can result in it becoming a habit (i.e. automatic). This research will test a treatment programme that uses theories of habit-formation to help people to maintain changes in their eating and activity behaviour over the longer term. The habit-formation approach has successfully helped overweight people to lose weight and keep it off in a small-scale trial with volunteers. This research will test whether it can help larger numbers of people recruited through GPs surgeries, and establish whether it could be cost-effective if it were adopted more widely within the NHS.","isTelecoms":0}
{"text":"Title: CRISPR Screen Multiplexing for Uncharacterised Region Function (SMURF) Abstract: A preliminary stage of the drug development process requires a dependency on a potential cellular drug target, such as a protein, to be validated in a specific disease setting. This development stage is termed 'target validation' and it provides evidence that modulation of a specific target may confer therapeutic benefit to patients. However current methods in target validation frequently identify false positive targets which are then pursued further for drug development. As a result, candidate drug compounds are developed that may confer little or no therapeutic benefit. This incurs substantial cost and time delays to the development process and leaves patients without appropriate treatment options. One approach to reducing the number of flawed target hypotheses is to improve the structural and functional data on targets during their validation. \n\nThe CRISPR-Cas gene editing system has been derived from bacteria and archaea where its native function is as an immune defence against viral infection. This has now been adapted to edit the genome of mammalian cells and has proven invaluable for use within both research and therapeutic settings. Recently published CRISPR-based screening data has demonstrated that certain sections of a gene sequence are not critical to protein function and are therefore unlikely to confer any therapeutic benefit as specific drug target sites. The focus of this project is to determine whether the CRISPR system is amenable to high-throughput screening formats and capable of producing reliable data relating to a target's structure and function. This would allow CRISPR-Cas to be utilised on a larger scale within drug discovery for the validation of novel uncharacterised drug targets that have clinical potential.\n\nThis project has two distinct aims. Firstly, precise DNA editing will be undertaken within a target protein to induce differential sensitivity to specific inhibitor compounds. Secondly, larger randomised gene knockout screens will be conducted to identify those nucleotide sequences that are critical to the function of a target protein. Following the design and development of stable cell lines which express the requisite CRISPR-Cas components, protocols will be validated using cell-based assays to identify perturbed protein function. Genetic sequencing of the target will also be required to illustrate the exact DNA changes that have been introduced. Initially these studies will be conducted in a simplified cell line system before progressing to more complex human cancer cell lines. \n\nCyclin-dependent kinase 2 will initially be used as a model target since its structure and function have been well characterised in the literature. Alternative model targets will also undergo analysis during the course of the project. If successful, this research may provide the pharmaceutical industry with improved methods for target validation by aiding the identification of relevant drug target sites on proteins. Ultimately, this approach may facilitate the identification of effective drugs for life-threatening diseases.","isTelecoms":1}
{"text":"Title: STABILITY ASSESSMENT FOR SUSTAINABLE AND RESILIENT TUNNELLING USING AI Abstract: The demand for fast commuting between densely populated cities has increased over the last 30 years. The need of such infrastructures has risen along with the technological advancement and the environmental advantage to cars and social benefits that encounters. The latter implies that the number of railway and road tunnels connecting (remote) areas faster due to topographical limitations has also risen. One of the key considerations on existing tunnels especially in the UK is their stability state. More specifically, the Victorian tunnels that lie on the nation's railway network have been vital to facilitating a reliable rail service across the country for the past 150 years. However, some of these tunnels have started to challenge the existing network. These tunnels were originally constructed using several rings of brick masonry as a lining. After many years, these brick linings have started to degrade and bricks are becoming dislocated from their surrounding rings, falling on the tracks deteriorating the transport service. There is a gap of scientific and technical knowledge in the tunneling environment and conditions at which these tunnels were initially constructed which exacerbates their current stability assessment where in most cases these tunnels have exceeded their proposed lifetime (Atkinson et al 2020). \nCurrently, condition assessment of all Network Rail tunnels is conducted by assessors through manual, visual, and tactile survey from track level and where necessary through the use of scaffolds or Mobile Elevated Working Platforms. Due to the health and safety risks associated with working on the railway, the manual and subjective assessment process as well as disruptive access that includes line blocks in which trains are not allowed to run, which leads to disruption to the travelling public, there is a concerted effort to automate the condition assessment of these tunnels. Another main limitation of the current method of condition assessment is that examination reports for tunnels are produced using manual entry of visually logged defects in to a Microsoft Excel spreadsheet that provides a schematic record of the examination findings and a Tunnel Condition Marking Index that scores the tunnel condition. The visual nature of examinations and the reliance on qualitative and often subjective records can lead to miscommunication when comparing the records of examinations carried out at different times or by different assessors. This subjectivity in assessment poses a safety concern in that defects are often missed due to the didcult environment and conditions within the tunnel under which qualitative assessments are visually made. \nThe main aim of this research project is to investigate the applicability of articial intelligence (AI), machine learning\/deep learning and signal\/image processing technologies to rapidly recognise common defects that are observed in tunnels due to various geological and geomechanical phenomena that can take place over the lifetime of these Victorian tunnels. Focusing on the long-term mechanisms (Paraskevopoulou, 2016; 2018, Paraskevopoulou et al. 2017, Paraskevopoulou and Diederichs, 2018) that have contributed to the current state aiming at expanding the current knowledge and practice performed by our industry partners, Bedi Consulting Ltd (BEDI), and National Rail from data captured using emerging technologies such as 3D laser scanning, photogrammetry and drone based survey to investigate the application of automation\/learning algorithms to objectively and quickly recognise long-term tunnel performance. The latter will contribute to relating these to the geomechanical behaviour (Bedi et al 2017) of the surrounding rock masses proposing mitigation measures and design guidelines (Bedi and Orr 2014) for sustainable and resilient tunnelling projects.","isTelecoms":1}
{"text":"Title: Access to justice for children with autism spectrum disorders Abstract: Evidence collected from eyewitnesses is crucial for the success of a criminal investigation. Information from witnesses governs the initial direction of an investigation (providing lines of enquiry and identifying possible suspects), and the strength of evidence has been associated with guilty suspects confessing to their crimes. However, little is known about the capabilities of individuals with autism spectrum disorders (ASD) when providing witness information. Given their vulnerabilities in terms of cognitive, social and emotional difficulties, these children are at high risk of victimisation, violence and abuse. Therefore, fair and appropriate access to justice for children with ASD is an issue of paramount importance. \n\nThe population of children and adults with ASD is very large, with prevalence rates of approximately one in 100 (Baird et al., 2006). We already know that individuals with ASD display a characteristic pattern of memory difficulties (e.g., having trouble recalling personally experienced events and recognising faces) and social communication impairments (e.g., lack of eye contact and problems with holding conversations) that call into question their abilities as criminal witnesses. Yet the few studies that have been conducted on this topic have shown that, although individuals with ASD recall less information about a witnessed event than typical groups, the information that they do provide can be just as accurate. \n\nEven less is known about the strengths and weaknesses of individuals with ASD across all the different stages of a criminal investigation. During the proposed research, several novel questions will be addressed: How does this group fare throughout the investigative process (e.g., during initial questioning, in an investigative interview, when identifying perpetrators, and during cross-examination)? What can be done to improve the amount of information that children with ASD recall, without a subsequent decrease in the accuracy of this information? How do the general public (who may be evaluating the evidence of individuals with ASD within a jury) perceive witnesses with ASD? And what factors (e.g., mood state, anxiety, suggestibility, basic memory abilities) are associated with the performance of children with ASD in a witness context? \n\nThis research will represent the first in depth investigation of witness characteristics in children with ASD and will fill an important gap in our knowledge of this disorder. The work will address the need for basic theoretical research to increase our understanding of the cognitive strengths and weaknesses of children with ASD, but it will also provide answers to an important and pressing real-world issue - how do we ensure that children with ASD obtain fair and appropriate access to justice? The project has been designed to impact directly on policy by providing a basis for the development of guidelines and interventions to improve the performance of children with ASD in the Criminal Justice System (in collaboration with the National Autistic Society, UK).","isTelecoms":0}
{"text":"Title: Regen-membrane - Pulsed Electrophoretic Deposition to give Membranes for Regenerative Medicine Abstract: Collagen membranes are a major tool in wound regeneration, encouraging cell growth, providing barrier functions, and improving cosmetic outcomes, with the market of membranes for dental wound repair alone expected to nearly double to $200m by 2023. Currently used membranes however suffer a range of limitations in size, shape, and biocompatibility, making surgeries complex and the wound healing behaviour hard to predict. As such, there is a need for new collagen based membranes to help both clinicians and patients.\n\nWe have developed a novel technology, based on electrophoretic deposition, to produce free-standing, collagen-based membranes that do not suffer from these limitations. Using our technology, rapid and simple production of large scale or complex shaped collagen membranes is possible, giving clinicians more options for difficult wound management. Furthermore, our technology allows for production of textured and curved membranes, including tubes, which currently cannot be fabricated and would be highly desirable for roles such as peripheral nerve regeneration and maxillofacial surgery.\n\nAdditionally, we can open new market areas by producing membranes with aligned fibres for high suturability, and membranes with live cells embedded within that can greatly increase the rate of healing, reduce patient discomfort, and improve cosmetic outcomes.  We anticipate that our cell-laden membranes will be able to be transportable in a partially dehydrated state, allowing for ease of storage and transport.\n\nFinally, our technology allows us to combine these attributes together to provide membranes tailored towards specific clinical needs, something not possible with the \u201cone size fits all\u201d membranes currently on the market. We believe this will make our products highly desirable and give us a significant advantage in a rapidly growing healthcare market.","isTelecoms":0}
{"text":"Title: Counterfactual Visual Explanations in Ophthalmic Imaging Abstract: Neural networks, a type of machine learning, achieve above-human performance in classifying or 'diagnosing' medical images. However, the inner workings of these networks are not interpretable to humans. Being able to understand why a neural network makes a certain classification decision is an important step in getting machine learning systems deployed in the clinic. This project focuses on building counterfactual images, which in essence allows the user to ask 'what if' questions of a neural network in order to understand its output better.\n\nThe project nicely matches the stated aims of the centre:\n\n1) Extracting more information from patient data to accelerate diagnosis:\nThe huge collection of OCT data from patients at Moorfields is a fantastic resource with\nalready demonstrated potential to accelerate and improve accuracy of diagnosis; it\nprovides the perfect exemplar for maximising the potential of human-AI partnership.\n2) Creating adaptive and flexible systems that improve the operation of healthcare\norganisations:\nThe human-AI partnership paradigm that motivates this project addresses this aim\ndirectly and has much wider potential beyond the demonstration in ophthalmology.\n3) Delivering personalised and targeted treatments for patients:\nBetter diagnostic and referral decisions directly enable personalised treatment and care\ndesign\n\nSupervisors: Pearse Keane, Danny Alexander","isTelecoms":1}
{"text":"Title: wearable chemical sensor - cortisol Abstract: The wearable chemical sensor-cortisol project is an industrial research project that will allow SouthWestSensor (SWS) Ltd to offer a novel chemical sensor device for the measurement of cortisol, to be used in hospitals, community care and sport science. SWS Ltd has already established sensor devices for the measurement of chemical concentrations for a variety of biomarkers from body fluids such as glucose, lactate and thiols. This project will set up a new collaboration between SWS and LGC group, to develop a novel device for continuous measurement of cortisol \u2013 an important hormone indicator to many diseases. Because cortisol changes in circadian cycles, with the magnitude varying from person to person, the single point measurements currently performed in hospital do not give a representative picture of cortisol in the subject. This new device will provide a step forward for the thorough and accurate measurement and better diagnostics of related diseases. Since cortisol is linked to stress wearable devices can also provide a real time and continuous measurement of training effect and the body condition of elite athletes.","isTelecoms":1}
{"text":"Title: Drought-proofing tree seeds: coating technology to increase productivity at forest nurseries Abstract: Globally, governments and private organisations set ambitious commitments for tree planting and forest regeneration programmes, at an estimated cost of &pound;1.5 billion per year. Demand for tree saplings is increasing in the UK and abroad. However, COVID-19 disruptions caused losses for the forest nursery sector and will likely lead to plant supply shortages in the coming years.\n\nThe sector is also vulnerable to increasingly erratic weather. For example, the 2018 heatwave impacted the nursery trade across Northern hemisphere. At UK nurseries, up to 90% of viable seeds were lost due to poor germination.\n\nFinally, without a strong, vibrant domestic timber supply, the UK will become reliant on international imports which naturally have a higher carbon footprint. Depending on where and how the timber was harvested, imports may also decrease global biodiversity.\n\nAt SilviBio, we want to address this quandary through our seed enhancement technologies that increase conifer seed germination rates. By improving germination rates, our technology will enable more efficient seed use that directly results in more trees for forest nurseries and helps the Government's reach its tree planting targets. Specifically, we want to modify our technology to improve scalability of application and enhance access to our product.","isTelecoms":0}
{"text":"Title: Elemental analysis and structural characterisation of Li-containing ore materials using advanced muon and neutron techniques Abstract: The rapidly increasing demand for Li-ion batteries to power portable consumer electronics, electric vehicles and large power storage facilities has led to the EU classing Li as a critical element from Sept 2020. The Faraday Battery Challenge is a &pound;274 million investment by UK government to fund research and innovation projects in the area of batteries. This is driven by the governments plan for replacement of all conventional petrol and diesel vehicles by electric and zero emission vehicles by 2035. To position the UK as a leader in the development of Li battery technologies the UK must ensure it is self-sufficient in terms of raw materials required for domestic production of Li batteries.","isTelecoms":1}
{"text":"Title: Language attitudes in the British deaf community: Evidence from the British Sign Language Corpus Abstract: The aim of this project is to conduct secondary data analysis of the BSL Corpus, an existing large video dataset of British Sign Language (or 'BSL', the language of the British deaf community), to study language awareness and language attitudes in BSL. The BSL Corpus consists of video data collected from 249 native and near-native deaf signers of BSL from 8 sites across the United Kingdom. The data are representative of the language community, including a mix of men and women, deaf adults with deaf parents and those with hearing parents, signers who are young and old, and individuals from working and middle class backgrounds as well as different ethnic groups. The primary aim of the project is to investigate language attitudes of the British deaf community using the BSL Corpus interview data which consists of responses from all 249 signers to a range of questions about BSL, what it is and what it isn't, how it is used and how it should be used, how it varies and how it's changing (and whether it should or shouldn't vary\/change). We will be able to see if there are similarities or differences in the language attitudes of different social groups within the deaf community (e.g. if there are differences in how BSL is viewed by younger and older signers), and how attitudes relate to signers' own behaviours (e.g. whether signers are aware that there are actually differences between younger and older signers, as found in recent research, and what those differences are). This study also gives us the opportunity to explore the deaf community's attitude towards language contact between BSL and English - e.g. via attitudes about BSL versus English-based sign systems such as Sign-Supported English (SSE). This information will be beneficial for future research on BSL but also in language planning and policy, including the legal status of BSL in the UK. Additionally, translations of the interview data will be completed and made publicly available online. Translating the interview data means people will be able to see video clips of deaf people from different areas of the UK, different age groups and gender signing in BSL along with English translations. This will dramatically increase the searchability and browsability of the interview data, making it accessible and thus a much more valuable resource for teachers, learners and researchers.","isTelecoms":1}
{"text":"Title: The drivers of major transitions in mutualistic dependence Abstract: Cooperation among species (mutualism) is widespread in nature. Such partnerships between species can be of very different kinds. Mutualisms vary from associations between species that can also live without each other (facultative) to tight obligate partnerships binding species' fates together. When do these different types of mutualisms evolve or get lost? What makes a species obligately dependent on another one? Why can some associations peacefully disassemble while, in other cases, divorce is a dead end? This project aims to understand when and how mutualistic dependence evolves. \n\nAddressing this major scientific challenge requires analysing mutualistic associations at different scales. I will do so using three main approaches. My first approach will involve mapping different kinds of animal\/plant mutualisms presence and absence across the plant tree of life in order to understand when they evolve or break down. To do this, I will use three major animal\/plant mutualisms: pollination, seed dispersal and plant defence against herbivores or pathogens. These three ecologically important types of animal\/plant mutualisms converge in that the key function can be dependent or independent on an animal mutualism. I will map these strategies on a large evolutionary plant trees (phylogenies). This will allow me to test several hypotheses regarding the factors promoting mutualistic dependence or its breakdown.\n\nMy next goal will be to determine what changes in the genetic makeup are responsible for shifts in mutualistic dependence. So far, our knowledge on this area is restricted to mutualisms involving microbes living inside a host. My previous worked has shown that facultative mutualisms are lost easily while obligate mutualisms are evolutionary conserved. What defines the reversibility of these mutualistic dependencies? To address these questions, I will focus on a type of symbiotic mutualisms where plants host ants in return for extra nutrients (and sometimes defence against herbivores). This group of ~105 plant species from the coffee family is ideal system to answer this question since they have various levels of dependence. Using DNA sequencing, I will focus on three main questions: (1) Does the loss of functional genes drive mutualism dependence in these symbioses between ants and plants, as it does in partnerships between microbes and hosts? (2) How do different levels of mutualistic dependence affect the pace of gene evolution? And (3) Can we identify the genomic changes associated with trait evolution in the transition from facultative to obligate dependence?\n\nFinally, I will test the hypothesis that obligate dependence on ants in this group is the result of the loss of pathogen defence function (implying that this function is performed by the ants), which arises from my preliminary data. To do so, I will perform experiments in the field where I remove ants from obligate and facultative plants, and examine plant heath across all these treatments, notably by using a state-of-the-art method to compare microbes communities in these different cases. This will, in turn, reveal the impact of mutualistic dependence on microbial communities.\n\nAt the end of this project, I hope to have identified the conditions fostering the evolution of mutualistic dependence, the mechanisms by which obligate dependence is mediated and how it impacts the evolution of the genetic makeup in an animal\/plant mutualism. Since mutualistic dependence affects many ecological and evolutionary processes, understanding how it evolves will enhance our understanding of species evolution. Moreover, because highly dependent, obligate mutualists are deemed to be more vulnerable to extinction since their fate is bound to their mutualistic partner, this research has the potential to inform conservation.","isTelecoms":0}
{"text":"Title: Climate at the time of the Human settlement the Eastern Pacific Abstract: The migration into the Pacific Ocean and the settlement of island archipelagoes by the ancestors of modern pacific islanders is contested, yet remains one of humankinds greatest achievements. Evidence for when and why people chose to undertake hazardous voyages in large wooden voyaging canoes is uncertain, however recent hypotheses developed in part by the Supervisory team, point to a coincidence with a widespread regional drought - the largest I the past 2000 years (Sear et al., 2020). What we are less certain of is what role climate played in driving the migrations east into Polynesia and how it supported those migrations - were they in effect &quot;chasing the rain&quot; east as drought developed in the west? What is also unclear is the extent of this drought and the detail of its duration around the region settled by the Polynesian voyagers. To understand this requires robust dated sediment archives containing both unequivocal evidence for human arrival and presence, and hydroclimate proxies. This project will seek to develop these for three islands in French Polynesia and combine the new records with existing evidence from other regions of the Pacific to understand the temporal and spatial coincidence of climate and human migration.","isTelecoms":0}
